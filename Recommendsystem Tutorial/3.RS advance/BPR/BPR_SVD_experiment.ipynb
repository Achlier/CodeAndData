{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BPR_SVD_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   The data used is u.data of ml-k100 in movielens, specifically user_id, item_id and rating. In [BPR](BPR_algorithm.ipynb), we use the number of rating greater than a certain value as implicit positive feedback, and the remaining rating is regarded as no feedback in the data. The concentration is expressed as (user_id, item_id, rating=0/1). In SVD we still use the rating score as the data for prediction. We compare the Top-N recommendation lists from the two models and finally compare the two models using the indicators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BPR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BPR Cost Function:\n",
    "\\begin{align}\n",
    "ln\\;P(\\theta|>_u) \\propto ln\\;P(>_u|\\theta)P(\\theta) &= ln\\;\\prod\\limits_{(u,i,j) \\in D} \\sigma(\\overline{x}_{ui} - \\overline{x}_{uj}) + ln P(\\theta) \\\\\n",
    "&= \\sum\\limits_{(u,i,j) \\in D}ln\\sigma(\\overline{x}_{ui} - \\overline{x}_{uj}) + \\lambda||\\theta||^2\\;\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: existing data set $D$, learning rate $\\alpha$, regularization parameter $\\lambda$, eigenvalue dimension $k$\n",
    "\n",
    "Output: Model parameters, ie matrix $W$, $H$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "> 1. initialize $W,H$\n",
    "\n",
    "> 2. Iteratively update the parameters, the formula is as follows：\n",
    "\\begin{align}\n",
    "w_{uf} &= w_{uf} + \\alpha(\\sum\\limits_{(u,i,j)\\in D}\\frac{1}{1+e^{\\overline{x}_{ui} - \\overline{x}_{uj}}}(h_{if}-h_{jf})+\\lambda w_{uf})\\\\\n",
    "h_{if} &= h_{if} + \\alpha(\\sum\\limits_{(u,i,j)\\in D}\\frac{1}{1+e^{\\overline{x}_{ui} - \\overline{x}_{uj}}}w_{uf} + \\lambda h_{if})\\\\\n",
    "h_{jf} &= h_{jf} + \\sum\\limits_{(u,i,j)\\in D}\\frac{1}{1+e^{\\overline{x}_{ui} - \\overline{x}_{uj}}}(-w_{uf}) + \\lambda h_{jf})\n",
    "\\end{align}\n",
    "\n",
    "> 3.Repeat step 2 until $W, H$ converges, output $W, H$\n",
    "\n",
    "> 4.Calculate the preference value of each user for the item by $W, H$, sort the items according to the preference value, and finally give the highest ranked $n$ items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> $ \\hat{r_{ui}} = b_{ui} + q_i^T (p_u + |N_{(u)}|^{-\\frac{1}{2}} \\sum\\limits_{j \\in N_{(u)}}y_j) $ $\\quad (q_i,p_u \\in R^f ，下同)$ </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost function:\n",
    "<center>$ C(q_i, p_u, b_u, b_i, y_j) =\\frac{1}{2} \\sum\\limits_{(u,i) \\in \\kappa}\\{(r_{ui} - \\hat{r}_{ui})^2 + \\lambda(||q_i||^2 + ||p_u||^2 + b_u^2 + b_i^2 + y_j^2)\\}$</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "error term:\n",
    "\\begin{align}\n",
    "error = r_{ui} - \\hat{r}_{ui}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: existing data set $R$ , learning rate $\\alpha$, regularization parameter $\\lambda$, eigenvalue dimension $k$\n",
    "\n",
    "Output: Model parameters, ie matrix $P$,$Q$,$Bu$,$Bi$,$Y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">1. initialize $P$ ,$Q$,$Bu$,$Bi$,$Y$\n",
    "\n",
    ">2. Iteratively update the parameters, by Stochastic Gradient Descent(SGD):\n",
    ">\\begin{align}\n",
    " b_u :&= b_u + \\alpha(error - \\lambda \\cdot b_u)\\\\\n",
    " b_i :&= b_i + \\alpha(error - \\lambda \\cdot b_i)\\\\\n",
    " p_u :&= p_u + \\alpha(error \\cdot q_i - \\lambda \\cdot p_u)\\\\\n",
    " q_i :&= q_i + \\alpha(error \\cdot (p_u +|N_{(u)}|^{-\\frac{1}{2}} \\sum\\limits_{j \\in N_{(u)}}y_j) - \\lambda \\cdot q_i)\\\\\n",
    " y_j :&= y_j + \\alpha(error \\cdot q_i \\cdot |N_{(u)}|^{-\\frac{1}{2}}  - \\lambda \\cdot y_j)\n",
    "\\end{align}\n",
    "\n",
    ">3.Repeat step 2 until  $P$ ,$Q$, $Bu$, $Bi$,$Y$  converges, output  them\n",
    "\n",
    ">4.Calculate the predict rating value of each user for the item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get The data from internet or local file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data dimension: \n",
      " (100000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>298</td>\n",
       "      <td>474</td>\n",
       "      <td>4</td>\n",
       "      <td>884182806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>115</td>\n",
       "      <td>265</td>\n",
       "      <td>2</td>\n",
       "      <td>881171488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>253</td>\n",
       "      <td>465</td>\n",
       "      <td>5</td>\n",
       "      <td>891628467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>305</td>\n",
       "      <td>451</td>\n",
       "      <td>3</td>\n",
       "      <td>886324817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>86</td>\n",
       "      <td>3</td>\n",
       "      <td>883603013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>62</td>\n",
       "      <td>257</td>\n",
       "      <td>2</td>\n",
       "      <td>879372434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>286</td>\n",
       "      <td>1014</td>\n",
       "      <td>5</td>\n",
       "      <td>879781125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>200</td>\n",
       "      <td>222</td>\n",
       "      <td>5</td>\n",
       "      <td>876042340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>210</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>891035994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>224</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>888104457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>303</td>\n",
       "      <td>785</td>\n",
       "      <td>3</td>\n",
       "      <td>879485318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>122</td>\n",
       "      <td>387</td>\n",
       "      <td>5</td>\n",
       "      <td>879270459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>194</td>\n",
       "      <td>274</td>\n",
       "      <td>2</td>\n",
       "      <td>879539794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>291</td>\n",
       "      <td>1042</td>\n",
       "      <td>4</td>\n",
       "      <td>874834944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>234</td>\n",
       "      <td>1184</td>\n",
       "      <td>2</td>\n",
       "      <td>892079237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>119</td>\n",
       "      <td>392</td>\n",
       "      <td>4</td>\n",
       "      <td>886176814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>167</td>\n",
       "      <td>486</td>\n",
       "      <td>4</td>\n",
       "      <td>892738452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>299</td>\n",
       "      <td>144</td>\n",
       "      <td>4</td>\n",
       "      <td>877881320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>291</td>\n",
       "      <td>118</td>\n",
       "      <td>2</td>\n",
       "      <td>874833878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>308</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>887736532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>95</td>\n",
       "      <td>546</td>\n",
       "      <td>2</td>\n",
       "      <td>879196566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>38</td>\n",
       "      <td>95</td>\n",
       "      <td>5</td>\n",
       "      <td>892430094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>102</td>\n",
       "      <td>768</td>\n",
       "      <td>2</td>\n",
       "      <td>883748450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>63</td>\n",
       "      <td>277</td>\n",
       "      <td>4</td>\n",
       "      <td>875747401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>160</td>\n",
       "      <td>234</td>\n",
       "      <td>5</td>\n",
       "      <td>876861185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99970</th>\n",
       "      <td>449</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>879959573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99971</th>\n",
       "      <td>661</td>\n",
       "      <td>762</td>\n",
       "      <td>2</td>\n",
       "      <td>876037121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99972</th>\n",
       "      <td>721</td>\n",
       "      <td>874</td>\n",
       "      <td>3</td>\n",
       "      <td>877137447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973</th>\n",
       "      <td>821</td>\n",
       "      <td>151</td>\n",
       "      <td>4</td>\n",
       "      <td>874792889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99974</th>\n",
       "      <td>764</td>\n",
       "      <td>596</td>\n",
       "      <td>3</td>\n",
       "      <td>876243046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99975</th>\n",
       "      <td>537</td>\n",
       "      <td>443</td>\n",
       "      <td>3</td>\n",
       "      <td>886031752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99976</th>\n",
       "      <td>618</td>\n",
       "      <td>628</td>\n",
       "      <td>2</td>\n",
       "      <td>891308019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99977</th>\n",
       "      <td>487</td>\n",
       "      <td>291</td>\n",
       "      <td>3</td>\n",
       "      <td>883445079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99978</th>\n",
       "      <td>113</td>\n",
       "      <td>975</td>\n",
       "      <td>5</td>\n",
       "      <td>875936424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99979</th>\n",
       "      <td>943</td>\n",
       "      <td>391</td>\n",
       "      <td>2</td>\n",
       "      <td>888640291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99980</th>\n",
       "      <td>864</td>\n",
       "      <td>685</td>\n",
       "      <td>4</td>\n",
       "      <td>888891900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99981</th>\n",
       "      <td>750</td>\n",
       "      <td>323</td>\n",
       "      <td>3</td>\n",
       "      <td>879445877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99982</th>\n",
       "      <td>279</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>875308510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99983</th>\n",
       "      <td>646</td>\n",
       "      <td>750</td>\n",
       "      <td>3</td>\n",
       "      <td>888528902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99984</th>\n",
       "      <td>654</td>\n",
       "      <td>370</td>\n",
       "      <td>2</td>\n",
       "      <td>887863914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99985</th>\n",
       "      <td>617</td>\n",
       "      <td>582</td>\n",
       "      <td>4</td>\n",
       "      <td>883789294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99986</th>\n",
       "      <td>913</td>\n",
       "      <td>690</td>\n",
       "      <td>3</td>\n",
       "      <td>880824288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99987</th>\n",
       "      <td>660</td>\n",
       "      <td>229</td>\n",
       "      <td>2</td>\n",
       "      <td>891406212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99988</th>\n",
       "      <td>421</td>\n",
       "      <td>498</td>\n",
       "      <td>4</td>\n",
       "      <td>892241344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99989</th>\n",
       "      <td>495</td>\n",
       "      <td>1091</td>\n",
       "      <td>4</td>\n",
       "      <td>888637503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99990</th>\n",
       "      <td>806</td>\n",
       "      <td>421</td>\n",
       "      <td>4</td>\n",
       "      <td>882388897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99991</th>\n",
       "      <td>676</td>\n",
       "      <td>538</td>\n",
       "      <td>4</td>\n",
       "      <td>892685437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99992</th>\n",
       "      <td>721</td>\n",
       "      <td>262</td>\n",
       "      <td>3</td>\n",
       "      <td>877137285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99993</th>\n",
       "      <td>913</td>\n",
       "      <td>209</td>\n",
       "      <td>2</td>\n",
       "      <td>881367150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99994</th>\n",
       "      <td>378</td>\n",
       "      <td>78</td>\n",
       "      <td>3</td>\n",
       "      <td>880056976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>880</td>\n",
       "      <td>476</td>\n",
       "      <td>3</td>\n",
       "      <td>880175444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>716</td>\n",
       "      <td>204</td>\n",
       "      <td>5</td>\n",
       "      <td>879795543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>276</td>\n",
       "      <td>1090</td>\n",
       "      <td>1</td>\n",
       "      <td>874795795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>13</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "      <td>882399156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>12</td>\n",
       "      <td>203</td>\n",
       "      <td>3</td>\n",
       "      <td>879959583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  item_id  rating  timestamp\n",
       "0          196      242       3  881250949\n",
       "1          186      302       3  891717742\n",
       "2           22      377       1  878887116\n",
       "3          244       51       2  880606923\n",
       "4          166      346       1  886397596\n",
       "5          298      474       4  884182806\n",
       "6          115      265       2  881171488\n",
       "7          253      465       5  891628467\n",
       "8          305      451       3  886324817\n",
       "9            6       86       3  883603013\n",
       "10          62      257       2  879372434\n",
       "11         286     1014       5  879781125\n",
       "12         200      222       5  876042340\n",
       "13         210       40       3  891035994\n",
       "14         224       29       3  888104457\n",
       "15         303      785       3  879485318\n",
       "16         122      387       5  879270459\n",
       "17         194      274       2  879539794\n",
       "18         291     1042       4  874834944\n",
       "19         234     1184       2  892079237\n",
       "20         119      392       4  886176814\n",
       "21         167      486       4  892738452\n",
       "22         299      144       4  877881320\n",
       "23         291      118       2  874833878\n",
       "24         308        1       4  887736532\n",
       "25          95      546       2  879196566\n",
       "26          38       95       5  892430094\n",
       "27         102      768       2  883748450\n",
       "28          63      277       4  875747401\n",
       "29         160      234       5  876861185\n",
       "...        ...      ...     ...        ...\n",
       "99970      449      120       1  879959573\n",
       "99971      661      762       2  876037121\n",
       "99972      721      874       3  877137447\n",
       "99973      821      151       4  874792889\n",
       "99974      764      596       3  876243046\n",
       "99975      537      443       3  886031752\n",
       "99976      618      628       2  891308019\n",
       "99977      487      291       3  883445079\n",
       "99978      113      975       5  875936424\n",
       "99979      943      391       2  888640291\n",
       "99980      864      685       4  888891900\n",
       "99981      750      323       3  879445877\n",
       "99982      279       64       1  875308510\n",
       "99983      646      750       3  888528902\n",
       "99984      654      370       2  887863914\n",
       "99985      617      582       4  883789294\n",
       "99986      913      690       3  880824288\n",
       "99987      660      229       2  891406212\n",
       "99988      421      498       4  892241344\n",
       "99989      495     1091       4  888637503\n",
       "99990      806      421       4  882388897\n",
       "99991      676      538       4  892685437\n",
       "99992      721      262       3  877137285\n",
       "99993      913      209       2  881367150\n",
       "99994      378       78       3  880056976\n",
       "99995      880      476       3  880175444\n",
       "99996      716      204       5  879795543\n",
       "99997      276     1090       1  874795795\n",
       "99998       13      225       2  882399156\n",
       "99999       12      203       3  879959583\n",
       "\n",
       "[100000 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "file_dir = 'ml-100k'\n",
    "file_path = os.path.join(file_dir, 'u.data')\n",
    "if not os.path.isdir(file_dir):\n",
    "    call(['curl', '-O', 'http://files.grouplens.org/datasets/movielens/' + file_dir + '.zip'])\n",
    "    call(['unzip', file_dir + '.zip'])\n",
    "\n",
    "# we will not be using the timestamp column\n",
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv(file_path, sep = '\\t', names = names)\n",
    "print('data dimension: \\n', df.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### BPR Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Desktop\\RS_AE\\BPR_all\\BPR.py:328: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  data[ratings_col] = 1\n",
      "C:\\Users\\lenovo\\Desktop\\RS_AE\\BPR_all\\BPR.py:331: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  data[col] = data[col].astype('category')\n"
     ]
    }
   ],
   "source": [
    "from BPR import *\n",
    "items_col = 'item_id'\n",
    "users_col = 'user_id'\n",
    "ratings_col = 'rating'\n",
    "threshold = 3\n",
    "X, df_2 = create_matrix(df, users_col, items_col, ratings_col, threshold)\n",
    "X_train, X_test = create_train_test(X, test_size = 0.2, seed = 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### with fixed other parameters and then change number of recomm-items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BPR: 100%|███████████████████████████████████████████████████████████████████████████| 160/160 [00:01<00:00, 92.73it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BPR.BPR at 0x21eafe75dd8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters were randomly chosen\n",
    "bpr_params = {'reg': 0.01,\n",
    "              'learning_rate': 0.01,\n",
    "              'n_iters': 160,\n",
    "              'n_factors': 15,\n",
    "              'batch_size': 100}\n",
    "bpr = BPR(**bpr_params)\n",
    "bpr.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- recall rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.004265655548314474,\n",
       " 0.024882990698501094,\n",
       " 0.054031636945316666,\n",
       " 0.08519462053439185,\n",
       " 0.11635760412346703,\n",
       " 0.1508383198056757,\n",
       " 0.1875703536939392]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc_list_bpr=[]\n",
    "for num in [10,50,100,150,200,250,300]:\n",
    "    rc = recall_bpr(bpr,X_train,X_test,num)\n",
    "    rc_list_bpr.append(rc)\n",
    "rc_list_bpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- precision rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.007635206786850477,\n",
       " 0.008907741251325556,\n",
       " 0.009671261930010604,\n",
       " 0.010166136443973135,\n",
       " 0.010413573700954401,\n",
       " 0.010799575821845176,\n",
       " 0.01119123365146695]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preci_list_bpr=[]\n",
    "for num in [10,50,100,150,200,250,300]:\n",
    "    preci = precision_bpr(bpr,X_train,X_test,num)\n",
    "    preci_list_bpr.append(preci)\n",
    "preci_list_bpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### with fixed other parameters and then change number of factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- recall rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BPR: 100%|███████████████████████████████████████████████████████████████████████████| 160/160 [00:01<00:00, 94.71it/s]\n",
      "BPR: 100%|███████████████████████████████████████████████████████████████████████████| 160/160 [00:01<00:00, 93.38it/s]\n",
      "BPR: 100%|███████████████████████████████████████████████████████████████████████████| 160/160 [00:01<00:00, 91.10it/s]\n",
      "BPR: 100%|███████████████████████████████████████████████████████████████████████████| 160/160 [00:01<00:00, 90.37it/s]\n",
      "BPR: 100%|███████████████████████████████████████████████████████████████████████████| 160/160 [00:01<00:00, 85.97it/s]\n",
      "BPR: 100%|███████████████████████████████████████████████████████████████████████████| 160/160 [00:01<00:00, 87.28it/s]\n",
      "BPR: 100%|███████████████████████████████████████████████████████████████████████████| 160/160 [00:01<00:00, 81.48it/s]\n",
      "BPR: 100%|███████████████████████████████████████████████████████████████████████████| 160/160 [00:02<00:00, 79.88it/s]\n",
      "BPR: 100%|███████████████████████████████████████████████████████████████████████████| 160/160 [00:01<00:00, 82.36it/s]\n",
      "BPR: 100%|███████████████████████████████████████████████████████████████████████████| 160/160 [00:01<00:00, 84.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.002666034717696546,\n",
       " 0.0017181112625155519,\n",
       " 0.002310563422003673,\n",
       " 0.0019550921263108,\n",
       " 0.0027252799336453582,\n",
       " 0.003495467740979916,\n",
       " 0.0024882990698501094,\n",
       " 0.0020143373422596127,\n",
       " 0.001777356478464364,\n",
       " 0.002666034717696546]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc_bpr_fac = []\n",
    "for factors in [10,20,30,40,50,60,70,80,90,100]:\n",
    "    bpr_params = {'reg': 0.01,\n",
    "                  'learning_rate': 0.01,\n",
    "                  'n_iters': 160,\n",
    "                  'n_factors': factors,\n",
    "                  'batch_size': 100}\n",
    "\n",
    "    bpr = BPR(**bpr_params)\n",
    "    bpr.fit(X_train)\n",
    "    rc = recall_bpr(bpr,X_train,X_test)\n",
    "    rc_bpr_fac.append(rc)\n",
    "rc_bpr_fac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- precision rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BPR: 100%|███████████████████████████████████████████████████████████████████████████| 160/160 [00:01<00:00, 94.82it/s]\n",
      "BPR: 100%|███████████████████████████████████████████████████████████████████████████| 160/160 [00:01<00:00, 90.95it/s]\n",
      "BPR: 100%|███████████████████████████████████████████████████████████████████████████| 160/160 [00:01<00:00, 92.36it/s]\n",
      "BPR: 100%|███████████████████████████████████████████████████████████████████████████| 160/160 [00:01<00:00, 88.61it/s]\n",
      "BPR: 100%|███████████████████████████████████████████████████████████████████████████| 160/160 [00:01<00:00, 89.08it/s]\n",
      "BPR: 100%|███████████████████████████████████████████████████████████████████████████| 160/160 [00:01<00:00, 88.62it/s]\n",
      "BPR: 100%|███████████████████████████████████████████████████████████████████████████| 160/160 [00:01<00:00, 87.81it/s]\n",
      "BPR: 100%|███████████████████████████████████████████████████████████████████████████| 160/160 [00:02<00:00, 78.10it/s]\n",
      "BPR: 100%|███████████████████████████████████████████████████████████████████████████| 160/160 [00:01<00:00, 86.57it/s]\n",
      "BPR: 100%|███████████████████████████████████████████████████████████████████████████| 160/160 [00:01<00:00, 86.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.009544008483563097,\n",
       " 0.007635206786850477,\n",
       " 0.008695652173913044,\n",
       " 0.008695652173913044,\n",
       " 0.009968186638388122,\n",
       " 0.012089077412513256,\n",
       " 0.008695652173913044,\n",
       " 0.008059384941675504,\n",
       " 0.007423117709437964,\n",
       " 0.009331919406150583]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preci_bpr_fac = []\n",
    "for factors in [10,20,30,40,50,60,70,80,90,100]:\n",
    "    bpr_params = {'reg': 0.01,\n",
    "                  'learning_rate': 0.01,\n",
    "                  'n_iters': 160,\n",
    "                  'n_factors': factors,\n",
    "                  'batch_size': 100}\n",
    "\n",
    "    bpr = BPR(**bpr_params)\n",
    "    bpr.fit(X_train)\n",
    "    preci = precision_bpr(bpr,X_train,X_test)\n",
    "    preci_bpr_fac.append(preci)\n",
    "preci_bpr_fac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### SVD++ Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### with fixed other parameters and then change number of recomm-items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80023\n",
      "19977\n",
      "cold start users count 0\n",
      "{\n",
      "    'dataset_name': 'u',\n",
      "    'k_fold_num': 5,\n",
      "    'k_test': 0,\n",
      "    'rating_path': 'Z:/RSA/data/u_ratings.txt',\n",
      "    'rating_cv_path': 'Z:/RSA/data/cv/',\n",
      "    'trust_path': 'Z:/RSA/data/u_trust.txt',\n",
      "    'sep': ' ',\n",
      "    'random_state': 0,\n",
      "    'size': 0.8,\n",
      "    'min_val': 0.5,\n",
      "    'max_val': 4.0,\n",
      "    'coldUserRating': 5,\n",
      "    'factor': 10,\n",
      "    'threshold': 0.0001,\n",
      "    'lr': 0.01,\n",
      "    'maxIter': 100,\n",
      "    'lambdaP': 0.001,\n",
      "    'lambdaQ': 0.001,\n",
      "    'gamma': 0,\n",
      "    'isEarlyStopping': False,\n",
      "    'result_path': '../results/',\n",
      "    'model_path': 'model/',\n",
      "    'result_log_path': 'log/'\n",
      "}\n",
      "80023\n",
      "19977\n",
      "cold start users count 0\n",
      "80023\n",
      "19977\n",
      "cold start users count 0\n",
      "<class 'data.RSContext'> iteration 1: loss = 35127.9838, delta_loss = -35127.98383 learning_Rate = 0.01000 rmse=1.12749 mae=0.87977\n",
      "<class 'data.RSContext'> iteration 2: loss = 8104.8620, delta_loss = 27023.12188 learning_Rate = 0.01000 rmse=1.02719 mae=0.80131\n",
      "<class 'data.RSContext'> iteration 3: loss = 6877.0900, delta_loss = 1227.77199 learning_Rate = 0.01000 rmse=1.00840 mae=0.78802\n",
      "<class 'data.RSContext'> iteration 4: loss = 6531.4986, delta_loss = 345.59134 learning_Rate = 0.01000 rmse=1.00152 mae=0.78394\n",
      "<class 'data.RSContext'> iteration 5: loss = 6360.4579, delta_loss = 171.04076 learning_Rate = 0.01000 rmse=0.99801 mae=0.78206\n",
      "<class 'data.RSContext'> iteration 6: loss = 6250.7427, delta_loss = 109.71518 learning_Rate = 0.01000 rmse=0.99568 mae=0.78081\n",
      "<class 'data.RSContext'> iteration 7: loss = 6170.1077, delta_loss = 80.63500 learning_Rate = 0.01000 rmse=0.99399 mae=0.77982\n",
      "<class 'data.RSContext'> iteration 8: loss = 6105.7804, delta_loss = 64.32724 learning_Rate = 0.01000 rmse=0.99273 mae=0.77910\n",
      "<class 'data.RSContext'> iteration 9: loss = 6051.5059, delta_loss = 54.27450 learning_Rate = 0.01000 rmse=0.99182 mae=0.77856\n",
      "<class 'data.RSContext'> iteration 10: loss = 6003.7634, delta_loss = 47.74259 learning_Rate = 0.01000 rmse=0.99115 mae=0.77816\n",
      "<class 'data.RSContext'> iteration 11: loss = 5960.3762, delta_loss = 43.38718 learning_Rate = 0.01000 rmse=0.99058 mae=0.77782\n",
      "<class 'data.RSContext'> iteration 12: loss = 5919.9076, delta_loss = 40.46859 learning_Rate = 0.01000 rmse=0.99003 mae=0.77751\n",
      "<class 'data.RSContext'> iteration 13: loss = 5881.3625, delta_loss = 38.54512 learning_Rate = 0.01000 rmse=0.98959 mae=0.77726\n",
      "<class 'data.RSContext'> iteration 14: loss = 5844.0265, delta_loss = 37.33592 learning_Rate = 0.01000 rmse=0.98923 mae=0.77704\n",
      "<class 'data.RSContext'> iteration 15: loss = 5807.3738, delta_loss = 36.65271 learning_Rate = 0.01000 rmse=0.98893 mae=0.77684\n",
      "<class 'data.RSContext'> iteration 16: loss = 5771.0109, delta_loss = 36.36295 learning_Rate = 0.01000 rmse=0.98868 mae=0.77665\n",
      "<class 'data.RSContext'> iteration 17: loss = 5734.6421, delta_loss = 36.36878 learning_Rate = 0.01000 rmse=0.98848 mae=0.77649\n",
      "<class 'data.RSContext'> iteration 18: loss = 5698.0477, delta_loss = 36.59436 learning_Rate = 0.01000 rmse=0.98829 mae=0.77634\n",
      "<class 'data.RSContext'> iteration 19: loss = 5661.0696, delta_loss = 36.97816 learning_Rate = 0.01000 rmse=0.98814 mae=0.77619\n",
      "<class 'data.RSContext'> iteration 20: loss = 5623.6013, delta_loss = 37.46824 learning_Rate = 0.01000 rmse=0.98799 mae=0.77606\n",
      "<class 'data.RSContext'> iteration 21: loss = 5585.5819, delta_loss = 38.01942 learning_Rate = 0.01000 rmse=0.98787 mae=0.77595\n",
      "<class 'data.RSContext'> iteration 22: loss = 5546.9901, delta_loss = 38.59176 learning_Rate = 0.01000 rmse=0.98776 mae=0.77583\n",
      "<class 'data.RSContext'> iteration 23: loss = 5507.8403, delta_loss = 39.14987 learning_Rate = 0.01000 rmse=0.98766 mae=0.77572\n",
      "<class 'data.RSContext'> iteration 24: loss = 5468.1774, delta_loss = 39.66284 learning_Rate = 0.01000 rmse=0.98759 mae=0.77561\n",
      "<class 'data.RSContext'> iteration 25: loss = 5428.0730, delta_loss = 40.10443 learning_Rate = 0.01000 rmse=0.98752 mae=0.77551\n",
      "<class 'data.RSContext'> iteration 26: loss = 5387.6195, delta_loss = 40.45347 learning_Rate = 0.01000 rmse=0.98746 mae=0.77540\n",
      "<class 'data.RSContext'> iteration 27: loss = 5346.9254, delta_loss = 40.69410 learning_Rate = 0.01000 rmse=0.98741 mae=0.77528\n",
      "<class 'data.RSContext'> iteration 28: loss = 5306.1095, delta_loss = 40.81597 learning_Rate = 0.01000 rmse=0.98735 mae=0.77514\n",
      "<class 'data.RSContext'> iteration 29: loss = 5265.2954, delta_loss = 40.81405 learning_Rate = 0.01000 rmse=0.98730 mae=0.77500\n",
      "<class 'data.RSContext'> iteration 30: loss = 5224.6072, delta_loss = 40.68824 learning_Rate = 0.01000 rmse=0.98724 mae=0.77484\n",
      "<class 'data.RSContext'> iteration 31: loss = 5184.1644, delta_loss = 40.44273 learning_Rate = 0.01000 rmse=0.98719 mae=0.77467\n",
      "<class 'data.RSContext'> iteration 32: loss = 5144.0793, delta_loss = 40.08514 learning_Rate = 0.01000 rmse=0.98714 mae=0.77448\n",
      "<class 'data.RSContext'> iteration 33: loss = 5104.4537, delta_loss = 39.62559 learning_Rate = 0.01000 rmse=0.98709 mae=0.77429\n",
      "<class 'data.RSContext'> iteration 34: loss = 5065.3779, delta_loss = 39.07584 learning_Rate = 0.01000 rmse=0.98704 mae=0.77407\n",
      "<class 'data.RSContext'> iteration 35: loss = 5026.9295, delta_loss = 38.44841 learning_Rate = 0.01000 rmse=0.98700 mae=0.77386\n",
      "<class 'data.RSContext'> iteration 36: loss = 4989.1735, delta_loss = 37.75595 learning_Rate = 0.01000 rmse=0.98693 mae=0.77366\n",
      "<class 'data.RSContext'> iteration 37: loss = 4952.1629, delta_loss = 37.01066 learning_Rate = 0.01000 rmse=0.98688 mae=0.77345\n",
      "<class 'data.RSContext'> iteration 38: loss = 4915.9388, delta_loss = 36.22401 learning_Rate = 0.01000 rmse=0.98682 mae=0.77323\n",
      "<class 'data.RSContext'> iteration 39: loss = 4880.5324, delta_loss = 35.40643 learning_Rate = 0.01000 rmse=0.98676 mae=0.77299\n",
      "<class 'data.RSContext'> iteration 40: loss = 4845.9652, delta_loss = 34.56725 learning_Rate = 0.01000 rmse=0.98670 mae=0.77276\n",
      "<class 'data.RSContext'> iteration 41: loss = 4812.2505, delta_loss = 33.71467 learning_Rate = 0.01000 rmse=0.98664 mae=0.77252\n",
      "<class 'data.RSContext'> iteration 42: loss = 4779.3947, delta_loss = 32.85578 learning_Rate = 0.01000 rmse=0.98658 mae=0.77229\n",
      "<class 'data.RSContext'> iteration 43: loss = 4747.3981, delta_loss = 31.99663 learning_Rate = 0.01000 rmse=0.98655 mae=0.77208\n",
      "<class 'data.RSContext'> iteration 44: loss = 4716.2557, delta_loss = 31.14233 learning_Rate = 0.01000 rmse=0.98653 mae=0.77190\n",
      "<class 'data.RSContext'> iteration 45: loss = 4685.9586, delta_loss = 30.29711 learning_Rate = 0.01000 rmse=0.98652 mae=0.77171\n",
      "<class 'data.RSContext'> iteration 46: loss = 4656.4942, delta_loss = 29.46445 learning_Rate = 0.01000 rmse=0.98649 mae=0.77154\n",
      "<class 'data.RSContext'> iteration 47: loss = 4627.8470, delta_loss = 28.64715 learning_Rate = 0.01000 rmse=0.98648 mae=0.77139\n",
      "<class 'data.RSContext'> iteration 48: loss = 4599.9996, delta_loss = 27.84742 learning_Rate = 0.01000 rmse=0.98648 mae=0.77126\n",
      "<class 'data.RSContext'> iteration 49: loss = 4572.9327, delta_loss = 27.06694 learning_Rate = 0.01000 rmse=0.98650 mae=0.77116\n",
      "<class 'data.RSContext'> iteration 50: loss = 4546.6257, delta_loss = 26.30697 learning_Rate = 0.01000 rmse=0.98654 mae=0.77106\n",
      "<class 'data.RSContext'> iteration 51: loss = 4521.0573, delta_loss = 25.56835 learning_Rate = 0.01000 rmse=0.98657 mae=0.77096\n",
      "<class 'data.RSContext'> iteration 52: loss = 4496.2057, delta_loss = 24.85164 learning_Rate = 0.01000 rmse=0.98660 mae=0.77086\n",
      "<class 'data.RSContext'> iteration 53: loss = 4472.0486, delta_loss = 24.15709 learning_Rate = 0.01000 rmse=0.98663 mae=0.77078\n",
      "<class 'data.RSContext'> iteration 54: loss = 4448.5639, delta_loss = 23.48475 learning_Rate = 0.01000 rmse=0.98668 mae=0.77069\n",
      "<class 'data.RSContext'> iteration 55: loss = 4425.7294, delta_loss = 22.83447 learning_Rate = 0.01000 rmse=0.98673 mae=0.77062\n",
      "<class 'data.RSContext'> iteration 56: loss = 4403.5234, delta_loss = 22.20595 learning_Rate = 0.01000 rmse=0.98679 mae=0.77055\n",
      "<class 'data.RSContext'> iteration 57: loss = 4381.9247, delta_loss = 21.59880 learning_Rate = 0.01000 rmse=0.98686 mae=0.77048\n",
      "<class 'data.RSContext'> iteration 58: loss = 4360.9121, delta_loss = 21.01251 learning_Rate = 0.01000 rmse=0.98694 mae=0.77043\n",
      "<class 'data.RSContext'> iteration 59: loss = 4340.4656, delta_loss = 20.44653 learning_Rate = 0.01000 rmse=0.98701 mae=0.77038\n",
      "<class 'data.RSContext'> iteration 60: loss = 4320.5653, delta_loss = 19.90026 learning_Rate = 0.01000 rmse=0.98709 mae=0.77034\n",
      "<class 'data.RSContext'> iteration 61: loss = 4301.1923, delta_loss = 19.37306 learning_Rate = 0.01000 rmse=0.98718 mae=0.77031\n",
      "<class 'data.RSContext'> iteration 62: loss = 4282.3280, delta_loss = 18.86429 learning_Rate = 0.01000 rmse=0.98726 mae=0.77028\n",
      "<class 'data.RSContext'> iteration 63: loss = 4263.9547, delta_loss = 18.37327 learning_Rate = 0.01000 rmse=0.98736 mae=0.77026\n",
      "<class 'data.RSContext'> iteration 64: loss = 4246.0553, delta_loss = 17.89937 learning_Rate = 0.01000 rmse=0.98747 mae=0.77023\n",
      "<class 'data.RSContext'> iteration 65: loss = 4228.6134, delta_loss = 17.44193 learning_Rate = 0.01000 rmse=0.98757 mae=0.77022\n",
      "<class 'data.RSContext'> iteration 66: loss = 4211.6131, delta_loss = 17.00032 learning_Rate = 0.01000 rmse=0.98767 mae=0.77021\n",
      "<class 'data.RSContext'> iteration 67: loss = 4195.0392, delta_loss = 16.57392 learning_Rate = 0.01000 rmse=0.98778 mae=0.77021\n",
      "<class 'data.RSContext'> iteration 68: loss = 4178.8770, delta_loss = 16.16213 learning_Rate = 0.01000 rmse=0.98790 mae=0.77022\n",
      "<class 'data.RSContext'> iteration 69: loss = 4163.1127, delta_loss = 15.76436 learning_Rate = 0.01000 rmse=0.98802 mae=0.77023\n",
      "<class 'data.RSContext'> iteration 70: loss = 4147.7326, delta_loss = 15.38005 learning_Rate = 0.01000 rmse=0.98814 mae=0.77024\n",
      "<class 'data.RSContext'> iteration 71: loss = 4132.7240, delta_loss = 15.00865 learning_Rate = 0.01000 rmse=0.98827 mae=0.77026\n",
      "<class 'data.RSContext'> iteration 72: loss = 4118.0743, delta_loss = 14.64965 learning_Rate = 0.01000 rmse=0.98840 mae=0.77029\n",
      "<class 'data.RSContext'> iteration 73: loss = 4103.7718, delta_loss = 14.30255 learning_Rate = 0.01000 rmse=0.98854 mae=0.77032\n",
      "<class 'data.RSContext'> iteration 74: loss = 4089.8049, delta_loss = 13.96685 learning_Rate = 0.01000 rmse=0.98868 mae=0.77036\n",
      "<class 'data.RSContext'> iteration 75: loss = 4076.1628, delta_loss = 13.64210 learning_Rate = 0.01000 rmse=0.98882 mae=0.77039\n",
      "<class 'data.RSContext'> iteration 76: loss = 4062.8350, delta_loss = 13.32786 learning_Rate = 0.01000 rmse=0.98896 mae=0.77042\n",
      "<class 'data.RSContext'> iteration 77: loss = 4049.8113, delta_loss = 13.02370 learning_Rate = 0.01000 rmse=0.98911 mae=0.77046\n",
      "<class 'data.RSContext'> iteration 78: loss = 4037.0821, delta_loss = 12.72921 learning_Rate = 0.01000 rmse=0.98926 mae=0.77050\n",
      "<class 'data.RSContext'> iteration 79: loss = 4024.6381, delta_loss = 12.44401 learning_Rate = 0.01000 rmse=0.98939 mae=0.77053\n",
      "<class 'data.RSContext'> iteration 80: loss = 4012.4703, delta_loss = 12.16773 learning_Rate = 0.01000 rmse=0.98954 mae=0.77057\n",
      "<class 'data.RSContext'> iteration 81: loss = 4000.5703, delta_loss = 11.90001 learning_Rate = 0.01000 rmse=0.98968 mae=0.77061\n",
      "<class 'data.RSContext'> iteration 82: loss = 3988.9298, delta_loss = 11.64051 learning_Rate = 0.01000 rmse=0.98983 mae=0.77066\n",
      "<class 'data.RSContext'> iteration 83: loss = 3977.5409, delta_loss = 11.38891 learning_Rate = 0.01000 rmse=0.98997 mae=0.77071\n",
      "<class 'data.RSContext'> iteration 84: loss = 3966.3960, delta_loss = 11.14490 learning_Rate = 0.01000 rmse=0.99012 mae=0.77076\n",
      "<class 'data.RSContext'> iteration 85: loss = 3955.4878, delta_loss = 10.90819 learning_Rate = 0.01000 rmse=0.99026 mae=0.77080\n",
      "<class 'data.RSContext'> iteration 86: loss = 3944.8093, delta_loss = 10.67849 learning_Rate = 0.01000 rmse=0.99041 mae=0.77085\n",
      "<class 'data.RSContext'> iteration 87: loss = 3934.3538, delta_loss = 10.45554 learning_Rate = 0.01000 rmse=0.99057 mae=0.77091\n",
      "<class 'data.RSContext'> iteration 88: loss = 3924.1147, delta_loss = 10.23908 learning_Rate = 0.01000 rmse=0.99072 mae=0.77096\n",
      "<class 'data.RSContext'> iteration 89: loss = 3914.0858, delta_loss = 10.02887 learning_Rate = 0.01000 rmse=0.99088 mae=0.77101\n",
      "<class 'data.RSContext'> iteration 90: loss = 3904.2612, delta_loss = 9.82468 learning_Rate = 0.01000 rmse=0.99103 mae=0.77107\n",
      "<class 'data.RSContext'> iteration 91: loss = 3894.6349, delta_loss = 9.62628 learning_Rate = 0.01000 rmse=0.99118 mae=0.77113\n",
      "<class 'data.RSContext'> iteration 92: loss = 3885.2014, delta_loss = 9.43347 learning_Rate = 0.01000 rmse=0.99134 mae=0.77118\n",
      "<class 'data.RSContext'> iteration 93: loss = 3875.9554, delta_loss = 9.24603 learning_Rate = 0.01000 rmse=0.99149 mae=0.77125\n",
      "<class 'data.RSContext'> iteration 94: loss = 3866.8916, delta_loss = 9.06379 learning_Rate = 0.01000 rmse=0.99166 mae=0.77132\n",
      "<class 'data.RSContext'> iteration 95: loss = 3858.0050, delta_loss = 8.88655 learning_Rate = 0.01000 rmse=0.99182 mae=0.77140\n",
      "<class 'data.RSContext'> iteration 96: loss = 3849.2909, delta_loss = 8.71414 learning_Rate = 0.01000 rmse=0.99199 mae=0.77147\n",
      "<class 'data.RSContext'> iteration 97: loss = 3840.7445, delta_loss = 8.54639 learning_Rate = 0.01000 rmse=0.99216 mae=0.77154\n",
      "<class 'data.RSContext'> iteration 98: loss = 3832.3614, delta_loss = 8.38314 learning_Rate = 0.01000 rmse=0.99233 mae=0.77162\n",
      "<class 'data.RSContext'> iteration 99: loss = 3824.1371, delta_loss = 8.22424 learning_Rate = 0.01000 rmse=0.99249 mae=0.77169\n",
      "<class 'data.RSContext'> iteration 100: loss = 3816.0676, delta_loss = 8.06955 learning_Rate = 0.01000 rmse=0.99266 mae=0.77175\n",
      "<class 'data.RSContext'> iteration 101: loss = 3808.1487, delta_loss = 7.91892 learning_Rate = 0.01000 rmse=0.99283 mae=0.77182\n",
      "<class 'data.RSContext'> iteration 102: loss = 3800.3765, delta_loss = 7.77221 learning_Rate = 0.01000 rmse=0.99300 mae=0.77190\n",
      "<class 'data.RSContext'> iteration 103: loss = 3792.7472, delta_loss = 7.62931 learning_Rate = 0.01000 rmse=0.99317 mae=0.77197\n",
      "<class 'data.RSContext'> iteration 104: loss = 3785.2571, delta_loss = 7.49008 learning_Rate = 0.01000 rmse=0.99335 mae=0.77205\n",
      "<class 'data.RSContext'> iteration 105: loss = 3777.9027, delta_loss = 7.35441 learning_Rate = 0.01000 rmse=0.99352 mae=0.77213\n",
      "<class 'data.RSContext'> iteration 106: loss = 3770.6805, delta_loss = 7.22218 learning_Rate = 0.01000 rmse=0.99371 mae=0.77221\n",
      "<class 'data.RSContext'> iteration 107: loss = 3763.5872, delta_loss = 7.09329 learning_Rate = 0.01000 rmse=0.99388 mae=0.77227\n",
      "<class 'data.RSContext'> iteration 108: loss = 3756.6196, delta_loss = 6.96763 learning_Rate = 0.01000 rmse=0.99405 mae=0.77235\n",
      "<class 'data.RSContext'> iteration 109: loss = 3749.7745, delta_loss = 6.84510 learning_Rate = 0.01000 rmse=0.99423 mae=0.77243\n",
      "<class 'data.RSContext'> iteration 110: loss = 3743.0489, delta_loss = 6.72561 learning_Rate = 0.01000 rmse=0.99441 mae=0.77251\n",
      "<class 'data.RSContext'> iteration 111: loss = 3736.4398, delta_loss = 6.60906 learning_Rate = 0.01000 rmse=0.99459 mae=0.77259\n",
      "<class 'data.RSContext'> iteration 112: loss = 3729.9444, delta_loss = 6.49535 learning_Rate = 0.01000 rmse=0.99477 mae=0.77266\n",
      "<class 'data.RSContext'> iteration 113: loss = 3723.5600, delta_loss = 6.38441 learning_Rate = 0.01000 rmse=0.99494 mae=0.77274\n",
      "<class 'data.RSContext'> iteration 114: loss = 3717.2839, delta_loss = 6.27616 learning_Rate = 0.01000 rmse=0.99512 mae=0.77281\n",
      "<class 'data.RSContext'> iteration 115: loss = 3711.1134, delta_loss = 6.17050 learning_Rate = 0.01000 rmse=0.99530 mae=0.77288\n",
      "<class 'data.RSContext'> iteration 116: loss = 3705.0460, delta_loss = 6.06737 learning_Rate = 0.01000 rmse=0.99547 mae=0.77295\n",
      "<class 'data.RSContext'> iteration 117: loss = 3699.0793, delta_loss = 5.96669 learning_Rate = 0.01000 rmse=0.99565 mae=0.77302\n",
      "<class 'data.RSContext'> iteration 118: loss = 3693.2109, delta_loss = 5.86839 learning_Rate = 0.01000 rmse=0.99583 mae=0.77309\n",
      "<class 'data.RSContext'> iteration 119: loss = 3687.4385, delta_loss = 5.77239 learning_Rate = 0.01000 rmse=0.99600 mae=0.77315\n",
      "<class 'data.RSContext'> iteration 120: loss = 3681.7599, delta_loss = 5.67864 learning_Rate = 0.01000 rmse=0.99618 mae=0.77322\n",
      "<class 'data.RSContext'> iteration 121: loss = 3676.1728, delta_loss = 5.58706 learning_Rate = 0.01000 rmse=0.99635 mae=0.77329\n",
      "<class 'data.RSContext'> iteration 122: loss = 3670.6752, delta_loss = 5.49760 learning_Rate = 0.01000 rmse=0.99652 mae=0.77335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'data.RSContext'> iteration 123: loss = 3665.2650, delta_loss = 5.41019 learning_Rate = 0.01000 rmse=0.99669 mae=0.77342\n",
      "<class 'data.RSContext'> iteration 124: loss = 3659.9403, delta_loss = 5.32477 learning_Rate = 0.01000 rmse=0.99686 mae=0.77349\n",
      "<class 'data.RSContext'> iteration 125: loss = 3654.6990, delta_loss = 5.24130 learning_Rate = 0.01000 rmse=0.99702 mae=0.77356\n",
      "<class 'data.RSContext'> iteration 126: loss = 3649.5393, delta_loss = 5.15970 learning_Rate = 0.01000 rmse=0.99718 mae=0.77362\n",
      "<class 'data.RSContext'> iteration 127: loss = 3644.4593, delta_loss = 5.07994 learning_Rate = 0.01000 rmse=0.99734 mae=0.77369\n",
      "<class 'data.RSContext'> iteration 128: loss = 3639.4574, delta_loss = 5.00196 learning_Rate = 0.01000 rmse=0.99751 mae=0.77376\n",
      "<class 'data.RSContext'> iteration 129: loss = 3634.5317, delta_loss = 4.92571 learning_Rate = 0.01000 rmse=0.99767 mae=0.77383\n",
      "<class 'data.RSContext'> iteration 130: loss = 3629.6805, delta_loss = 4.85114 learning_Rate = 0.01000 rmse=0.99783 mae=0.77390\n",
      "<class 'data.RSContext'> iteration 131: loss = 3624.9023, delta_loss = 4.77821 learning_Rate = 0.01000 rmse=0.99800 mae=0.77398\n",
      "<class 'data.RSContext'> iteration 132: loss = 3620.1954, delta_loss = 4.70687 learning_Rate = 0.01000 rmse=0.99816 mae=0.77406\n",
      "<class 'data.RSContext'> iteration 133: loss = 3615.5584, delta_loss = 4.63708 learning_Rate = 0.01000 rmse=0.99832 mae=0.77413\n",
      "<class 'data.RSContext'> iteration 134: loss = 3610.9896, delta_loss = 4.56879 learning_Rate = 0.01000 rmse=0.99848 mae=0.77421\n",
      "<class 'data.RSContext'> iteration 135: loss = 3606.4876, delta_loss = 4.50197 learning_Rate = 0.01000 rmse=0.99864 mae=0.77428\n",
      "<class 'data.RSContext'> iteration 136: loss = 3602.0510, delta_loss = 4.43658 learning_Rate = 0.01000 rmse=0.99881 mae=0.77435\n",
      "<class 'data.RSContext'> iteration 137: loss = 3597.6785, delta_loss = 4.37257 learning_Rate = 0.01000 rmse=0.99896 mae=0.77443\n",
      "<class 'data.RSContext'> iteration 138: loss = 3593.3685, delta_loss = 4.30991 learning_Rate = 0.01000 rmse=0.99912 mae=0.77451\n",
      "<class 'data.RSContext'> iteration 139: loss = 3589.1200, delta_loss = 4.24857 learning_Rate = 0.01000 rmse=0.99928 mae=0.77458\n",
      "<class 'data.RSContext'> iteration 140: loss = 3584.9315, delta_loss = 4.18851 learning_Rate = 0.01000 rmse=0.99944 mae=0.77466\n",
      "<class 'data.RSContext'> iteration 141: loss = 3580.8018, delta_loss = 4.12970 learning_Rate = 0.01000 rmse=0.99960 mae=0.77473\n",
      "<class 'data.RSContext'> iteration 142: loss = 3576.7297, delta_loss = 4.07210 learning_Rate = 0.01000 rmse=0.99975 mae=0.77480\n",
      "<class 'data.RSContext'> iteration 143: loss = 3572.7140, delta_loss = 4.01568 learning_Rate = 0.01000 rmse=0.99991 mae=0.77488\n",
      "<class 'data.RSContext'> iteration 144: loss = 3568.7536, delta_loss = 3.96042 learning_Rate = 0.01000 rmse=1.00006 mae=0.77495\n",
      "<class 'data.RSContext'> iteration 145: loss = 3564.8473, delta_loss = 3.90628 learning_Rate = 0.01000 rmse=1.00022 mae=0.77502\n",
      "<class 'data.RSContext'> iteration 146: loss = 3560.9940, delta_loss = 3.85323 learning_Rate = 0.01000 rmse=1.00038 mae=0.77509\n",
      "<class 'data.RSContext'> iteration 147: loss = 3557.1928, delta_loss = 3.80125 learning_Rate = 0.01000 rmse=1.00053 mae=0.77516\n",
      "<class 'data.RSContext'> iteration 148: loss = 3553.4425, delta_loss = 3.75031 learning_Rate = 0.01000 rmse=1.00068 mae=0.77524\n",
      "<class 'data.RSContext'> iteration 149: loss = 3549.7421, delta_loss = 3.70038 learning_Rate = 0.01000 rmse=1.00084 mae=0.77532\n",
      "<class 'data.RSContext'> iteration 150: loss = 3546.0907, delta_loss = 3.65144 learning_Rate = 0.01000 rmse=1.00099 mae=0.77539\n",
      "<class 'data.RSContext'> iteration 151: loss = 3542.4872, delta_loss = 3.60346 learning_Rate = 0.01000 rmse=1.00114 mae=0.77547\n",
      "<class 'data.RSContext'> iteration 152: loss = 3538.9308, delta_loss = 3.55642 learning_Rate = 0.01000 rmse=1.00130 mae=0.77554\n",
      "<class 'data.RSContext'> iteration 153: loss = 3535.4205, delta_loss = 3.51029 learning_Rate = 0.01000 rmse=1.00145 mae=0.77562\n",
      "<class 'data.RSContext'> iteration 154: loss = 3531.9554, delta_loss = 3.46506 learning_Rate = 0.01000 rmse=1.00160 mae=0.77570\n",
      "<class 'data.RSContext'> iteration 155: loss = 3528.5347, delta_loss = 3.42070 learning_Rate = 0.01000 rmse=1.00176 mae=0.77578\n",
      "<class 'data.RSContext'> iteration 156: loss = 3525.1575, delta_loss = 3.37719 learning_Rate = 0.01000 rmse=1.00191 mae=0.77586\n",
      "<class 'data.RSContext'> iteration 157: loss = 3521.8230, delta_loss = 3.33451 learning_Rate = 0.01000 rmse=1.00206 mae=0.77594\n",
      "<class 'data.RSContext'> iteration 158: loss = 3518.5304, delta_loss = 3.29264 learning_Rate = 0.01000 rmse=1.00221 mae=0.77602\n",
      "<class 'data.RSContext'> iteration 159: loss = 3515.2788, delta_loss = 3.25156 learning_Rate = 0.01000 rmse=1.00236 mae=0.77610\n",
      "<class 'data.RSContext'> iteration 160: loss = 3512.0676, delta_loss = 3.21125 learning_Rate = 0.01000 rmse=1.00251 mae=0.77618\n",
      "current best rmse is 1.00251, mae is 0.77618\n"
     ]
    }
   ],
   "source": [
    "from SVDpp import *\n",
    "svdpp = SVDPP()\n",
    "RS = run_func(init_model=svdpp.init_model,train_model=svdpp.train_model,predict=svdpp.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- recall rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.009711167843019472,\n",
       " 0.06532512389247634,\n",
       " 0.133053010962607,\n",
       " 0.193672723632177,\n",
       " 0.25093857936627123,\n",
       " 0.3025479301196376,\n",
       " 0.3497522150473044]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc_list_svd=[]\n",
    "for num in [10,50,100,150,200,250,300]:\n",
    "    rc = recall_svd(RS,num)\n",
    "    rc_list_svd.append(rc)\n",
    "rc_list_svd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- precision rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.020572640509013786,\n",
       " 0.02767762460233298,\n",
       " 0.028186638388123013,\n",
       " 0.02735242135030046,\n",
       " 0.026580063626723223,\n",
       " 0.025637327677624604,\n",
       " 0.024697773064687168]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preci_list_svd=[]\n",
    "for num in [10,50,100,150,200,250,300]:\n",
    "    preci = precision_svd(RS,num)\n",
    "    preci_list_svd.append(preci)\n",
    "preci_list_svd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### with fixed other parameters and then change number of factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- recall rate and precision rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80023\n",
      "19977\n",
      "cold start users count 0\n",
      "{\n",
      "    'dataset_name': 'u',\n",
      "    'k_fold_num': 5,\n",
      "    'k_test': 0,\n",
      "    'rating_path': 'Z:/RSA/data/u_ratings.txt',\n",
      "    'rating_cv_path': 'Z:/RSA/data/cv/',\n",
      "    'trust_path': 'Z:/RSA/data/u_trust.txt',\n",
      "    'sep': ' ',\n",
      "    'random_state': 0,\n",
      "    'size': 0.8,\n",
      "    'min_val': 0.5,\n",
      "    'max_val': 4.0,\n",
      "    'coldUserRating': 5,\n",
      "    'factor': 10,\n",
      "    'threshold': 0.0001,\n",
      "    'lr': 0.01,\n",
      "    'maxIter': 100,\n",
      "    'lambdaP': 0.001,\n",
      "    'lambdaQ': 0.001,\n",
      "    'gamma': 0,\n",
      "    'isEarlyStopping': False,\n",
      "    'result_path': '../results/',\n",
      "    'model_path': 'model/',\n",
      "    'result_log_path': 'log/'\n",
      "}\n",
      "80023\n",
      "19977\n",
      "cold start users count 0\n",
      "80023\n",
      "19977\n",
      "cold start users count 0\n",
      "<class 'data.RSContext'> iteration 1: loss = 33238.4053, delta_loss = -33238.40526 learning_Rate = 0.01000 rmse=1.11850 mae=0.87399\n",
      "<class 'data.RSContext'> iteration 2: loss = 7820.2714, delta_loss = 25418.13385 learning_Rate = 0.01000 rmse=1.02146 mae=0.79706\n",
      "<class 'data.RSContext'> iteration 3: loss = 6745.4756, delta_loss = 1074.79585 learning_Rate = 0.01000 rmse=1.00409 mae=0.78462\n",
      "<class 'data.RSContext'> iteration 4: loss = 6455.4639, delta_loss = 290.01162 learning_Rate = 0.01000 rmse=0.99866 mae=0.78136\n",
      "<class 'data.RSContext'> iteration 5: loss = 6311.9624, delta_loss = 143.50152 learning_Rate = 0.01000 rmse=0.99601 mae=0.78014\n",
      "<class 'data.RSContext'> iteration 6: loss = 6217.5419, delta_loss = 94.42055 learning_Rate = 0.01000 rmse=0.99417 mae=0.77927\n",
      "<class 'data.RSContext'> iteration 7: loss = 6145.5579, delta_loss = 71.98397 learning_Rate = 0.01000 rmse=0.99298 mae=0.77863\n",
      "<class 'data.RSContext'> iteration 8: loss = 6085.7093, delta_loss = 59.84861 learning_Rate = 0.01000 rmse=0.99219 mae=0.77821\n",
      "<class 'data.RSContext'> iteration 9: loss = 6032.9891, delta_loss = 52.72016 learning_Rate = 0.01000 rmse=0.99151 mae=0.77790\n",
      "<class 'data.RSContext'> iteration 10: loss = 5984.5695, delta_loss = 48.41968 learning_Rate = 0.01000 rmse=0.99099 mae=0.77765\n",
      "<class 'data.RSContext'> iteration 11: loss = 5938.6804, delta_loss = 45.88905 learning_Rate = 0.01000 rmse=0.99058 mae=0.77745\n",
      "<class 'data.RSContext'> iteration 12: loss = 5894.1276, delta_loss = 44.55281 learning_Rate = 0.01000 rmse=0.99026 mae=0.77731\n",
      "<class 'data.RSContext'> iteration 13: loss = 5850.0562, delta_loss = 44.07138 learning_Rate = 0.01000 rmse=0.98997 mae=0.77718\n",
      "<class 'data.RSContext'> iteration 14: loss = 5805.8255, delta_loss = 44.23075 learning_Rate = 0.01000 rmse=0.98973 mae=0.77705\n",
      "<class 'data.RSContext'> iteration 15: loss = 5760.9381, delta_loss = 44.88742 learning_Rate = 0.01000 rmse=0.98951 mae=0.77691\n",
      "<class 'data.RSContext'> iteration 16: loss = 5714.9995, delta_loss = 45.93851 learning_Rate = 0.01000 rmse=0.98931 mae=0.77676\n",
      "<class 'data.RSContext'> iteration 17: loss = 5667.6951, delta_loss = 47.30443 learning_Rate = 0.01000 rmse=0.98910 mae=0.77660\n",
      "<class 'data.RSContext'> iteration 18: loss = 5618.7767, delta_loss = 48.91838 learning_Rate = 0.01000 rmse=0.98891 mae=0.77644\n",
      "<class 'data.RSContext'> iteration 19: loss = 5568.0570, delta_loss = 50.71975 learning_Rate = 0.01000 rmse=0.98874 mae=0.77630\n",
      "<class 'data.RSContext'> iteration 20: loss = 5515.4068, delta_loss = 52.65017 learning_Rate = 0.01000 rmse=0.98857 mae=0.77614\n",
      "<class 'data.RSContext'> iteration 21: loss = 5460.7556, delta_loss = 54.65122 learning_Rate = 0.01000 rmse=0.98843 mae=0.77598\n",
      "<class 'data.RSContext'> iteration 22: loss = 5404.0919, delta_loss = 56.66367 learning_Rate = 0.01000 rmse=0.98830 mae=0.77582\n",
      "<class 'data.RSContext'> iteration 23: loss = 5345.4640, delta_loss = 58.62790 learning_Rate = 0.01000 rmse=0.98817 mae=0.77563\n",
      "<class 'data.RSContext'> iteration 24: loss = 5284.9788, delta_loss = 60.48520 learning_Rate = 0.01000 rmse=0.98804 mae=0.77541\n",
      "<class 'data.RSContext'> iteration 25: loss = 5222.7989, delta_loss = 62.17992 learning_Rate = 0.01000 rmse=0.98793 mae=0.77517\n",
      "<class 'data.RSContext'> iteration 26: loss = 5159.1369, delta_loss = 63.66197 learning_Rate = 0.01000 rmse=0.98782 mae=0.77494\n",
      "<class 'data.RSContext'> iteration 27: loss = 5094.2476, delta_loss = 64.88934 learning_Rate = 0.01000 rmse=0.98773 mae=0.77472\n",
      "<class 'data.RSContext'> iteration 28: loss = 5028.4173, delta_loss = 65.83024 learning_Rate = 0.01000 rmse=0.98765 mae=0.77451\n",
      "<class 'data.RSContext'> iteration 29: loss = 4961.9527, delta_loss = 66.46462 learning_Rate = 0.01000 rmse=0.98761 mae=0.77430\n",
      "<class 'data.RSContext'> iteration 30: loss = 4895.1681, delta_loss = 66.78462 learning_Rate = 0.01000 rmse=0.98761 mae=0.77410\n",
      "<class 'data.RSContext'> iteration 31: loss = 4828.3739, delta_loss = 66.79417 learning_Rate = 0.01000 rmse=0.98763 mae=0.77390\n",
      "<class 'data.RSContext'> iteration 32: loss = 4761.8662, delta_loss = 66.50769 learning_Rate = 0.01000 rmse=0.98768 mae=0.77372\n",
      "<class 'data.RSContext'> iteration 33: loss = 4695.9181, delta_loss = 65.94812 learning_Rate = 0.01000 rmse=0.98777 mae=0.77358\n",
      "<class 'data.RSContext'> iteration 34: loss = 4630.7735, delta_loss = 65.14463 learning_Rate = 0.01000 rmse=0.98792 mae=0.77348\n",
      "<class 'data.RSContext'> iteration 35: loss = 4566.6432, delta_loss = 64.13024 learning_Rate = 0.01000 rmse=0.98812 mae=0.77344\n",
      "<class 'data.RSContext'> iteration 36: loss = 4503.7037, delta_loss = 62.93953 learning_Rate = 0.01000 rmse=0.98834 mae=0.77340\n",
      "<class 'data.RSContext'> iteration 37: loss = 4442.0969, delta_loss = 61.60680 learning_Rate = 0.01000 rmse=0.98860 mae=0.77338\n",
      "<class 'data.RSContext'> iteration 38: loss = 4381.9324, delta_loss = 60.16448 learning_Rate = 0.01000 rmse=0.98891 mae=0.77341\n",
      "<class 'data.RSContext'> iteration 39: loss = 4323.2903, delta_loss = 58.64213 learning_Rate = 0.01000 rmse=0.98927 mae=0.77348\n",
      "<class 'data.RSContext'> iteration 40: loss = 4266.2245, delta_loss = 57.06582 learning_Rate = 0.01000 rmse=0.98969 mae=0.77361\n",
      "<class 'data.RSContext'> iteration 41: loss = 4210.7666, delta_loss = 55.45787 learning_Rate = 0.01000 rmse=0.99017 mae=0.77379\n",
      "<class 'data.RSContext'> iteration 42: loss = 4156.9297, delta_loss = 53.83690 learning_Rate = 0.01000 rmse=0.99069 mae=0.77401\n",
      "<class 'data.RSContext'> iteration 43: loss = 4104.7116, delta_loss = 52.21811 learning_Rate = 0.01000 rmse=0.99126 mae=0.77426\n",
      "<class 'data.RSContext'> iteration 44: loss = 4054.0980, delta_loss = 50.61362 learning_Rate = 0.01000 rmse=0.99186 mae=0.77453\n",
      "<class 'data.RSContext'> iteration 45: loss = 4005.0651, delta_loss = 49.03290 learning_Rate = 0.01000 rmse=0.99252 mae=0.77484\n",
      "<class 'data.RSContext'> iteration 46: loss = 3957.5819, delta_loss = 47.48319 learning_Rate = 0.01000 rmse=0.99320 mae=0.77513\n",
      "<class 'data.RSContext'> iteration 47: loss = 3911.6120, delta_loss = 45.96988 learning_Rate = 0.01000 rmse=0.99390 mae=0.77544\n",
      "<class 'data.RSContext'> iteration 48: loss = 3867.1151, delta_loss = 44.49686 learning_Rate = 0.01000 rmse=0.99463 mae=0.77579\n",
      "<class 'data.RSContext'> iteration 49: loss = 3824.0483, delta_loss = 43.06685 learning_Rate = 0.01000 rmse=0.99539 mae=0.77616\n",
      "<class 'data.RSContext'> iteration 50: loss = 3782.3667, delta_loss = 41.68156 learning_Rate = 0.01000 rmse=0.99619 mae=0.77656\n",
      "<class 'data.RSContext'> iteration 51: loss = 3742.0248, delta_loss = 40.34197 learning_Rate = 0.01000 rmse=0.99700 mae=0.77700\n",
      "<class 'data.RSContext'> iteration 52: loss = 3702.9763, delta_loss = 39.04847 learning_Rate = 0.01000 rmse=0.99783 mae=0.77746\n",
      "<class 'data.RSContext'> iteration 53: loss = 3665.1754, delta_loss = 37.80094 learning_Rate = 0.01000 rmse=0.99867 mae=0.77794\n",
      "<class 'data.RSContext'> iteration 54: loss = 3628.5764, delta_loss = 36.59893 learning_Rate = 0.01000 rmse=0.99949 mae=0.77840\n",
      "<class 'data.RSContext'> iteration 55: loss = 3593.1347, delta_loss = 35.44169 learning_Rate = 0.01000 rmse=1.00033 mae=0.77888\n",
      "<class 'data.RSContext'> iteration 56: loss = 3558.8065, delta_loss = 34.32826 learning_Rate = 0.01000 rmse=1.00115 mae=0.77937\n",
      "<class 'data.RSContext'> iteration 57: loss = 3525.5490, delta_loss = 33.25752 learning_Rate = 0.01000 rmse=1.00197 mae=0.77986\n",
      "<class 'data.RSContext'> iteration 58: loss = 3493.3207, delta_loss = 32.22824 learning_Rate = 0.01000 rmse=1.00278 mae=0.78035\n",
      "<class 'data.RSContext'> iteration 59: loss = 3462.0816, delta_loss = 31.23908 learning_Rate = 0.01000 rmse=1.00360 mae=0.78085\n",
      "<class 'data.RSContext'> iteration 60: loss = 3431.7930, delta_loss = 30.28868 learning_Rate = 0.01000 rmse=1.00440 mae=0.78135\n",
      "<class 'data.RSContext'> iteration 61: loss = 3402.4173, delta_loss = 29.37564 learning_Rate = 0.01000 rmse=1.00520 mae=0.78184\n",
      "<class 'data.RSContext'> iteration 62: loss = 3373.9188, delta_loss = 28.49852 learning_Rate = 0.01000 rmse=1.00599 mae=0.78233\n",
      "<class 'data.RSContext'> iteration 63: loss = 3346.2629, delta_loss = 27.65593 learning_Rate = 0.01000 rmse=1.00677 mae=0.78282\n",
      "<class 'data.RSContext'> iteration 64: loss = 3319.4164, delta_loss = 26.84644 learning_Rate = 0.01000 rmse=1.00756 mae=0.78331\n",
      "<class 'data.RSContext'> iteration 65: loss = 3293.3477, delta_loss = 26.06869 learning_Rate = 0.01000 rmse=1.00833 mae=0.78380\n",
      "<class 'data.RSContext'> iteration 66: loss = 3268.0264, delta_loss = 25.32132 learning_Rate = 0.01000 rmse=1.00909 mae=0.78429\n",
      "<class 'data.RSContext'> iteration 67: loss = 3243.4234, delta_loss = 24.60301 learning_Rate = 0.01000 rmse=1.00985 mae=0.78477\n",
      "<class 'data.RSContext'> iteration 68: loss = 3219.5109, delta_loss = 23.91249 learning_Rate = 0.01000 rmse=1.01060 mae=0.78524\n",
      "<class 'data.RSContext'> iteration 69: loss = 3196.2624, delta_loss = 23.24852 learning_Rate = 0.01000 rmse=1.01135 mae=0.78571\n",
      "<class 'data.RSContext'> iteration 70: loss = 3173.6525, delta_loss = 22.60991 learning_Rate = 0.01000 rmse=1.01209 mae=0.78618\n",
      "<class 'data.RSContext'> iteration 71: loss = 3151.6570, delta_loss = 21.99551 learning_Rate = 0.01000 rmse=1.01283 mae=0.78665\n",
      "<class 'data.RSContext'> iteration 72: loss = 3130.2527, delta_loss = 21.40423 learning_Rate = 0.01000 rmse=1.01355 mae=0.78711\n",
      "<class 'data.RSContext'> iteration 73: loss = 3109.4177, delta_loss = 20.83501 learning_Rate = 0.01000 rmse=1.01426 mae=0.78757\n",
      "<class 'data.RSContext'> iteration 74: loss = 3089.1309, delta_loss = 20.28684 learning_Rate = 0.01000 rmse=1.01497 mae=0.78801\n",
      "<class 'data.RSContext'> iteration 75: loss = 3069.3721, delta_loss = 19.75878 learning_Rate = 0.01000 rmse=1.01567 mae=0.78847\n",
      "<class 'data.RSContext'> iteration 76: loss = 3050.1222, delta_loss = 19.24989 learning_Rate = 0.01000 rmse=1.01636 mae=0.78890\n",
      "<class 'data.RSContext'> iteration 77: loss = 3031.3629, delta_loss = 18.75932 learning_Rate = 0.01000 rmse=1.01704 mae=0.78934\n",
      "<class 'data.RSContext'> iteration 78: loss = 3013.0767, delta_loss = 18.28622 learning_Rate = 0.01000 rmse=1.01771 mae=0.78978\n",
      "<class 'data.RSContext'> iteration 79: loss = 2995.2468, delta_loss = 17.82983 learning_Rate = 0.01000 rmse=1.01837 mae=0.79021\n",
      "<class 'data.RSContext'> iteration 80: loss = 2977.8575, delta_loss = 17.38938 learning_Rate = 0.01000 rmse=1.01902 mae=0.79063\n",
      "<class 'data.RSContext'> iteration 81: loss = 2960.8933, delta_loss = 16.96418 learning_Rate = 0.01000 rmse=1.01966 mae=0.79105\n",
      "<class 'data.RSContext'> iteration 82: loss = 2944.3397, delta_loss = 16.55354 learning_Rate = 0.01000 rmse=1.02029 mae=0.79146\n",
      "<class 'data.RSContext'> iteration 83: loss = 2928.1829, delta_loss = 16.15683 learning_Rate = 0.01000 rmse=1.02091 mae=0.79186\n",
      "<class 'data.RSContext'> iteration 84: loss = 2912.4095, delta_loss = 15.77346 learning_Rate = 0.01000 rmse=1.02152 mae=0.79225\n",
      "<class 'data.RSContext'> iteration 85: loss = 2897.0066, delta_loss = 15.40284 learning_Rate = 0.01000 rmse=1.02212 mae=0.79264\n",
      "<class 'data.RSContext'> iteration 86: loss = 2881.9622, delta_loss = 15.04443 learning_Rate = 0.01000 rmse=1.02271 mae=0.79303\n",
      "<class 'data.RSContext'> iteration 87: loss = 2867.2644, delta_loss = 14.69773 learning_Rate = 0.01000 rmse=1.02329 mae=0.79341\n",
      "<class 'data.RSContext'> iteration 88: loss = 2852.9022, delta_loss = 14.36224 learning_Rate = 0.01000 rmse=1.02386 mae=0.79380\n",
      "<class 'data.RSContext'> iteration 89: loss = 2838.8647, delta_loss = 14.03751 learning_Rate = 0.01000 rmse=1.02444 mae=0.79418\n",
      "<class 'data.RSContext'> iteration 90: loss = 2825.1416, delta_loss = 13.72309 learning_Rate = 0.01000 rmse=1.02500 mae=0.79455\n",
      "<class 'data.RSContext'> iteration 91: loss = 2811.7230, delta_loss = 13.41857 learning_Rate = 0.01000 rmse=1.02556 mae=0.79492\n",
      "<class 'data.RSContext'> iteration 92: loss = 2798.5995, delta_loss = 13.12356 learning_Rate = 0.01000 rmse=1.02610 mae=0.79528\n",
      "<class 'data.RSContext'> iteration 93: loss = 2785.7618, delta_loss = 12.83767 learning_Rate = 0.01000 rmse=1.02663 mae=0.79564\n",
      "<class 'data.RSContext'> iteration 94: loss = 2773.2012, delta_loss = 12.56057 learning_Rate = 0.01000 rmse=1.02716 mae=0.79600\n",
      "<class 'data.RSContext'> iteration 95: loss = 2760.9093, delta_loss = 12.29191 learning_Rate = 0.01000 rmse=1.02769 mae=0.79635\n",
      "<class 'data.RSContext'> iteration 96: loss = 2748.8780, delta_loss = 12.03136 learning_Rate = 0.01000 rmse=1.02820 mae=0.79670\n",
      "<class 'data.RSContext'> iteration 97: loss = 2737.0994, delta_loss = 11.77862 learning_Rate = 0.01000 rmse=1.02871 mae=0.79703\n",
      "<class 'data.RSContext'> iteration 98: loss = 2725.5660, delta_loss = 11.53340 learning_Rate = 0.01000 rmse=1.02921 mae=0.79737\n",
      "<class 'data.RSContext'> iteration 99: loss = 2714.2706, delta_loss = 11.29542 learning_Rate = 0.01000 rmse=1.02971 mae=0.79770\n",
      "<class 'data.RSContext'> iteration 100: loss = 2703.2061, delta_loss = 11.06441 learning_Rate = 0.01000 rmse=1.03020 mae=0.79804\n",
      "<class 'data.RSContext'> iteration 101: loss = 2692.3660, delta_loss = 10.84013 learning_Rate = 0.01000 rmse=1.03069 mae=0.79837\n",
      "<class 'data.RSContext'> iteration 102: loss = 2681.7437, delta_loss = 10.62232 learning_Rate = 0.01000 rmse=1.03117 mae=0.79870\n",
      "<class 'data.RSContext'> iteration 103: loss = 2671.3329, delta_loss = 10.41076 learning_Rate = 0.01000 rmse=1.03164 mae=0.79902\n",
      "<class 'data.RSContext'> iteration 104: loss = 2661.1277, delta_loss = 10.20523 learning_Rate = 0.01000 rmse=1.03211 mae=0.79933\n",
      "<class 'data.RSContext'> iteration 105: loss = 2651.1222, delta_loss = 10.00551 learning_Rate = 0.01000 rmse=1.03257 mae=0.79964\n",
      "<class 'data.RSContext'> iteration 106: loss = 2641.3108, delta_loss = 9.81141 learning_Rate = 0.01000 rmse=1.03301 mae=0.79994\n",
      "<class 'data.RSContext'> iteration 107: loss = 2631.6881, delta_loss = 9.62272 learning_Rate = 0.01000 rmse=1.03346 mae=0.80023\n",
      "<class 'data.RSContext'> iteration 108: loss = 2622.2488, delta_loss = 9.43926 learning_Rate = 0.01000 rmse=1.03389 mae=0.80053\n",
      "<class 'data.RSContext'> iteration 109: loss = 2612.9879, delta_loss = 9.26086 learning_Rate = 0.01000 rmse=1.03432 mae=0.80081\n",
      "<class 'data.RSContext'> iteration 110: loss = 2603.9006, delta_loss = 9.08733 learning_Rate = 0.01000 rmse=1.03475 mae=0.80110\n",
      "<class 'data.RSContext'> iteration 111: loss = 2594.9821, delta_loss = 8.91852 learning_Rate = 0.01000 rmse=1.03517 mae=0.80137\n",
      "<class 'data.RSContext'> iteration 112: loss = 2586.2278, delta_loss = 8.75427 learning_Rate = 0.01000 rmse=1.03559 mae=0.80165\n",
      "<class 'data.RSContext'> iteration 113: loss = 2577.6334, delta_loss = 8.59442 learning_Rate = 0.01000 rmse=1.03600 mae=0.80193\n",
      "<class 'data.RSContext'> iteration 114: loss = 2569.1946, delta_loss = 8.43883 learning_Rate = 0.01000 rmse=1.03641 mae=0.80221\n",
      "<class 'data.RSContext'> iteration 115: loss = 2560.9072, delta_loss = 8.28735 learning_Rate = 0.01000 rmse=1.03681 mae=0.80248\n",
      "<class 'data.RSContext'> iteration 116: loss = 2552.7674, delta_loss = 8.13986 learning_Rate = 0.01000 rmse=1.03721 mae=0.80275\n",
      "<class 'data.RSContext'> iteration 117: loss = 2544.7711, delta_loss = 7.99623 learning_Rate = 0.01000 rmse=1.03761 mae=0.80303\n",
      "<class 'data.RSContext'> iteration 118: loss = 2536.9148, delta_loss = 7.85631 learning_Rate = 0.01000 rmse=1.03800 mae=0.80330\n",
      "<class 'data.RSContext'> iteration 119: loss = 2529.1948, delta_loss = 7.72001 learning_Rate = 0.01000 rmse=1.03838 mae=0.80356\n",
      "<class 'data.RSContext'> iteration 120: loss = 2521.6076, delta_loss = 7.58719 learning_Rate = 0.01000 rmse=1.03876 mae=0.80382\n",
      "<class 'data.RSContext'> iteration 121: loss = 2514.1499, delta_loss = 7.45775 learning_Rate = 0.01000 rmse=1.03915 mae=0.80408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'data.RSContext'> iteration 122: loss = 2506.8183, delta_loss = 7.33158 learning_Rate = 0.01000 rmse=1.03952 mae=0.80433\n",
      "<class 'data.RSContext'> iteration 123: loss = 2499.6097, delta_loss = 7.20858 learning_Rate = 0.01000 rmse=1.03990 mae=0.80459\n",
      "<class 'data.RSContext'> iteration 124: loss = 2492.5211, delta_loss = 7.08864 learning_Rate = 0.01000 rmse=1.04026 mae=0.80483\n",
      "<class 'data.RSContext'> iteration 125: loss = 2485.5494, delta_loss = 6.97167 learning_Rate = 0.01000 rmse=1.04062 mae=0.80508\n",
      "<class 'data.RSContext'> iteration 126: loss = 2478.6918, delta_loss = 6.85758 learning_Rate = 0.01000 rmse=1.04099 mae=0.80532\n",
      "<class 'data.RSContext'> iteration 127: loss = 2471.9456, delta_loss = 6.74627 learning_Rate = 0.01000 rmse=1.04134 mae=0.80556\n",
      "<class 'data.RSContext'> iteration 128: loss = 2465.3079, delta_loss = 6.63766 learning_Rate = 0.01000 rmse=1.04170 mae=0.80581\n",
      "<class 'data.RSContext'> iteration 129: loss = 2458.7762, delta_loss = 6.53167 learning_Rate = 0.01000 rmse=1.04205 mae=0.80604\n",
      "<class 'data.RSContext'> iteration 130: loss = 2452.3480, delta_loss = 6.42821 learning_Rate = 0.01000 rmse=1.04239 mae=0.80628\n",
      "<class 'data.RSContext'> iteration 131: loss = 2446.0208, delta_loss = 6.32720 learning_Rate = 0.01000 rmse=1.04273 mae=0.80651\n",
      "<class 'data.RSContext'> iteration 132: loss = 2439.7922, delta_loss = 6.22858 learning_Rate = 0.01000 rmse=1.04307 mae=0.80676\n",
      "<class 'data.RSContext'> iteration 133: loss = 2433.6600, delta_loss = 6.13228 learning_Rate = 0.01000 rmse=1.04340 mae=0.80699\n",
      "<class 'data.RSContext'> iteration 134: loss = 2427.6218, delta_loss = 6.03821 learning_Rate = 0.01000 rmse=1.04373 mae=0.80722\n",
      "<class 'data.RSContext'> iteration 135: loss = 2421.6754, delta_loss = 5.94631 learning_Rate = 0.01000 rmse=1.04406 mae=0.80745\n",
      "<class 'data.RSContext'> iteration 136: loss = 2415.8189, delta_loss = 5.85652 learning_Rate = 0.01000 rmse=1.04439 mae=0.80768\n",
      "<class 'data.RSContext'> iteration 137: loss = 2410.0502, delta_loss = 5.76877 learning_Rate = 0.01000 rmse=1.04472 mae=0.80790\n",
      "<class 'data.RSContext'> iteration 138: loss = 2404.3671, delta_loss = 5.68301 learning_Rate = 0.01000 rmse=1.04504 mae=0.80813\n",
      "<class 'data.RSContext'> iteration 139: loss = 2398.7680, delta_loss = 5.59918 learning_Rate = 0.01000 rmse=1.04536 mae=0.80835\n",
      "<class 'data.RSContext'> iteration 140: loss = 2393.2508, delta_loss = 5.51721 learning_Rate = 0.01000 rmse=1.04567 mae=0.80856\n",
      "<class 'data.RSContext'> iteration 141: loss = 2387.8137, delta_loss = 5.43706 learning_Rate = 0.01000 rmse=1.04598 mae=0.80877\n",
      "<class 'data.RSContext'> iteration 142: loss = 2382.4550, delta_loss = 5.35867 learning_Rate = 0.01000 rmse=1.04629 mae=0.80899\n",
      "<class 'data.RSContext'> iteration 143: loss = 2377.1730, delta_loss = 5.28199 learning_Rate = 0.01000 rmse=1.04659 mae=0.80919\n",
      "<class 'data.RSContext'> iteration 144: loss = 2371.9661, delta_loss = 5.20697 learning_Rate = 0.01000 rmse=1.04689 mae=0.80940\n",
      "<class 'data.RSContext'> iteration 145: loss = 2366.8325, delta_loss = 5.13357 learning_Rate = 0.01000 rmse=1.04719 mae=0.80960\n",
      "<class 'data.RSContext'> iteration 146: loss = 2361.7707, delta_loss = 5.06174 learning_Rate = 0.01000 rmse=1.04749 mae=0.80980\n",
      "<class 'data.RSContext'> iteration 147: loss = 2356.7793, delta_loss = 4.99143 learning_Rate = 0.01000 rmse=1.04778 mae=0.80999\n",
      "<class 'data.RSContext'> iteration 148: loss = 2351.8567, delta_loss = 4.92260 learning_Rate = 0.01000 rmse=1.04807 mae=0.81019\n",
      "<class 'data.RSContext'> iteration 149: loss = 2347.0015, delta_loss = 4.85522 learning_Rate = 0.01000 rmse=1.04836 mae=0.81039\n",
      "<class 'data.RSContext'> iteration 150: loss = 2342.2123, delta_loss = 4.78923 learning_Rate = 0.01000 rmse=1.04866 mae=0.81058\n",
      "<class 'data.RSContext'> iteration 151: loss = 2337.4877, delta_loss = 4.72461 learning_Rate = 0.01000 rmse=1.04894 mae=0.81077\n",
      "<class 'data.RSContext'> iteration 152: loss = 2332.8263, delta_loss = 4.66131 learning_Rate = 0.01000 rmse=1.04923 mae=0.81096\n",
      "<class 'data.RSContext'> iteration 153: loss = 2328.2270, delta_loss = 4.59930 learning_Rate = 0.01000 rmse=1.04951 mae=0.81114\n",
      "<class 'data.RSContext'> iteration 154: loss = 2323.6885, delta_loss = 4.53854 learning_Rate = 0.01000 rmse=1.04979 mae=0.81132\n",
      "<class 'data.RSContext'> iteration 155: loss = 2319.2095, delta_loss = 4.47900 learning_Rate = 0.01000 rmse=1.05006 mae=0.81151\n",
      "<class 'data.RSContext'> iteration 156: loss = 2314.7889, delta_loss = 4.42065 learning_Rate = 0.01000 rmse=1.05034 mae=0.81169\n",
      "<class 'data.RSContext'> iteration 157: loss = 2310.4254, delta_loss = 4.36346 learning_Rate = 0.01000 rmse=1.05061 mae=0.81187\n",
      "<class 'data.RSContext'> iteration 158: loss = 2306.1180, delta_loss = 4.30739 learning_Rate = 0.01000 rmse=1.05088 mae=0.81204\n",
      "<class 'data.RSContext'> iteration 159: loss = 2301.8656, delta_loss = 4.25242 learning_Rate = 0.01000 rmse=1.05115 mae=0.81222\n",
      "<class 'data.RSContext'> iteration 160: loss = 2297.6671, delta_loss = 4.19851 learning_Rate = 0.01000 rmse=1.05142 mae=0.81240\n",
      "current best rmse is 1.05142, mae is 0.81240\n",
      "80023\n",
      "19977\n",
      "cold start users count 0\n",
      "{\n",
      "    'dataset_name': 'u',\n",
      "    'k_fold_num': 5,\n",
      "    'k_test': 0,\n",
      "    'rating_path': 'Z:/RSA/data/u_ratings.txt',\n",
      "    'rating_cv_path': 'Z:/RSA/data/cv/',\n",
      "    'trust_path': 'Z:/RSA/data/u_trust.txt',\n",
      "    'sep': ' ',\n",
      "    'random_state': 0,\n",
      "    'size': 0.8,\n",
      "    'min_val': 0.5,\n",
      "    'max_val': 4.0,\n",
      "    'coldUserRating': 5,\n",
      "    'factor': 10,\n",
      "    'threshold': 0.0001,\n",
      "    'lr': 0.01,\n",
      "    'maxIter': 100,\n",
      "    'lambdaP': 0.001,\n",
      "    'lambdaQ': 0.001,\n",
      "    'gamma': 0,\n",
      "    'isEarlyStopping': False,\n",
      "    'result_path': '../results/',\n",
      "    'model_path': 'model/',\n",
      "    'result_log_path': 'log/'\n",
      "}\n",
      "80023\n",
      "19977\n",
      "cold start users count 0\n",
      "80023\n",
      "19977\n",
      "cold start users count 0\n",
      "<class 'data.RSContext'> iteration 1: loss = 32624.0752, delta_loss = -32624.07521 learning_Rate = 0.01000 rmse=1.11489 mae=0.87223\n",
      "<class 'data.RSContext'> iteration 2: loss = 7680.4664, delta_loss = 24943.60883 learning_Rate = 0.01000 rmse=1.02022 mae=0.79740\n",
      "<class 'data.RSContext'> iteration 3: loss = 6700.5209, delta_loss = 979.94544 learning_Rate = 0.01000 rmse=1.00420 mae=0.78525\n",
      "<class 'data.RSContext'> iteration 4: loss = 6442.1273, delta_loss = 258.39366 learning_Rate = 0.01000 rmse=0.99921 mae=0.78218\n",
      "<class 'data.RSContext'> iteration 5: loss = 6309.5081, delta_loss = 132.61915 learning_Rate = 0.01000 rmse=0.99664 mae=0.78092\n",
      "<class 'data.RSContext'> iteration 6: loss = 6218.1948, delta_loss = 91.31331 learning_Rate = 0.01000 rmse=0.99496 mae=0.78010\n",
      "<class 'data.RSContext'> iteration 7: loss = 6145.7308, delta_loss = 72.46399 learning_Rate = 0.01000 rmse=0.99378 mae=0.77948\n",
      "<class 'data.RSContext'> iteration 8: loss = 6083.3203, delta_loss = 62.41058 learning_Rate = 0.01000 rmse=0.99285 mae=0.77894\n",
      "<class 'data.RSContext'> iteration 9: loss = 6026.5460, delta_loss = 56.77423 learning_Rate = 0.01000 rmse=0.99205 mae=0.77845\n",
      "<class 'data.RSContext'> iteration 10: loss = 5972.8178, delta_loss = 53.72825 learning_Rate = 0.01000 rmse=0.99138 mae=0.77806\n",
      "<class 'data.RSContext'> iteration 11: loss = 5920.4514, delta_loss = 52.36643 learning_Rate = 0.01000 rmse=0.99079 mae=0.77771\n",
      "<class 'data.RSContext'> iteration 12: loss = 5868.2676, delta_loss = 52.18375 learning_Rate = 0.01000 rmse=0.99018 mae=0.77734\n",
      "<class 'data.RSContext'> iteration 13: loss = 5815.3957, delta_loss = 52.87190 learning_Rate = 0.01000 rmse=0.98955 mae=0.77696\n",
      "<class 'data.RSContext'> iteration 14: loss = 5761.1706, delta_loss = 54.22505 learning_Rate = 0.01000 rmse=0.98892 mae=0.77653\n",
      "<class 'data.RSContext'> iteration 15: loss = 5705.0793, delta_loss = 56.09135 learning_Rate = 0.01000 rmse=0.98829 mae=0.77609\n",
      "<class 'data.RSContext'> iteration 16: loss = 5646.7332, delta_loss = 58.34614 learning_Rate = 0.01000 rmse=0.98763 mae=0.77561\n",
      "<class 'data.RSContext'> iteration 17: loss = 5585.8564, delta_loss = 60.87681 learning_Rate = 0.01000 rmse=0.98695 mae=0.77511\n",
      "<class 'data.RSContext'> iteration 18: loss = 5522.2814, delta_loss = 63.57491 learning_Rate = 0.01000 rmse=0.98623 mae=0.77456\n",
      "<class 'data.RSContext'> iteration 19: loss = 5455.9481, delta_loss = 66.33334 learning_Rate = 0.01000 rmse=0.98551 mae=0.77399\n",
      "<class 'data.RSContext'> iteration 20: loss = 5386.9007, delta_loss = 69.04738 learning_Rate = 0.01000 rmse=0.98478 mae=0.77340\n",
      "<class 'data.RSContext'> iteration 21: loss = 5315.2821, delta_loss = 71.61857 learning_Rate = 0.01000 rmse=0.98402 mae=0.77278\n",
      "<class 'data.RSContext'> iteration 22: loss = 5241.3221, delta_loss = 73.96006 learning_Rate = 0.01000 rmse=0.98326 mae=0.77213\n",
      "<class 'data.RSContext'> iteration 23: loss = 5165.3200, delta_loss = 76.00210 learning_Rate = 0.01000 rmse=0.98252 mae=0.77149\n",
      "<class 'data.RSContext'> iteration 24: loss = 5087.6240, delta_loss = 77.69599 learning_Rate = 0.01000 rmse=0.98180 mae=0.77086\n",
      "<class 'data.RSContext'> iteration 25: loss = 5008.6084, delta_loss = 79.01561 learning_Rate = 0.01000 rmse=0.98110 mae=0.77025\n",
      "<class 'data.RSContext'> iteration 26: loss = 4928.6525, delta_loss = 79.95588 learning_Rate = 0.01000 rmse=0.98045 mae=0.76967\n",
      "<class 'data.RSContext'> iteration 27: loss = 4848.1237, delta_loss = 80.52883 learning_Rate = 0.01000 rmse=0.97982 mae=0.76911\n",
      "<class 'data.RSContext'> iteration 28: loss = 4767.3653, delta_loss = 80.75835 learning_Rate = 0.01000 rmse=0.97926 mae=0.76864\n",
      "<class 'data.RSContext'> iteration 29: loss = 4686.6905, delta_loss = 80.67478 learning_Rate = 0.01000 rmse=0.97879 mae=0.76822\n",
      "<class 'data.RSContext'> iteration 30: loss = 4606.3799, delta_loss = 80.31065 learning_Rate = 0.01000 rmse=0.97840 mae=0.76787\n",
      "<class 'data.RSContext'> iteration 31: loss = 4526.6821, delta_loss = 79.69781 learning_Rate = 0.01000 rmse=0.97810 mae=0.76758\n",
      "<class 'data.RSContext'> iteration 32: loss = 4447.8160, delta_loss = 78.86609 learning_Rate = 0.01000 rmse=0.97787 mae=0.76733\n",
      "<class 'data.RSContext'> iteration 33: loss = 4369.9730, delta_loss = 77.84299 learning_Rate = 0.01000 rmse=0.97771 mae=0.76713\n",
      "<class 'data.RSContext'> iteration 34: loss = 4293.3191, delta_loss = 76.65395 learning_Rate = 0.01000 rmse=0.97764 mae=0.76701\n",
      "<class 'data.RSContext'> iteration 35: loss = 4217.9963, delta_loss = 75.32277 learning_Rate = 0.01000 rmse=0.97767 mae=0.76696\n",
      "<class 'data.RSContext'> iteration 36: loss = 4144.1244, delta_loss = 73.87187 learning_Rate = 0.01000 rmse=0.97778 mae=0.76698\n",
      "<class 'data.RSContext'> iteration 37: loss = 4071.8019, delta_loss = 72.32248 learning_Rate = 0.01000 rmse=0.97800 mae=0.76708\n",
      "<class 'data.RSContext'> iteration 38: loss = 4001.1074, delta_loss = 70.69450 learning_Rate = 0.01000 rmse=0.97830 mae=0.76724\n",
      "<class 'data.RSContext'> iteration 39: loss = 3932.1010, delta_loss = 69.00641 learning_Rate = 0.01000 rmse=0.97867 mae=0.76746\n",
      "<class 'data.RSContext'> iteration 40: loss = 3864.8259, delta_loss = 67.27509 learning_Rate = 0.01000 rmse=0.97912 mae=0.76772\n",
      "<class 'data.RSContext'> iteration 41: loss = 3799.3102, delta_loss = 65.51573 learning_Rate = 0.01000 rmse=0.97965 mae=0.76803\n",
      "<class 'data.RSContext'> iteration 42: loss = 3735.5685, delta_loss = 63.74172 learning_Rate = 0.01000 rmse=0.98025 mae=0.76840\n",
      "<class 'data.RSContext'> iteration 43: loss = 3673.6038, delta_loss = 61.96475 learning_Rate = 0.01000 rmse=0.98093 mae=0.76885\n",
      "<class 'data.RSContext'> iteration 44: loss = 3613.4089, delta_loss = 60.19481 learning_Rate = 0.01000 rmse=0.98167 mae=0.76934\n",
      "<class 'data.RSContext'> iteration 45: loss = 3554.9686, delta_loss = 58.44038 learning_Rate = 0.01000 rmse=0.98247 mae=0.76988\n",
      "<class 'data.RSContext'> iteration 46: loss = 3498.2600, delta_loss = 56.70852 learning_Rate = 0.01000 rmse=0.98332 mae=0.77046\n",
      "<class 'data.RSContext'> iteration 47: loss = 3443.2550, delta_loss = 55.00505 learning_Rate = 0.01000 rmse=0.98423 mae=0.77109\n",
      "<class 'data.RSContext'> iteration 48: loss = 3389.9203, delta_loss = 53.33467 learning_Rate = 0.01000 rmse=0.98518 mae=0.77176\n",
      "<class 'data.RSContext'> iteration 49: loss = 3338.2192, delta_loss = 51.70112 learning_Rate = 0.01000 rmse=0.98618 mae=0.77246\n",
      "<class 'data.RSContext'> iteration 50: loss = 3288.1119, delta_loss = 50.10730 learning_Rate = 0.01000 rmse=0.98722 mae=0.77320\n",
      "<class 'data.RSContext'> iteration 51: loss = 3239.5565, delta_loss = 48.55537 learning_Rate = 0.01000 rmse=0.98829 mae=0.77397\n",
      "<class 'data.RSContext'> iteration 52: loss = 3192.5097, delta_loss = 47.04686 learning_Rate = 0.01000 rmse=0.98937 mae=0.77473\n",
      "<class 'data.RSContext'> iteration 53: loss = 3146.9269, delta_loss = 45.58277 learning_Rate = 0.01000 rmse=0.99048 mae=0.77552\n",
      "<class 'data.RSContext'> iteration 54: loss = 3102.7633, delta_loss = 44.16364 learning_Rate = 0.01000 rmse=0.99161 mae=0.77632\n",
      "<class 'data.RSContext'> iteration 55: loss = 3059.9736, delta_loss = 42.78962 learning_Rate = 0.01000 rmse=0.99275 mae=0.77712\n",
      "<class 'data.RSContext'> iteration 56: loss = 3018.5131, delta_loss = 41.46055 learning_Rate = 0.01000 rmse=0.99391 mae=0.77793\n",
      "<class 'data.RSContext'> iteration 57: loss = 2978.3371, delta_loss = 40.17602 learning_Rate = 0.01000 rmse=0.99506 mae=0.77874\n",
      "<class 'data.RSContext'> iteration 58: loss = 2939.4017, delta_loss = 38.93538 learning_Rate = 0.01000 rmse=0.99623 mae=0.77955\n",
      "<class 'data.RSContext'> iteration 59: loss = 2901.6639, delta_loss = 37.73784 learning_Rate = 0.01000 rmse=0.99740 mae=0.78039\n",
      "<class 'data.RSContext'> iteration 60: loss = 2865.0814, delta_loss = 36.58247 learning_Rate = 0.01000 rmse=0.99857 mae=0.78120\n",
      "<class 'data.RSContext'> iteration 61: loss = 2829.6131, delta_loss = 35.46825 learning_Rate = 0.01000 rmse=0.99975 mae=0.78203\n",
      "<class 'data.RSContext'> iteration 62: loss = 2795.2191, delta_loss = 34.39406 learning_Rate = 0.01000 rmse=1.00094 mae=0.78286\n",
      "<class 'data.RSContext'> iteration 63: loss = 2761.8603, delta_loss = 33.35876 learning_Rate = 0.01000 rmse=1.00212 mae=0.78367\n",
      "<class 'data.RSContext'> iteration 64: loss = 2729.4992, delta_loss = 32.36115 learning_Rate = 0.01000 rmse=1.00332 mae=0.78449\n",
      "<class 'data.RSContext'> iteration 65: loss = 2698.0991, delta_loss = 31.40004 learning_Rate = 0.01000 rmse=1.00450 mae=0.78530\n",
      "<class 'data.RSContext'> iteration 66: loss = 2667.6249, delta_loss = 30.47419 learning_Rate = 0.01000 rmse=1.00568 mae=0.78609\n",
      "<class 'data.RSContext'> iteration 67: loss = 2638.0425, delta_loss = 29.58240 learning_Rate = 0.01000 rmse=1.00685 mae=0.78686\n",
      "<class 'data.RSContext'> iteration 68: loss = 2609.3191, delta_loss = 28.72345 learning_Rate = 0.01000 rmse=1.00801 mae=0.78763\n",
      "<class 'data.RSContext'> iteration 69: loss = 2581.4229, delta_loss = 27.89616 learning_Rate = 0.01000 rmse=1.00915 mae=0.78839\n",
      "<class 'data.RSContext'> iteration 70: loss = 2554.3236, delta_loss = 27.09936 learning_Rate = 0.01000 rmse=1.01028 mae=0.78913\n",
      "<class 'data.RSContext'> iteration 71: loss = 2527.9917, delta_loss = 26.33189 learning_Rate = 0.01000 rmse=1.01139 mae=0.78985\n",
      "<class 'data.RSContext'> iteration 72: loss = 2502.3990, delta_loss = 25.59263 learning_Rate = 0.01000 rmse=1.01248 mae=0.79055\n",
      "<class 'data.RSContext'> iteration 73: loss = 2477.5186, delta_loss = 24.88049 learning_Rate = 0.01000 rmse=1.01356 mae=0.79125\n",
      "<class 'data.RSContext'> iteration 74: loss = 2453.3241, delta_loss = 24.19440 learning_Rate = 0.01000 rmse=1.01462 mae=0.79193\n",
      "<class 'data.RSContext'> iteration 75: loss = 2429.7908, delta_loss = 23.53334 learning_Rate = 0.01000 rmse=1.01566 mae=0.79259\n",
      "<class 'data.RSContext'> iteration 76: loss = 2406.8945, delta_loss = 22.89631 learning_Rate = 0.01000 rmse=1.01668 mae=0.79325\n",
      "<class 'data.RSContext'> iteration 77: loss = 2384.6121, delta_loss = 22.28234 learning_Rate = 0.01000 rmse=1.01769 mae=0.79390\n",
      "<class 'data.RSContext'> iteration 78: loss = 2362.9216, delta_loss = 21.69051 learning_Rate = 0.01000 rmse=1.01869 mae=0.79454\n",
      "<class 'data.RSContext'> iteration 79: loss = 2341.8017, delta_loss = 21.11991 learning_Rate = 0.01000 rmse=1.01967 mae=0.79516\n",
      "<class 'data.RSContext'> iteration 80: loss = 2321.2321, delta_loss = 20.56968 learning_Rate = 0.01000 rmse=1.02064 mae=0.79576\n",
      "<class 'data.RSContext'> iteration 81: loss = 2301.1931, delta_loss = 20.03899 learning_Rate = 0.01000 rmse=1.02160 mae=0.79637\n",
      "<class 'data.RSContext'> iteration 82: loss = 2281.6660, delta_loss = 19.52704 learning_Rate = 0.01000 rmse=1.02255 mae=0.79697\n",
      "<class 'data.RSContext'> iteration 83: loss = 2262.6329, delta_loss = 19.03307 learning_Rate = 0.01000 rmse=1.02348 mae=0.79757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'data.RSContext'> iteration 84: loss = 2244.0766, delta_loss = 18.55634 learning_Rate = 0.01000 rmse=1.02440 mae=0.79817\n",
      "<class 'data.RSContext'> iteration 85: loss = 2225.9805, delta_loss = 18.09614 learning_Rate = 0.01000 rmse=1.02532 mae=0.79876\n",
      "<class 'data.RSContext'> iteration 86: loss = 2208.3287, delta_loss = 17.65179 learning_Rate = 0.01000 rmse=1.02622 mae=0.79933\n",
      "<class 'data.RSContext'> iteration 87: loss = 2191.1060, delta_loss = 17.22265 learning_Rate = 0.01000 rmse=1.02711 mae=0.79990\n",
      "<class 'data.RSContext'> iteration 88: loss = 2174.2979, delta_loss = 16.80808 learning_Rate = 0.01000 rmse=1.02798 mae=0.80045\n",
      "<class 'data.RSContext'> iteration 89: loss = 2157.8904, delta_loss = 16.40751 learning_Rate = 0.01000 rmse=1.02884 mae=0.80099\n",
      "<class 'data.RSContext'> iteration 90: loss = 2141.8701, delta_loss = 16.02035 learning_Rate = 0.01000 rmse=1.02969 mae=0.80153\n",
      "<class 'data.RSContext'> iteration 91: loss = 2126.2240, delta_loss = 15.64606 learning_Rate = 0.01000 rmse=1.03053 mae=0.80206\n",
      "<class 'data.RSContext'> iteration 92: loss = 2110.9399, delta_loss = 15.28412 learning_Rate = 0.01000 rmse=1.03136 mae=0.80259\n",
      "<class 'data.RSContext'> iteration 93: loss = 2096.0059, delta_loss = 14.93402 learning_Rate = 0.01000 rmse=1.03217 mae=0.80310\n",
      "<class 'data.RSContext'> iteration 94: loss = 2081.4106, delta_loss = 14.59529 learning_Rate = 0.01000 rmse=1.03297 mae=0.80361\n",
      "<class 'data.RSContext'> iteration 95: loss = 2067.1431, delta_loss = 14.26747 learning_Rate = 0.01000 rmse=1.03376 mae=0.80411\n",
      "<class 'data.RSContext'> iteration 96: loss = 2053.1930, delta_loss = 13.95013 learning_Rate = 0.01000 rmse=1.03454 mae=0.80461\n",
      "<class 'data.RSContext'> iteration 97: loss = 2039.5502, delta_loss = 13.64283 learning_Rate = 0.01000 rmse=1.03531 mae=0.80510\n",
      "<class 'data.RSContext'> iteration 98: loss = 2026.2050, delta_loss = 13.34519 learning_Rate = 0.01000 rmse=1.03606 mae=0.80558\n",
      "<class 'data.RSContext'> iteration 99: loss = 2013.1482, delta_loss = 13.05681 learning_Rate = 0.01000 rmse=1.03680 mae=0.80605\n",
      "<class 'data.RSContext'> iteration 100: loss = 2000.3708, delta_loss = 12.77734 learning_Rate = 0.01000 rmse=1.03753 mae=0.80653\n",
      "<class 'data.RSContext'> iteration 101: loss = 1987.8644, delta_loss = 12.50642 learning_Rate = 0.01000 rmse=1.03824 mae=0.80700\n",
      "<class 'data.RSContext'> iteration 102: loss = 1975.6207, delta_loss = 12.24372 learning_Rate = 0.01000 rmse=1.03895 mae=0.80747\n",
      "<class 'data.RSContext'> iteration 103: loss = 1963.6318, delta_loss = 11.98891 learning_Rate = 0.01000 rmse=1.03965 mae=0.80793\n",
      "<class 'data.RSContext'> iteration 104: loss = 1951.8901, delta_loss = 11.74170 learning_Rate = 0.01000 rmse=1.04033 mae=0.80838\n",
      "<class 'data.RSContext'> iteration 105: loss = 1940.3883, delta_loss = 11.50179 learning_Rate = 0.01000 rmse=1.04101 mae=0.80883\n",
      "<class 'data.RSContext'> iteration 106: loss = 1929.1194, delta_loss = 11.26891 learning_Rate = 0.01000 rmse=1.04168 mae=0.80926\n",
      "<class 'data.RSContext'> iteration 107: loss = 1918.0766, delta_loss = 11.04278 learning_Rate = 0.01000 rmse=1.04233 mae=0.80970\n",
      "<class 'data.RSContext'> iteration 108: loss = 1907.2534, delta_loss = 10.82315 learning_Rate = 0.01000 rmse=1.04298 mae=0.81013\n",
      "<class 'data.RSContext'> iteration 109: loss = 1896.6437, delta_loss = 10.60978 learning_Rate = 0.01000 rmse=1.04361 mae=0.81056\n",
      "<class 'data.RSContext'> iteration 110: loss = 1886.2412, delta_loss = 10.40244 learning_Rate = 0.01000 rmse=1.04424 mae=0.81098\n",
      "<class 'data.RSContext'> iteration 111: loss = 1876.0403, delta_loss = 10.20090 learning_Rate = 0.01000 rmse=1.04486 mae=0.81140\n",
      "<class 'data.RSContext'> iteration 112: loss = 1866.0354, delta_loss = 10.00495 learning_Rate = 0.01000 rmse=1.04547 mae=0.81181\n",
      "<class 'data.RSContext'> iteration 113: loss = 1856.2210, delta_loss = 9.81439 learning_Rate = 0.01000 rmse=1.04607 mae=0.81223\n",
      "<class 'data.RSContext'> iteration 114: loss = 1846.5920, delta_loss = 9.62902 learning_Rate = 0.01000 rmse=1.04667 mae=0.81264\n",
      "<class 'data.RSContext'> iteration 115: loss = 1837.1433, delta_loss = 9.44867 learning_Rate = 0.01000 rmse=1.04727 mae=0.81306\n",
      "<class 'data.RSContext'> iteration 116: loss = 1827.8702, delta_loss = 9.27315 learning_Rate = 0.01000 rmse=1.04785 mae=0.81347\n",
      "<class 'data.RSContext'> iteration 117: loss = 1818.7679, delta_loss = 9.10229 learning_Rate = 0.01000 rmse=1.04844 mae=0.81387\n",
      "<class 'data.RSContext'> iteration 118: loss = 1809.8319, delta_loss = 8.93593 learning_Rate = 0.01000 rmse=1.04901 mae=0.81427\n",
      "<class 'data.RSContext'> iteration 119: loss = 1801.0580, delta_loss = 8.77392 learning_Rate = 0.01000 rmse=1.04957 mae=0.81466\n",
      "<class 'data.RSContext'> iteration 120: loss = 1792.4419, delta_loss = 8.61611 learning_Rate = 0.01000 rmse=1.05013 mae=0.81505\n",
      "<class 'data.RSContext'> iteration 121: loss = 1783.9795, delta_loss = 8.46236 learning_Rate = 0.01000 rmse=1.05069 mae=0.81544\n",
      "<class 'data.RSContext'> iteration 122: loss = 1775.6670, delta_loss = 8.31253 learning_Rate = 0.01000 rmse=1.05124 mae=0.81583\n",
      "<class 'data.RSContext'> iteration 123: loss = 1767.5005, delta_loss = 8.16650 learning_Rate = 0.01000 rmse=1.05178 mae=0.81620\n",
      "<class 'data.RSContext'> iteration 124: loss = 1759.4764, delta_loss = 8.02413 learning_Rate = 0.01000 rmse=1.05231 mae=0.81657\n",
      "<class 'data.RSContext'> iteration 125: loss = 1751.5911, delta_loss = 7.88531 learning_Rate = 0.01000 rmse=1.05283 mae=0.81694\n",
      "<class 'data.RSContext'> iteration 126: loss = 1743.8411, delta_loss = 7.74992 learning_Rate = 0.01000 rmse=1.05335 mae=0.81730\n",
      "<class 'data.RSContext'> iteration 127: loss = 1736.2233, delta_loss = 7.61786 learning_Rate = 0.01000 rmse=1.05387 mae=0.81766\n",
      "<class 'data.RSContext'> iteration 128: loss = 1728.7343, delta_loss = 7.48903 learning_Rate = 0.01000 rmse=1.05438 mae=0.81802\n",
      "<class 'data.RSContext'> iteration 129: loss = 1721.3710, delta_loss = 7.36331 learning_Rate = 0.01000 rmse=1.05489 mae=0.81838\n",
      "<class 'data.RSContext'> iteration 130: loss = 1714.1303, delta_loss = 7.24061 learning_Rate = 0.01000 rmse=1.05540 mae=0.81873\n",
      "<class 'data.RSContext'> iteration 131: loss = 1707.0095, delta_loss = 7.12085 learning_Rate = 0.01000 rmse=1.05589 mae=0.81908\n",
      "<class 'data.RSContext'> iteration 132: loss = 1700.0055, delta_loss = 7.00393 learning_Rate = 0.01000 rmse=1.05638 mae=0.81943\n",
      "<class 'data.RSContext'> iteration 133: loss = 1693.1158, delta_loss = 6.88977 learning_Rate = 0.01000 rmse=1.05687 mae=0.81978\n",
      "<class 'data.RSContext'> iteration 134: loss = 1686.3375, delta_loss = 6.77829 learning_Rate = 0.01000 rmse=1.05735 mae=0.82012\n",
      "<class 'data.RSContext'> iteration 135: loss = 1679.6681, delta_loss = 6.66940 learning_Rate = 0.01000 rmse=1.05782 mae=0.82046\n",
      "<class 'data.RSContext'> iteration 136: loss = 1673.1051, delta_loss = 6.56303 learning_Rate = 0.01000 rmse=1.05829 mae=0.82078\n",
      "<class 'data.RSContext'> iteration 137: loss = 1666.6460, delta_loss = 6.45911 learning_Rate = 0.01000 rmse=1.05876 mae=0.82111\n",
      "<class 'data.RSContext'> iteration 138: loss = 1660.2884, delta_loss = 6.35756 learning_Rate = 0.01000 rmse=1.05923 mae=0.82144\n",
      "<class 'data.RSContext'> iteration 139: loss = 1654.0301, delta_loss = 6.25833 learning_Rate = 0.01000 rmse=1.05969 mae=0.82176\n",
      "<class 'data.RSContext'> iteration 140: loss = 1647.8687, delta_loss = 6.16134 learning_Rate = 0.01000 rmse=1.06015 mae=0.82208\n",
      "<class 'data.RSContext'> iteration 141: loss = 1641.8022, delta_loss = 6.06653 learning_Rate = 0.01000 rmse=1.06060 mae=0.82241\n",
      "<class 'data.RSContext'> iteration 142: loss = 1635.8283, delta_loss = 5.97385 learning_Rate = 0.01000 rmse=1.06105 mae=0.82272\n",
      "<class 'data.RSContext'> iteration 143: loss = 1629.9451, delta_loss = 5.88322 learning_Rate = 0.01000 rmse=1.06150 mae=0.82304\n",
      "<class 'data.RSContext'> iteration 144: loss = 1624.1505, delta_loss = 5.79460 learning_Rate = 0.01000 rmse=1.06194 mae=0.82335\n",
      "<class 'data.RSContext'> iteration 145: loss = 1618.4426, delta_loss = 5.70793 learning_Rate = 0.01000 rmse=1.06238 mae=0.82366\n",
      "<class 'data.RSContext'> iteration 146: loss = 1612.8194, delta_loss = 5.62317 learning_Rate = 0.01000 rmse=1.06282 mae=0.82397\n",
      "<class 'data.RSContext'> iteration 147: loss = 1607.2792, delta_loss = 5.54025 learning_Rate = 0.01000 rmse=1.06325 mae=0.82427\n",
      "<class 'data.RSContext'> iteration 148: loss = 1601.8200, delta_loss = 5.45912 learning_Rate = 0.01000 rmse=1.06369 mae=0.82457\n",
      "<class 'data.RSContext'> iteration 149: loss = 1596.4403, delta_loss = 5.37975 learning_Rate = 0.01000 rmse=1.06412 mae=0.82486\n",
      "<class 'data.RSContext'> iteration 150: loss = 1591.1382, delta_loss = 5.30209 learning_Rate = 0.01000 rmse=1.06454 mae=0.82516\n",
      "<class 'data.RSContext'> iteration 151: loss = 1585.9121, delta_loss = 5.22608 learning_Rate = 0.01000 rmse=1.06496 mae=0.82545\n",
      "<class 'data.RSContext'> iteration 152: loss = 1580.7604, delta_loss = 5.15169 learning_Rate = 0.01000 rmse=1.06538 mae=0.82574\n",
      "<class 'data.RSContext'> iteration 153: loss = 1575.6816, delta_loss = 5.07888 learning_Rate = 0.01000 rmse=1.06579 mae=0.82601\n",
      "<class 'data.RSContext'> iteration 154: loss = 1570.6740, delta_loss = 5.00760 learning_Rate = 0.01000 rmse=1.06620 mae=0.82630\n",
      "<class 'data.RSContext'> iteration 155: loss = 1565.7362, delta_loss = 4.93781 learning_Rate = 0.01000 rmse=1.06662 mae=0.82658\n",
      "<class 'data.RSContext'> iteration 156: loss = 1560.8667, delta_loss = 4.86949 learning_Rate = 0.01000 rmse=1.06702 mae=0.82686\n",
      "<class 'data.RSContext'> iteration 157: loss = 1556.0641, delta_loss = 4.80258 learning_Rate = 0.01000 rmse=1.06742 mae=0.82714\n",
      "<class 'data.RSContext'> iteration 158: loss = 1551.3270, delta_loss = 4.73706 learning_Rate = 0.01000 rmse=1.06782 mae=0.82741\n",
      "<class 'data.RSContext'> iteration 159: loss = 1546.6541, delta_loss = 4.67289 learning_Rate = 0.01000 rmse=1.06822 mae=0.82768\n",
      "<class 'data.RSContext'> iteration 160: loss = 1542.0441, delta_loss = 4.61003 learning_Rate = 0.01000 rmse=1.06862 mae=0.82795\n",
      "current best rmse is 1.06862, mae is 0.82795\n",
      "80023\n",
      "19977\n",
      "cold start users count 0\n",
      "{\n",
      "    'dataset_name': 'u',\n",
      "    'k_fold_num': 5,\n",
      "    'k_test': 0,\n",
      "    'rating_path': 'Z:/RSA/data/u_ratings.txt',\n",
      "    'rating_cv_path': 'Z:/RSA/data/cv/',\n",
      "    'trust_path': 'Z:/RSA/data/u_trust.txt',\n",
      "    'sep': ' ',\n",
      "    'random_state': 0,\n",
      "    'size': 0.8,\n",
      "    'min_val': 0.5,\n",
      "    'max_val': 4.0,\n",
      "    'coldUserRating': 5,\n",
      "    'factor': 10,\n",
      "    'threshold': 0.0001,\n",
      "    'lr': 0.01,\n",
      "    'maxIter': 100,\n",
      "    'lambdaP': 0.001,\n",
      "    'lambdaQ': 0.001,\n",
      "    'gamma': 0,\n",
      "    'isEarlyStopping': False,\n",
      "    'result_path': '../results/',\n",
      "    'model_path': 'model/',\n",
      "    'result_log_path': 'log/'\n",
      "}\n",
      "80023\n",
      "19977\n",
      "cold start users count 0\n",
      "80023\n",
      "19977\n",
      "cold start users count 0\n",
      "<class 'data.RSContext'> iteration 1: loss = 31788.0910, delta_loss = -31788.09099 learning_Rate = 0.01000 rmse=1.10768 mae=0.86813\n",
      "<class 'data.RSContext'> iteration 2: loss = 7604.8034, delta_loss = 24183.28762 learning_Rate = 0.01000 rmse=1.01600 mae=0.79565\n",
      "<class 'data.RSContext'> iteration 3: loss = 6663.6656, delta_loss = 941.13779 learning_Rate = 0.01000 rmse=1.00103 mae=0.78397\n",
      "<class 'data.RSContext'> iteration 4: loss = 6415.6578, delta_loss = 248.00780 learning_Rate = 0.01000 rmse=0.99649 mae=0.78112\n",
      "<class 'data.RSContext'> iteration 5: loss = 6288.0500, delta_loss = 127.60779 learning_Rate = 0.01000 rmse=0.99416 mae=0.77992\n",
      "<class 'data.RSContext'> iteration 6: loss = 6199.8131, delta_loss = 88.23686 learning_Rate = 0.01000 rmse=0.99261 mae=0.77907\n",
      "<class 'data.RSContext'> iteration 7: loss = 6129.4325, delta_loss = 70.38061 learning_Rate = 0.01000 rmse=0.99154 mae=0.77849\n",
      "<class 'data.RSContext'> iteration 8: loss = 6068.5020, delta_loss = 60.93055 learning_Rate = 0.01000 rmse=0.99070 mae=0.77803\n",
      "<class 'data.RSContext'> iteration 9: loss = 6012.8065, delta_loss = 55.69551 learning_Rate = 0.01000 rmse=0.99006 mae=0.77764\n",
      "<class 'data.RSContext'> iteration 10: loss = 5959.8710, delta_loss = 52.93545 learning_Rate = 0.01000 rmse=0.98948 mae=0.77731\n",
      "<class 'data.RSContext'> iteration 11: loss = 5908.0781, delta_loss = 51.79287 learning_Rate = 0.01000 rmse=0.98895 mae=0.77701\n",
      "<class 'data.RSContext'> iteration 12: loss = 5856.2831, delta_loss = 51.79504 learning_Rate = 0.01000 rmse=0.98848 mae=0.77671\n",
      "<class 'data.RSContext'> iteration 13: loss = 5803.6243, delta_loss = 52.65884 learning_Rate = 0.01000 rmse=0.98804 mae=0.77642\n",
      "<class 'data.RSContext'> iteration 14: loss = 5749.4230, delta_loss = 54.20128 learning_Rate = 0.01000 rmse=0.98759 mae=0.77612\n",
      "<class 'data.RSContext'> iteration 15: loss = 5693.1297, delta_loss = 56.29325 learning_Rate = 0.01000 rmse=0.98715 mae=0.77581\n",
      "<class 'data.RSContext'> iteration 16: loss = 5634.2964, delta_loss = 58.83338 learning_Rate = 0.01000 rmse=0.98671 mae=0.77551\n",
      "<class 'data.RSContext'> iteration 17: loss = 5572.5639, delta_loss = 61.73247 learning_Rate = 0.01000 rmse=0.98625 mae=0.77518\n",
      "<class 'data.RSContext'> iteration 18: loss = 5507.6600, delta_loss = 64.90390 learning_Rate = 0.01000 rmse=0.98576 mae=0.77482\n",
      "<class 'data.RSContext'> iteration 19: loss = 5439.4017, delta_loss = 68.25830 learning_Rate = 0.01000 rmse=0.98525 mae=0.77444\n",
      "<class 'data.RSContext'> iteration 20: loss = 5367.7003, delta_loss = 71.70133 learning_Rate = 0.01000 rmse=0.98472 mae=0.77402\n",
      "<class 'data.RSContext'> iteration 21: loss = 5292.5660, delta_loss = 75.13437 learning_Rate = 0.01000 rmse=0.98415 mae=0.77358\n",
      "<class 'data.RSContext'> iteration 22: loss = 5214.1085, delta_loss = 78.45746 learning_Rate = 0.01000 rmse=0.98356 mae=0.77311\n",
      "<class 'data.RSContext'> iteration 23: loss = 5132.5345, delta_loss = 81.57399 learning_Rate = 0.01000 rmse=0.98294 mae=0.77260\n",
      "<class 'data.RSContext'> iteration 24: loss = 5048.1382, delta_loss = 84.39628 learning_Rate = 0.01000 rmse=0.98232 mae=0.77209\n",
      "<class 'data.RSContext'> iteration 25: loss = 4961.2874, delta_loss = 86.85083 learning_Rate = 0.01000 rmse=0.98169 mae=0.77160\n",
      "<class 'data.RSContext'> iteration 26: loss = 4872.4050, delta_loss = 88.88241 learning_Rate = 0.01000 rmse=0.98108 mae=0.77112\n",
      "<class 'data.RSContext'> iteration 27: loss = 4781.9487, delta_loss = 90.45626 learning_Rate = 0.01000 rmse=0.98049 mae=0.77063\n",
      "<class 'data.RSContext'> iteration 28: loss = 4690.3905, delta_loss = 91.55819 learning_Rate = 0.01000 rmse=0.97992 mae=0.77012\n",
      "<class 'data.RSContext'> iteration 29: loss = 4598.1977, delta_loss = 92.19287 learning_Rate = 0.01000 rmse=0.97941 mae=0.76963\n",
      "<class 'data.RSContext'> iteration 30: loss = 4505.8168, delta_loss = 92.38090 learning_Rate = 0.01000 rmse=0.97896 mae=0.76916\n",
      "<class 'data.RSContext'> iteration 31: loss = 4413.6616, delta_loss = 92.15513 learning_Rate = 0.01000 rmse=0.97858 mae=0.76869\n",
      "<class 'data.RSContext'> iteration 32: loss = 4322.1048, delta_loss = 91.55681 learning_Rate = 0.01000 rmse=0.97828 mae=0.76826\n",
      "<class 'data.RSContext'> iteration 33: loss = 4231.4729, delta_loss = 90.63189 learning_Rate = 0.01000 rmse=0.97805 mae=0.76788\n",
      "<class 'data.RSContext'> iteration 34: loss = 4142.0452, delta_loss = 89.42775 learning_Rate = 0.01000 rmse=0.97792 mae=0.76758\n",
      "<class 'data.RSContext'> iteration 35: loss = 4054.0546, delta_loss = 87.99062 learning_Rate = 0.01000 rmse=0.97790 mae=0.76735\n",
      "<class 'data.RSContext'> iteration 36: loss = 3967.6910, delta_loss = 86.36359 learning_Rate = 0.01000 rmse=0.97797 mae=0.76722\n",
      "<class 'data.RSContext'> iteration 37: loss = 3883.1055, delta_loss = 84.58551 learning_Rate = 0.01000 rmse=0.97814 mae=0.76716\n",
      "<class 'data.RSContext'> iteration 38: loss = 3800.4150, delta_loss = 82.69046 learning_Rate = 0.01000 rmse=0.97841 mae=0.76717\n",
      "<class 'data.RSContext'> iteration 39: loss = 3719.7073, delta_loss = 80.70773 learning_Rate = 0.01000 rmse=0.97876 mae=0.76724\n",
      "<class 'data.RSContext'> iteration 40: loss = 3641.0450, delta_loss = 78.66224 learning_Rate = 0.01000 rmse=0.97921 mae=0.76739\n",
      "<class 'data.RSContext'> iteration 41: loss = 3564.4700, delta_loss = 76.57501 learning_Rate = 0.01000 rmse=0.97973 mae=0.76761\n",
      "<class 'data.RSContext'> iteration 42: loss = 3490.0063, delta_loss = 74.46371 learning_Rate = 0.01000 rmse=0.98033 mae=0.76787\n",
      "<class 'data.RSContext'> iteration 43: loss = 3417.6631, delta_loss = 72.34327 learning_Rate = 0.01000 rmse=0.98101 mae=0.76821\n",
      "<class 'data.RSContext'> iteration 44: loss = 3347.4368, delta_loss = 70.22623 learning_Rate = 0.01000 rmse=0.98175 mae=0.76860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'data.RSContext'> iteration 45: loss = 3279.3136, delta_loss = 68.12319 learning_Rate = 0.01000 rmse=0.98256 mae=0.76903\n",
      "<class 'data.RSContext'> iteration 46: loss = 3213.2706, delta_loss = 66.04302 learning_Rate = 0.01000 rmse=0.98343 mae=0.76952\n",
      "<class 'data.RSContext'> iteration 47: loss = 3149.2774, delta_loss = 63.99316 learning_Rate = 0.01000 rmse=0.98435 mae=0.77006\n",
      "<class 'data.RSContext'> iteration 48: loss = 3087.2977, delta_loss = 61.97975 learning_Rate = 0.01000 rmse=0.98531 mae=0.77062\n",
      "<class 'data.RSContext'> iteration 49: loss = 3027.2899, delta_loss = 60.00779 learning_Rate = 0.01000 rmse=0.98632 mae=0.77124\n",
      "<class 'data.RSContext'> iteration 50: loss = 2969.2086, delta_loss = 58.08132 learning_Rate = 0.01000 rmse=0.98736 mae=0.77189\n",
      "<class 'data.RSContext'> iteration 51: loss = 2913.0051, delta_loss = 56.20347 learning_Rate = 0.01000 rmse=0.98844 mae=0.77256\n",
      "<class 'data.RSContext'> iteration 52: loss = 2858.6285, delta_loss = 54.37662 learning_Rate = 0.01000 rmse=0.98956 mae=0.77325\n",
      "<class 'data.RSContext'> iteration 53: loss = 2806.0260, delta_loss = 52.60247 learning_Rate = 0.01000 rmse=0.99070 mae=0.77396\n",
      "<class 'data.RSContext'> iteration 54: loss = 2755.1439, delta_loss = 50.88214 learning_Rate = 0.01000 rmse=0.99185 mae=0.77470\n",
      "<class 'data.RSContext'> iteration 55: loss = 2705.9276, delta_loss = 49.21625 learning_Rate = 0.01000 rmse=0.99302 mae=0.77546\n",
      "<class 'data.RSContext'> iteration 56: loss = 2658.3226, delta_loss = 47.60502 learning_Rate = 0.01000 rmse=0.99421 mae=0.77623\n",
      "<class 'data.RSContext'> iteration 57: loss = 2612.2744, delta_loss = 46.04826 learning_Rate = 0.01000 rmse=0.99541 mae=0.77701\n",
      "<class 'data.RSContext'> iteration 58: loss = 2567.7288, delta_loss = 44.54551 learning_Rate = 0.01000 rmse=0.99661 mae=0.77780\n",
      "<class 'data.RSContext'> iteration 59: loss = 2524.6328, delta_loss = 43.09604 learning_Rate = 0.01000 rmse=0.99781 mae=0.77859\n",
      "<class 'data.RSContext'> iteration 60: loss = 2482.9339, delta_loss = 41.69892 learning_Rate = 0.01000 rmse=0.99900 mae=0.77938\n",
      "<class 'data.RSContext'> iteration 61: loss = 2442.5809, delta_loss = 40.35303 learning_Rate = 0.01000 rmse=1.00020 mae=0.78017\n",
      "<class 'data.RSContext'> iteration 62: loss = 2403.5237, delta_loss = 39.05714 learning_Rate = 0.01000 rmse=1.00139 mae=0.78096\n",
      "<class 'data.RSContext'> iteration 63: loss = 2365.7138, delta_loss = 37.80988 learning_Rate = 0.01000 rmse=1.00260 mae=0.78176\n",
      "<class 'data.RSContext'> iteration 64: loss = 2329.1040, delta_loss = 36.60984 learning_Rate = 0.01000 rmse=1.00379 mae=0.78255\n",
      "<class 'data.RSContext'> iteration 65: loss = 2293.6485, delta_loss = 35.45552 learning_Rate = 0.01000 rmse=1.00498 mae=0.78334\n",
      "<class 'data.RSContext'> iteration 66: loss = 2259.3031, delta_loss = 34.34540 learning_Rate = 0.01000 rmse=1.00616 mae=0.78411\n",
      "<class 'data.RSContext'> iteration 67: loss = 2226.0251, delta_loss = 33.27794 learning_Rate = 0.01000 rmse=1.00734 mae=0.78488\n",
      "<class 'data.RSContext'> iteration 68: loss = 2193.7735, delta_loss = 32.25160 learning_Rate = 0.01000 rmse=1.00852 mae=0.78566\n",
      "<class 'data.RSContext'> iteration 69: loss = 2162.5087, delta_loss = 31.26482 learning_Rate = 0.01000 rmse=1.00970 mae=0.78644\n",
      "<class 'data.RSContext'> iteration 70: loss = 2132.1926, delta_loss = 30.31610 learning_Rate = 0.01000 rmse=1.01087 mae=0.78720\n",
      "<class 'data.RSContext'> iteration 71: loss = 2102.7887, delta_loss = 29.40393 learning_Rate = 0.01000 rmse=1.01203 mae=0.78796\n",
      "<class 'data.RSContext'> iteration 72: loss = 2074.2618, delta_loss = 28.52684 learning_Rate = 0.01000 rmse=1.01318 mae=0.78872\n",
      "<class 'data.RSContext'> iteration 73: loss = 2046.5784, delta_loss = 27.68342 learning_Rate = 0.01000 rmse=1.01434 mae=0.78948\n",
      "<class 'data.RSContext'> iteration 74: loss = 2019.7061, delta_loss = 26.87228 learning_Rate = 0.01000 rmse=1.01549 mae=0.79023\n",
      "<class 'data.RSContext'> iteration 75: loss = 1993.6141, delta_loss = 26.09206 learning_Rate = 0.01000 rmse=1.01662 mae=0.79099\n",
      "<class 'data.RSContext'> iteration 76: loss = 1968.2726, delta_loss = 25.34148 learning_Rate = 0.01000 rmse=1.01774 mae=0.79174\n",
      "<class 'data.RSContext'> iteration 77: loss = 1943.6533, delta_loss = 24.61928 learning_Rate = 0.01000 rmse=1.01885 mae=0.79248\n",
      "<class 'data.RSContext'> iteration 78: loss = 1919.7291, delta_loss = 23.92426 learning_Rate = 0.01000 rmse=1.01994 mae=0.79322\n",
      "<class 'data.RSContext'> iteration 79: loss = 1896.4738, delta_loss = 23.25525 learning_Rate = 0.01000 rmse=1.02102 mae=0.79396\n",
      "<class 'data.RSContext'> iteration 80: loss = 1873.8627, delta_loss = 22.61116 learning_Rate = 0.01000 rmse=1.02209 mae=0.79470\n",
      "<class 'data.RSContext'> iteration 81: loss = 1851.8717, delta_loss = 21.99091 learning_Rate = 0.01000 rmse=1.02316 mae=0.79542\n",
      "<class 'data.RSContext'> iteration 82: loss = 1830.4783, delta_loss = 21.39348 learning_Rate = 0.01000 rmse=1.02421 mae=0.79614\n",
      "<class 'data.RSContext'> iteration 83: loss = 1809.6604, delta_loss = 20.81790 learning_Rate = 0.01000 rmse=1.02526 mae=0.79685\n",
      "<class 'data.RSContext'> iteration 84: loss = 1789.3971, delta_loss = 20.26324 learning_Rate = 0.01000 rmse=1.02630 mae=0.79756\n",
      "<class 'data.RSContext'> iteration 85: loss = 1769.6685, delta_loss = 19.72860 learning_Rate = 0.01000 rmse=1.02733 mae=0.79828\n",
      "<class 'data.RSContext'> iteration 86: loss = 1750.4554, delta_loss = 19.21313 learning_Rate = 0.01000 rmse=1.02835 mae=0.79898\n",
      "<class 'data.RSContext'> iteration 87: loss = 1731.7394, delta_loss = 18.71602 learning_Rate = 0.01000 rmse=1.02936 mae=0.79967\n",
      "<class 'data.RSContext'> iteration 88: loss = 1713.5029, delta_loss = 18.23649 learning_Rate = 0.01000 rmse=1.03036 mae=0.80035\n",
      "<class 'data.RSContext'> iteration 89: loss = 1695.7291, delta_loss = 17.77379 learning_Rate = 0.01000 rmse=1.03135 mae=0.80104\n",
      "<class 'data.RSContext'> iteration 90: loss = 1678.4018, delta_loss = 17.32723 learning_Rate = 0.01000 rmse=1.03234 mae=0.80172\n",
      "<class 'data.RSContext'> iteration 91: loss = 1661.5057, delta_loss = 16.89612 learning_Rate = 0.01000 rmse=1.03331 mae=0.80240\n",
      "<class 'data.RSContext'> iteration 92: loss = 1645.0259, delta_loss = 16.47983 learning_Rate = 0.01000 rmse=1.03427 mae=0.80307\n",
      "<class 'data.RSContext'> iteration 93: loss = 1628.9482, delta_loss = 16.07773 learning_Rate = 0.01000 rmse=1.03521 mae=0.80372\n",
      "<class 'data.RSContext'> iteration 94: loss = 1613.2589, delta_loss = 15.68924 learning_Rate = 0.01000 rmse=1.03615 mae=0.80436\n",
      "<class 'data.RSContext'> iteration 95: loss = 1597.9451, delta_loss = 15.31380 learning_Rate = 0.01000 rmse=1.03707 mae=0.80500\n",
      "<class 'data.RSContext'> iteration 96: loss = 1582.9943, delta_loss = 14.95088 learning_Rate = 0.01000 rmse=1.03799 mae=0.80562\n",
      "<class 'data.RSContext'> iteration 97: loss = 1568.3943, delta_loss = 14.59996 learning_Rate = 0.01000 rmse=1.03890 mae=0.80624\n",
      "<class 'data.RSContext'> iteration 98: loss = 1554.1337, delta_loss = 14.26057 learning_Rate = 0.01000 rmse=1.03980 mae=0.80686\n",
      "<class 'data.RSContext'> iteration 99: loss = 1540.2015, delta_loss = 13.93223 learning_Rate = 0.01000 rmse=1.04068 mae=0.80747\n",
      "<class 'data.RSContext'> iteration 100: loss = 1526.5870, delta_loss = 13.61451 learning_Rate = 0.01000 rmse=1.04156 mae=0.80809\n",
      "<class 'data.RSContext'> iteration 101: loss = 1513.2800, delta_loss = 13.30697 learning_Rate = 0.01000 rmse=1.04242 mae=0.80868\n",
      "<class 'data.RSContext'> iteration 102: loss = 1500.2708, delta_loss = 13.00923 learning_Rate = 0.01000 rmse=1.04327 mae=0.80927\n",
      "<class 'data.RSContext'> iteration 103: loss = 1487.5499, delta_loss = 12.72089 learning_Rate = 0.01000 rmse=1.04411 mae=0.80986\n",
      "<class 'data.RSContext'> iteration 104: loss = 1475.1083, delta_loss = 12.44158 learning_Rate = 0.01000 rmse=1.04494 mae=0.81044\n",
      "<class 'data.RSContext'> iteration 105: loss = 1462.9374, delta_loss = 12.17095 learning_Rate = 0.01000 rmse=1.04577 mae=0.81101\n",
      "<class 'data.RSContext'> iteration 106: loss = 1451.0287, delta_loss = 11.90867 learning_Rate = 0.01000 rmse=1.04658 mae=0.81158\n",
      "<class 'data.RSContext'> iteration 107: loss = 1439.3743, delta_loss = 11.65441 learning_Rate = 0.01000 rmse=1.04738 mae=0.81215\n",
      "<class 'data.RSContext'> iteration 108: loss = 1427.9664, delta_loss = 11.40787 learning_Rate = 0.01000 rmse=1.04817 mae=0.81270\n",
      "<class 'data.RSContext'> iteration 109: loss = 1416.7977, delta_loss = 11.16875 learning_Rate = 0.01000 rmse=1.04895 mae=0.81326\n",
      "<class 'data.RSContext'> iteration 110: loss = 1405.8609, delta_loss = 10.93678 learning_Rate = 0.01000 rmse=1.04972 mae=0.81380\n",
      "<class 'data.RSContext'> iteration 111: loss = 1395.1492, delta_loss = 10.71168 learning_Rate = 0.01000 rmse=1.05047 mae=0.81435\n",
      "<class 'data.RSContext'> iteration 112: loss = 1384.6560, delta_loss = 10.49319 learning_Rate = 0.01000 rmse=1.05122 mae=0.81488\n",
      "<class 'data.RSContext'> iteration 113: loss = 1374.3749, delta_loss = 10.28108 learning_Rate = 0.01000 rmse=1.05195 mae=0.81540\n",
      "<class 'data.RSContext'> iteration 114: loss = 1364.2998, delta_loss = 10.07510 learning_Rate = 0.01000 rmse=1.05267 mae=0.81592\n",
      "<class 'data.RSContext'> iteration 115: loss = 1354.4248, delta_loss = 9.87504 learning_Rate = 0.01000 rmse=1.05339 mae=0.81643\n",
      "<class 'data.RSContext'> iteration 116: loss = 1344.7441, delta_loss = 9.68067 learning_Rate = 0.01000 rmse=1.05411 mae=0.81694\n",
      "<class 'data.RSContext'> iteration 117: loss = 1335.2523, delta_loss = 9.49178 learning_Rate = 0.01000 rmse=1.05481 mae=0.81745\n",
      "<class 'data.RSContext'> iteration 118: loss = 1325.9442, delta_loss = 9.30819 learning_Rate = 0.01000 rmse=1.05551 mae=0.81795\n",
      "<class 'data.RSContext'> iteration 119: loss = 1316.8144, delta_loss = 9.12971 learning_Rate = 0.01000 rmse=1.05620 mae=0.81844\n",
      "<class 'data.RSContext'> iteration 120: loss = 1307.8583, delta_loss = 8.95614 learning_Rate = 0.01000 rmse=1.05687 mae=0.81892\n",
      "<class 'data.RSContext'> iteration 121: loss = 1299.0710, delta_loss = 8.78732 learning_Rate = 0.01000 rmse=1.05753 mae=0.81941\n",
      "<class 'data.RSContext'> iteration 122: loss = 1290.4479, delta_loss = 8.62309 learning_Rate = 0.01000 rmse=1.05819 mae=0.81988\n",
      "<class 'data.RSContext'> iteration 123: loss = 1281.9846, delta_loss = 8.46327 learning_Rate = 0.01000 rmse=1.05883 mae=0.82034\n",
      "<class 'data.RSContext'> iteration 124: loss = 1273.6769, delta_loss = 8.30772 learning_Rate = 0.01000 rmse=1.05947 mae=0.82081\n",
      "<class 'data.RSContext'> iteration 125: loss = 1265.5206, delta_loss = 8.15630 learning_Rate = 0.01000 rmse=1.06011 mae=0.82127\n",
      "<class 'data.RSContext'> iteration 126: loss = 1257.5117, delta_loss = 8.00885 learning_Rate = 0.01000 rmse=1.06074 mae=0.82172\n",
      "<class 'data.RSContext'> iteration 127: loss = 1249.6465, delta_loss = 7.86526 learning_Rate = 0.01000 rmse=1.06136 mae=0.82217\n",
      "<class 'data.RSContext'> iteration 128: loss = 1241.9211, delta_loss = 7.72538 learning_Rate = 0.01000 rmse=1.06198 mae=0.82261\n",
      "<class 'data.RSContext'> iteration 129: loss = 1234.3320, delta_loss = 7.58909 learning_Rate = 0.01000 rmse=1.06259 mae=0.82305\n",
      "<class 'data.RSContext'> iteration 130: loss = 1226.8757, delta_loss = 7.45628 learning_Rate = 0.01000 rmse=1.06320 mae=0.82349\n",
      "<class 'data.RSContext'> iteration 131: loss = 1219.5489, delta_loss = 7.32683 learning_Rate = 0.01000 rmse=1.06380 mae=0.82392\n",
      "<class 'data.RSContext'> iteration 132: loss = 1212.3483, delta_loss = 7.20062 learning_Rate = 0.01000 rmse=1.06439 mae=0.82435\n",
      "<class 'data.RSContext'> iteration 133: loss = 1205.2707, delta_loss = 7.07756 learning_Rate = 0.01000 rmse=1.06497 mae=0.82477\n",
      "<class 'data.RSContext'> iteration 134: loss = 1198.3132, delta_loss = 6.95755 learning_Rate = 0.01000 rmse=1.06555 mae=0.82519\n",
      "<class 'data.RSContext'> iteration 135: loss = 1191.4727, delta_loss = 6.84048 learning_Rate = 0.01000 rmse=1.06612 mae=0.82561\n",
      "<class 'data.RSContext'> iteration 136: loss = 1184.7464, delta_loss = 6.72626 learning_Rate = 0.01000 rmse=1.06669 mae=0.82602\n",
      "<class 'data.RSContext'> iteration 137: loss = 1178.1316, delta_loss = 6.61480 learning_Rate = 0.01000 rmse=1.06725 mae=0.82643\n",
      "<class 'data.RSContext'> iteration 138: loss = 1171.6256, delta_loss = 6.50602 learning_Rate = 0.01000 rmse=1.06781 mae=0.82684\n",
      "<class 'data.RSContext'> iteration 139: loss = 1165.2258, delta_loss = 6.39984 learning_Rate = 0.01000 rmse=1.06837 mae=0.82726\n",
      "<class 'data.RSContext'> iteration 140: loss = 1158.9296, delta_loss = 6.29616 learning_Rate = 0.01000 rmse=1.06893 mae=0.82766\n",
      "<class 'data.RSContext'> iteration 141: loss = 1152.7347, delta_loss = 6.19492 learning_Rate = 0.01000 rmse=1.06947 mae=0.82806\n",
      "<class 'data.RSContext'> iteration 142: loss = 1146.6386, delta_loss = 6.09605 learning_Rate = 0.01000 rmse=1.07002 mae=0.82846\n",
      "<class 'data.RSContext'> iteration 143: loss = 1140.6392, delta_loss = 5.99946 learning_Rate = 0.01000 rmse=1.07055 mae=0.82886\n",
      "<class 'data.RSContext'> iteration 144: loss = 1134.7341, delta_loss = 5.90509 learning_Rate = 0.01000 rmse=1.07108 mae=0.82925\n",
      "<class 'data.RSContext'> iteration 145: loss = 1128.9212, delta_loss = 5.81289 learning_Rate = 0.01000 rmse=1.07161 mae=0.82965\n",
      "<class 'data.RSContext'> iteration 146: loss = 1123.1984, delta_loss = 5.72277 learning_Rate = 0.01000 rmse=1.07213 mae=0.83004\n",
      "<class 'data.RSContext'> iteration 147: loss = 1117.5637, delta_loss = 5.63469 learning_Rate = 0.01000 rmse=1.07264 mae=0.83042\n",
      "<class 'data.RSContext'> iteration 148: loss = 1112.0152, delta_loss = 5.54857 learning_Rate = 0.01000 rmse=1.07315 mae=0.83080\n",
      "<class 'data.RSContext'> iteration 149: loss = 1106.5508, delta_loss = 5.46438 learning_Rate = 0.01000 rmse=1.07366 mae=0.83118\n",
      "<class 'data.RSContext'> iteration 150: loss = 1101.1688, delta_loss = 5.38204 learning_Rate = 0.01000 rmse=1.07416 mae=0.83156\n",
      "<class 'data.RSContext'> iteration 151: loss = 1095.8672, delta_loss = 5.30151 learning_Rate = 0.01000 rmse=1.07466 mae=0.83194\n",
      "<class 'data.RSContext'> iteration 152: loss = 1090.6445, delta_loss = 5.22274 learning_Rate = 0.01000 rmse=1.07515 mae=0.83232\n",
      "<class 'data.RSContext'> iteration 153: loss = 1085.4988, delta_loss = 5.14567 learning_Rate = 0.01000 rmse=1.07564 mae=0.83269\n",
      "<class 'data.RSContext'> iteration 154: loss = 1080.4286, delta_loss = 5.07027 learning_Rate = 0.01000 rmse=1.07613 mae=0.83306\n",
      "<class 'data.RSContext'> iteration 155: loss = 1075.4321, delta_loss = 4.99648 learning_Rate = 0.01000 rmse=1.07662 mae=0.83343\n",
      "<class 'data.RSContext'> iteration 156: loss = 1070.5078, delta_loss = 4.92425 learning_Rate = 0.01000 rmse=1.07709 mae=0.83380\n",
      "<class 'data.RSContext'> iteration 157: loss = 1065.6543, delta_loss = 4.85356 learning_Rate = 0.01000 rmse=1.07757 mae=0.83416\n",
      "<class 'data.RSContext'> iteration 158: loss = 1060.8699, delta_loss = 4.78435 learning_Rate = 0.01000 rmse=1.07805 mae=0.83452\n",
      "<class 'data.RSContext'> iteration 159: loss = 1056.1533, delta_loss = 4.71658 learning_Rate = 0.01000 rmse=1.07852 mae=0.83488\n",
      "<class 'data.RSContext'> iteration 160: loss = 1051.5031, delta_loss = 4.65022 learning_Rate = 0.01000 rmse=1.07899 mae=0.83524\n",
      "current best rmse is 1.07899, mae is 0.83524\n",
      "80023\n",
      "19977\n",
      "cold start users count 0\n",
      "{\n",
      "    'dataset_name': 'u',\n",
      "    'k_fold_num': 5,\n",
      "    'k_test': 0,\n",
      "    'rating_path': 'Z:/RSA/data/u_ratings.txt',\n",
      "    'rating_cv_path': 'Z:/RSA/data/cv/',\n",
      "    'trust_path': 'Z:/RSA/data/u_trust.txt',\n",
      "    'sep': ' ',\n",
      "    'random_state': 0,\n",
      "    'size': 0.8,\n",
      "    'min_val': 0.5,\n",
      "    'max_val': 4.0,\n",
      "    'coldUserRating': 5,\n",
      "    'factor': 10,\n",
      "    'threshold': 0.0001,\n",
      "    'lr': 0.01,\n",
      "    'maxIter': 100,\n",
      "    'lambdaP': 0.001,\n",
      "    'lambdaQ': 0.001,\n",
      "    'gamma': 0,\n",
      "    'isEarlyStopping': False,\n",
      "    'result_path': '../results/',\n",
      "    'model_path': 'model/',\n",
      "    'result_log_path': 'log/'\n",
      "}\n",
      "80023\n",
      "19977\n",
      "cold start users count 0\n",
      "80023\n",
      "19977\n",
      "cold start users count 0\n",
      "<class 'data.RSContext'> iteration 1: loss = 31328.5517, delta_loss = -31328.55168 learning_Rate = 0.01000 rmse=1.10310 mae=0.86329\n",
      "<class 'data.RSContext'> iteration 2: loss = 7568.3149, delta_loss = 23760.23675 learning_Rate = 0.01000 rmse=1.01515 mae=0.79352\n",
      "<class 'data.RSContext'> iteration 3: loss = 6637.0142, delta_loss = 931.30078 learning_Rate = 0.01000 rmse=1.00045 mae=0.78243\n",
      "<class 'data.RSContext'> iteration 4: loss = 6390.1063, delta_loss = 246.90784 learning_Rate = 0.01000 rmse=0.99574 mae=0.77979\n",
      "<class 'data.RSContext'> iteration 5: loss = 6262.9093, delta_loss = 127.19703 learning_Rate = 0.01000 rmse=0.99347 mae=0.77881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'data.RSContext'> iteration 6: loss = 6174.4558, delta_loss = 88.45345 learning_Rate = 0.01000 rmse=0.99207 mae=0.77805\n",
      "<class 'data.RSContext'> iteration 7: loss = 6103.2418, delta_loss = 71.21402 learning_Rate = 0.01000 rmse=0.99092 mae=0.77747\n",
      "<class 'data.RSContext'> iteration 8: loss = 6040.8975, delta_loss = 62.34430 learning_Rate = 0.01000 rmse=0.99002 mae=0.77700\n",
      "<class 'data.RSContext'> iteration 9: loss = 5983.2326, delta_loss = 57.66486 learning_Rate = 0.01000 rmse=0.98930 mae=0.77661\n",
      "<class 'data.RSContext'> iteration 10: loss = 5927.7759, delta_loss = 55.45677 learning_Rate = 0.01000 rmse=0.98868 mae=0.77622\n",
      "<class 'data.RSContext'> iteration 11: loss = 5872.8945, delta_loss = 54.88140 learning_Rate = 0.01000 rmse=0.98810 mae=0.77586\n",
      "<class 'data.RSContext'> iteration 12: loss = 5817.4149, delta_loss = 55.47959 learning_Rate = 0.01000 rmse=0.98751 mae=0.77549\n",
      "<class 'data.RSContext'> iteration 13: loss = 5760.4389, delta_loss = 56.97601 learning_Rate = 0.01000 rmse=0.98688 mae=0.77508\n",
      "<class 'data.RSContext'> iteration 14: loss = 5701.2496, delta_loss = 59.18930 learning_Rate = 0.01000 rmse=0.98623 mae=0.77464\n",
      "<class 'data.RSContext'> iteration 15: loss = 5639.2641, delta_loss = 61.98544 learning_Rate = 0.01000 rmse=0.98557 mae=0.77417\n",
      "<class 'data.RSContext'> iteration 16: loss = 5574.0131, delta_loss = 65.25100 learning_Rate = 0.01000 rmse=0.98488 mae=0.77366\n",
      "<class 'data.RSContext'> iteration 17: loss = 5505.1361, delta_loss = 68.87708 learning_Rate = 0.01000 rmse=0.98414 mae=0.77311\n",
      "<class 'data.RSContext'> iteration 18: loss = 5432.3862, delta_loss = 72.74988 learning_Rate = 0.01000 rmse=0.98336 mae=0.77250\n",
      "<class 'data.RSContext'> iteration 19: loss = 5355.6398, delta_loss = 76.74634 learning_Rate = 0.01000 rmse=0.98254 mae=0.77185\n",
      "<class 'data.RSContext'> iteration 20: loss = 5274.9052, delta_loss = 80.73463 learning_Rate = 0.01000 rmse=0.98167 mae=0.77112\n",
      "<class 'data.RSContext'> iteration 21: loss = 5190.3263, delta_loss = 84.57886 learning_Rate = 0.01000 rmse=0.98078 mae=0.77036\n",
      "<class 'data.RSContext'> iteration 22: loss = 5102.1788, delta_loss = 88.14758 learning_Rate = 0.01000 rmse=0.97984 mae=0.76953\n",
      "<class 'data.RSContext'> iteration 23: loss = 5010.8543, delta_loss = 91.32443 learning_Rate = 0.01000 rmse=0.97887 mae=0.76866\n",
      "<class 'data.RSContext'> iteration 24: loss = 4916.8355, delta_loss = 94.01880 learning_Rate = 0.01000 rmse=0.97789 mae=0.76777\n",
      "<class 'data.RSContext'> iteration 25: loss = 4820.6618, delta_loss = 96.17375 learning_Rate = 0.01000 rmse=0.97691 mae=0.76686\n",
      "<class 'data.RSContext'> iteration 26: loss = 4722.8927, delta_loss = 97.76911 learning_Rate = 0.01000 rmse=0.97595 mae=0.76598\n",
      "<class 'data.RSContext'> iteration 27: loss = 4624.0738, delta_loss = 98.81891 learning_Rate = 0.01000 rmse=0.97506 mae=0.76514\n",
      "<class 'data.RSContext'> iteration 28: loss = 4524.7099, delta_loss = 99.36388 learning_Rate = 0.01000 rmse=0.97422 mae=0.76434\n",
      "<class 'data.RSContext'> iteration 29: loss = 4425.2488, delta_loss = 99.46110 learning_Rate = 0.01000 rmse=0.97346 mae=0.76361\n",
      "<class 'data.RSContext'> iteration 30: loss = 4326.0751, delta_loss = 99.17368 learning_Rate = 0.01000 rmse=0.97279 mae=0.76295\n",
      "<class 'data.RSContext'> iteration 31: loss = 4227.5127, delta_loss = 98.56240 learning_Rate = 0.01000 rmse=0.97221 mae=0.76235\n",
      "<class 'data.RSContext'> iteration 32: loss = 4129.8320, delta_loss = 97.68067 learning_Rate = 0.01000 rmse=0.97173 mae=0.76184\n",
      "<class 'data.RSContext'> iteration 33: loss = 4033.2595, delta_loss = 96.57251 learning_Rate = 0.01000 rmse=0.97136 mae=0.76141\n",
      "<class 'data.RSContext'> iteration 34: loss = 3937.9866, delta_loss = 95.27292 learning_Rate = 0.01000 rmse=0.97112 mae=0.76108\n",
      "<class 'data.RSContext'> iteration 35: loss = 3844.1771, delta_loss = 93.80945 learning_Rate = 0.01000 rmse=0.97100 mae=0.76085\n",
      "<class 'data.RSContext'> iteration 36: loss = 3751.9729, delta_loss = 92.20420 learning_Rate = 0.01000 rmse=0.97098 mae=0.76071\n",
      "<class 'data.RSContext'> iteration 37: loss = 3661.4973, delta_loss = 90.47561 learning_Rate = 0.01000 rmse=0.97106 mae=0.76064\n",
      "<class 'data.RSContext'> iteration 38: loss = 3572.8575, delta_loss = 88.63981 learning_Rate = 0.01000 rmse=0.97123 mae=0.76066\n",
      "<class 'data.RSContext'> iteration 39: loss = 3486.1459, delta_loss = 86.71158 learning_Rate = 0.01000 rmse=0.97148 mae=0.76075\n",
      "<class 'data.RSContext'> iteration 40: loss = 3401.4411, delta_loss = 84.70489 learning_Rate = 0.01000 rmse=0.97183 mae=0.76090\n",
      "<class 'data.RSContext'> iteration 41: loss = 3318.8078, delta_loss = 82.63325 learning_Rate = 0.01000 rmse=0.97227 mae=0.76112\n",
      "<class 'data.RSContext'> iteration 42: loss = 3238.2980, delta_loss = 80.50981 learning_Rate = 0.01000 rmse=0.97279 mae=0.76139\n",
      "<class 'data.RSContext'> iteration 43: loss = 3159.9506, delta_loss = 78.34743 learning_Rate = 0.01000 rmse=0.97339 mae=0.76171\n",
      "<class 'data.RSContext'> iteration 44: loss = 3083.7920, delta_loss = 76.15854 learning_Rate = 0.01000 rmse=0.97407 mae=0.76209\n",
      "<class 'data.RSContext'> iteration 45: loss = 3009.8369, delta_loss = 73.95515 learning_Rate = 0.01000 rmse=0.97483 mae=0.76253\n",
      "<class 'data.RSContext'> iteration 46: loss = 2938.0883, delta_loss = 71.74860 learning_Rate = 0.01000 rmse=0.97567 mae=0.76302\n",
      "<class 'data.RSContext'> iteration 47: loss = 2868.5388, delta_loss = 69.54950 learning_Rate = 0.01000 rmse=0.97658 mae=0.76355\n",
      "<class 'data.RSContext'> iteration 48: loss = 2801.1712, delta_loss = 67.36761 learning_Rate = 0.01000 rmse=0.97755 mae=0.76412\n",
      "<class 'data.RSContext'> iteration 49: loss = 2735.9595, delta_loss = 65.21166 learning_Rate = 0.01000 rmse=0.97855 mae=0.76472\n",
      "<class 'data.RSContext'> iteration 50: loss = 2672.8702, delta_loss = 63.08937 learning_Rate = 0.01000 rmse=0.97960 mae=0.76537\n",
      "<class 'data.RSContext'> iteration 51: loss = 2611.8628, delta_loss = 61.00736 learning_Rate = 0.01000 rmse=0.98069 mae=0.76606\n",
      "<class 'data.RSContext'> iteration 52: loss = 2552.8916, delta_loss = 58.97118 learning_Rate = 0.01000 rmse=0.98180 mae=0.76677\n",
      "<class 'data.RSContext'> iteration 53: loss = 2495.9063, delta_loss = 56.98532 learning_Rate = 0.01000 rmse=0.98295 mae=0.76751\n",
      "<class 'data.RSContext'> iteration 54: loss = 2440.8530, delta_loss = 55.05331 learning_Rate = 0.01000 rmse=0.98413 mae=0.76828\n",
      "<class 'data.RSContext'> iteration 55: loss = 2387.6753, delta_loss = 53.17773 learning_Rate = 0.01000 rmse=0.98533 mae=0.76907\n",
      "<class 'data.RSContext'> iteration 56: loss = 2336.3149, delta_loss = 51.36040 learning_Rate = 0.01000 rmse=0.98655 mae=0.76988\n",
      "<class 'data.RSContext'> iteration 57: loss = 2286.7125, delta_loss = 49.60238 learning_Rate = 0.01000 rmse=0.98780 mae=0.77072\n",
      "<class 'data.RSContext'> iteration 58: loss = 2238.8083, delta_loss = 47.90414 learning_Rate = 0.01000 rmse=0.98906 mae=0.77157\n",
      "<class 'data.RSContext'> iteration 59: loss = 2192.5427, delta_loss = 46.26561 learning_Rate = 0.01000 rmse=0.99034 mae=0.77244\n",
      "<class 'data.RSContext'> iteration 60: loss = 2147.8564, delta_loss = 44.68630 learning_Rate = 0.01000 rmse=0.99163 mae=0.77332\n",
      "<class 'data.RSContext'> iteration 61: loss = 2104.6911, delta_loss = 43.16538 learning_Rate = 0.01000 rmse=0.99292 mae=0.77420\n",
      "<class 'data.RSContext'> iteration 62: loss = 2062.9893, delta_loss = 41.70171 learning_Rate = 0.01000 rmse=0.99421 mae=0.77507\n",
      "<class 'data.RSContext'> iteration 63: loss = 2022.6954, delta_loss = 40.29397 learning_Rate = 0.01000 rmse=0.99551 mae=0.77595\n",
      "<class 'data.RSContext'> iteration 64: loss = 1983.7547, delta_loss = 38.94066 learning_Rate = 0.01000 rmse=0.99681 mae=0.77683\n",
      "<class 'data.RSContext'> iteration 65: loss = 1946.1146, delta_loss = 37.64015 learning_Rate = 0.01000 rmse=0.99810 mae=0.77769\n",
      "<class 'data.RSContext'> iteration 66: loss = 1909.7238, delta_loss = 36.39076 learning_Rate = 0.01000 rmse=0.99939 mae=0.77855\n",
      "<class 'data.RSContext'> iteration 67: loss = 1874.5331, delta_loss = 35.19074 learning_Rate = 0.01000 rmse=1.00067 mae=0.77939\n",
      "<class 'data.RSContext'> iteration 68: loss = 1840.4948, delta_loss = 34.03831 learning_Rate = 0.01000 rmse=1.00193 mae=0.78024\n",
      "<class 'data.RSContext'> iteration 69: loss = 1807.5630, delta_loss = 32.93172 learning_Rate = 0.01000 rmse=1.00319 mae=0.78110\n",
      "<class 'data.RSContext'> iteration 70: loss = 1775.6938, delta_loss = 31.86918 learning_Rate = 0.01000 rmse=1.00444 mae=0.78195\n",
      "<class 'data.RSContext'> iteration 71: loss = 1744.8449, delta_loss = 30.84897 learning_Rate = 0.01000 rmse=1.00568 mae=0.78279\n",
      "<class 'data.RSContext'> iteration 72: loss = 1714.9755, delta_loss = 29.86938 learning_Rate = 0.01000 rmse=1.00690 mae=0.78362\n",
      "<class 'data.RSContext'> iteration 73: loss = 1686.0468, delta_loss = 28.92873 learning_Rate = 0.01000 rmse=1.00812 mae=0.78444\n",
      "<class 'data.RSContext'> iteration 74: loss = 1658.0214, delta_loss = 28.02541 learning_Rate = 0.01000 rmse=1.00932 mae=0.78527\n",
      "<class 'data.RSContext'> iteration 75: loss = 1630.8635, delta_loss = 27.15784 learning_Rate = 0.01000 rmse=1.01051 mae=0.78609\n",
      "<class 'data.RSContext'> iteration 76: loss = 1604.5390, delta_loss = 26.32449 learning_Rate = 0.01000 rmse=1.01169 mae=0.78691\n",
      "<class 'data.RSContext'> iteration 77: loss = 1579.0151, delta_loss = 25.52391 learning_Rate = 0.01000 rmse=1.01285 mae=0.78772\n",
      "<class 'data.RSContext'> iteration 78: loss = 1554.2605, delta_loss = 24.75466 learning_Rate = 0.01000 rmse=1.01399 mae=0.78852\n",
      "<class 'data.RSContext'> iteration 79: loss = 1530.2451, delta_loss = 24.01540 learning_Rate = 0.01000 rmse=1.01513 mae=0.78931\n",
      "<class 'data.RSContext'> iteration 80: loss = 1506.9403, delta_loss = 23.30481 learning_Rate = 0.01000 rmse=1.01625 mae=0.79009\n",
      "<class 'data.RSContext'> iteration 81: loss = 1484.3186, delta_loss = 22.62164 learning_Rate = 0.01000 rmse=1.01735 mae=0.79085\n",
      "<class 'data.RSContext'> iteration 82: loss = 1462.3539, delta_loss = 21.96468 learning_Rate = 0.01000 rmse=1.01843 mae=0.79161\n",
      "<class 'data.RSContext'> iteration 83: loss = 1441.0211, delta_loss = 21.33278 learning_Rate = 0.01000 rmse=1.01950 mae=0.79235\n",
      "<class 'data.RSContext'> iteration 84: loss = 1420.2963, delta_loss = 20.72485 learning_Rate = 0.01000 rmse=1.02056 mae=0.79310\n",
      "<class 'data.RSContext'> iteration 85: loss = 1400.1565, delta_loss = 20.13983 learning_Rate = 0.01000 rmse=1.02161 mae=0.79383\n",
      "<class 'data.RSContext'> iteration 86: loss = 1380.5798, delta_loss = 19.57671 learning_Rate = 0.01000 rmse=1.02265 mae=0.79456\n",
      "<class 'data.RSContext'> iteration 87: loss = 1361.5452, delta_loss = 19.03453 learning_Rate = 0.01000 rmse=1.02366 mae=0.79527\n",
      "<class 'data.RSContext'> iteration 88: loss = 1343.0329, delta_loss = 18.51238 learning_Rate = 0.01000 rmse=1.02467 mae=0.79598\n",
      "<class 'data.RSContext'> iteration 89: loss = 1325.0235, delta_loss = 18.00938 learning_Rate = 0.01000 rmse=1.02565 mae=0.79668\n",
      "<class 'data.RSContext'> iteration 90: loss = 1307.4988, delta_loss = 17.52470 learning_Rate = 0.01000 rmse=1.02663 mae=0.79736\n",
      "<class 'data.RSContext'> iteration 91: loss = 1290.4412, delta_loss = 17.05754 learning_Rate = 0.01000 rmse=1.02761 mae=0.79806\n",
      "<class 'data.RSContext'> iteration 92: loss = 1273.8341, delta_loss = 16.60714 learning_Rate = 0.01000 rmse=1.02857 mae=0.79875\n",
      "<class 'data.RSContext'> iteration 93: loss = 1257.6613, delta_loss = 16.17279 learning_Rate = 0.01000 rmse=1.02952 mae=0.79944\n",
      "<class 'data.RSContext'> iteration 94: loss = 1241.9075, delta_loss = 15.75378 learning_Rate = 0.01000 rmse=1.03047 mae=0.80011\n",
      "<class 'data.RSContext'> iteration 95: loss = 1226.5581, delta_loss = 15.34947 learning_Rate = 0.01000 rmse=1.03140 mae=0.80079\n",
      "<class 'data.RSContext'> iteration 96: loss = 1211.5988, delta_loss = 14.95923 learning_Rate = 0.01000 rmse=1.03232 mae=0.80147\n",
      "<class 'data.RSContext'> iteration 97: loss = 1197.0164, delta_loss = 14.58246 learning_Rate = 0.01000 rmse=1.03324 mae=0.80215\n",
      "<class 'data.RSContext'> iteration 98: loss = 1182.7978, delta_loss = 14.21860 learning_Rate = 0.01000 rmse=1.03414 mae=0.80281\n",
      "<class 'data.RSContext'> iteration 99: loss = 1168.9307, delta_loss = 13.86710 learning_Rate = 0.01000 rmse=1.03504 mae=0.80347\n",
      "<class 'data.RSContext'> iteration 100: loss = 1155.4032, delta_loss = 13.52745 learning_Rate = 0.01000 rmse=1.03592 mae=0.80411\n",
      "<class 'data.RSContext'> iteration 101: loss = 1142.2040, delta_loss = 13.19916 learning_Rate = 0.01000 rmse=1.03679 mae=0.80475\n",
      "<class 'data.RSContext'> iteration 102: loss = 1129.3223, delta_loss = 12.88176 learning_Rate = 0.01000 rmse=1.03766 mae=0.80539\n",
      "<class 'data.RSContext'> iteration 103: loss = 1116.7475, delta_loss = 12.57480 learning_Rate = 0.01000 rmse=1.03852 mae=0.80602\n",
      "<class 'data.RSContext'> iteration 104: loss = 1104.4696, delta_loss = 12.27785 learning_Rate = 0.01000 rmse=1.03937 mae=0.80665\n",
      "<class 'data.RSContext'> iteration 105: loss = 1092.4791, delta_loss = 11.99052 learning_Rate = 0.01000 rmse=1.04021 mae=0.80726\n",
      "<class 'data.RSContext'> iteration 106: loss = 1080.7667, delta_loss = 11.71241 learning_Rate = 0.01000 rmse=1.04104 mae=0.80787\n",
      "<class 'data.RSContext'> iteration 107: loss = 1069.3235, delta_loss = 11.44317 learning_Rate = 0.01000 rmse=1.04187 mae=0.80848\n",
      "<class 'data.RSContext'> iteration 108: loss = 1058.1411, delta_loss = 11.18242 learning_Rate = 0.01000 rmse=1.04267 mae=0.80907\n",
      "<class 'data.RSContext'> iteration 109: loss = 1047.2113, delta_loss = 10.92985 learning_Rate = 0.01000 rmse=1.04348 mae=0.80967\n",
      "<class 'data.RSContext'> iteration 110: loss = 1036.5261, delta_loss = 10.68514 learning_Rate = 0.01000 rmse=1.04428 mae=0.81025\n",
      "<class 'data.RSContext'> iteration 111: loss = 1026.0782, delta_loss = 10.44797 learning_Rate = 0.01000 rmse=1.04506 mae=0.81082\n",
      "<class 'data.RSContext'> iteration 112: loss = 1015.8601, delta_loss = 10.21805 learning_Rate = 0.01000 rmse=1.04584 mae=0.81139\n",
      "<class 'data.RSContext'> iteration 113: loss = 1005.8650, delta_loss = 9.99512 learning_Rate = 0.01000 rmse=1.04661 mae=0.81196\n",
      "<class 'data.RSContext'> iteration 114: loss = 996.0861, delta_loss = 9.77890 learning_Rate = 0.01000 rmse=1.04737 mae=0.81252\n",
      "<class 'data.RSContext'> iteration 115: loss = 986.5169, delta_loss = 9.56914 learning_Rate = 0.01000 rmse=1.04813 mae=0.81307\n",
      "<class 'data.RSContext'> iteration 116: loss = 977.1513, delta_loss = 9.36560 learning_Rate = 0.01000 rmse=1.04889 mae=0.81362\n",
      "<class 'data.RSContext'> iteration 117: loss = 967.9833, delta_loss = 9.16805 learning_Rate = 0.01000 rmse=1.04963 mae=0.81417\n",
      "<class 'data.RSContext'> iteration 118: loss = 959.0070, delta_loss = 8.97627 learning_Rate = 0.01000 rmse=1.05036 mae=0.81471\n",
      "<class 'data.RSContext'> iteration 119: loss = 950.2170, delta_loss = 8.79005 learning_Rate = 0.01000 rmse=1.05109 mae=0.81525\n",
      "<class 'data.RSContext'> iteration 120: loss = 941.6078, delta_loss = 8.60918 learning_Rate = 0.01000 rmse=1.05182 mae=0.81579\n",
      "<class 'data.RSContext'> iteration 121: loss = 933.1743, delta_loss = 8.43347 learning_Rate = 0.01000 rmse=1.05253 mae=0.81632\n",
      "<class 'data.RSContext'> iteration 122: loss = 924.9116, delta_loss = 8.26275 learning_Rate = 0.01000 rmse=1.05324 mae=0.81685\n",
      "<class 'data.RSContext'> iteration 123: loss = 916.8148, delta_loss = 8.09682 learning_Rate = 0.01000 rmse=1.05394 mae=0.81737\n",
      "<class 'data.RSContext'> iteration 124: loss = 908.8792, delta_loss = 7.93553 learning_Rate = 0.01000 rmse=1.05463 mae=0.81788\n",
      "<class 'data.RSContext'> iteration 125: loss = 901.1005, delta_loss = 7.77871 learning_Rate = 0.01000 rmse=1.05532 mae=0.81840\n",
      "<class 'data.RSContext'> iteration 126: loss = 893.4743, delta_loss = 7.62621 learning_Rate = 0.01000 rmse=1.05599 mae=0.81890\n",
      "<class 'data.RSContext'> iteration 127: loss = 885.9965, delta_loss = 7.47787 learning_Rate = 0.01000 rmse=1.05666 mae=0.81939\n",
      "<class 'data.RSContext'> iteration 128: loss = 878.6629, delta_loss = 7.33356 learning_Rate = 0.01000 rmse=1.05733 mae=0.81988\n",
      "<class 'data.RSContext'> iteration 129: loss = 871.4698, delta_loss = 7.19313 learning_Rate = 0.01000 rmse=1.05799 mae=0.82037\n",
      "<class 'data.RSContext'> iteration 130: loss = 864.4133, delta_loss = 7.05647 learning_Rate = 0.01000 rmse=1.05864 mae=0.82085\n",
      "<class 'data.RSContext'> iteration 131: loss = 857.4899, delta_loss = 6.92343 learning_Rate = 0.01000 rmse=1.05929 mae=0.82133\n",
      "<class 'data.RSContext'> iteration 132: loss = 850.6960, delta_loss = 6.79391 learning_Rate = 0.01000 rmse=1.05993 mae=0.82180\n",
      "<class 'data.RSContext'> iteration 133: loss = 844.0282, delta_loss = 6.66778 learning_Rate = 0.01000 rmse=1.06056 mae=0.82226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'data.RSContext'> iteration 134: loss = 837.4833, delta_loss = 6.54493 learning_Rate = 0.01000 rmse=1.06119 mae=0.82272\n",
      "<class 'data.RSContext'> iteration 135: loss = 831.0580, delta_loss = 6.42526 learning_Rate = 0.01000 rmse=1.06181 mae=0.82318\n",
      "<class 'data.RSContext'> iteration 136: loss = 824.7493, delta_loss = 6.30866 learning_Rate = 0.01000 rmse=1.06243 mae=0.82364\n",
      "<class 'data.RSContext'> iteration 137: loss = 818.5543, delta_loss = 6.19504 learning_Rate = 0.01000 rmse=1.06304 mae=0.82409\n",
      "<class 'data.RSContext'> iteration 138: loss = 812.4700, delta_loss = 6.08430 learning_Rate = 0.01000 rmse=1.06364 mae=0.82453\n",
      "<class 'data.RSContext'> iteration 139: loss = 806.4936, delta_loss = 5.97635 learning_Rate = 0.01000 rmse=1.06424 mae=0.82497\n",
      "<class 'data.RSContext'> iteration 140: loss = 800.6225, delta_loss = 5.87110 learning_Rate = 0.01000 rmse=1.06483 mae=0.82540\n",
      "<class 'data.RSContext'> iteration 141: loss = 794.8541, delta_loss = 5.76846 learning_Rate = 0.01000 rmse=1.06541 mae=0.82583\n",
      "<class 'data.RSContext'> iteration 142: loss = 789.1857, delta_loss = 5.66836 learning_Rate = 0.01000 rmse=1.06599 mae=0.82626\n",
      "<class 'data.RSContext'> iteration 143: loss = 783.6150, delta_loss = 5.57072 learning_Rate = 0.01000 rmse=1.06656 mae=0.82668\n",
      "<class 'data.RSContext'> iteration 144: loss = 778.1395, delta_loss = 5.47545 learning_Rate = 0.01000 rmse=1.06713 mae=0.82710\n",
      "<class 'data.RSContext'> iteration 145: loss = 772.7570, delta_loss = 5.38250 learning_Rate = 0.01000 rmse=1.06769 mae=0.82752\n",
      "<class 'data.RSContext'> iteration 146: loss = 767.4653, delta_loss = 5.29178 learning_Rate = 0.01000 rmse=1.06825 mae=0.82793\n",
      "<class 'data.RSContext'> iteration 147: loss = 762.2620, delta_loss = 5.20323 learning_Rate = 0.01000 rmse=1.06880 mae=0.82834\n",
      "<class 'data.RSContext'> iteration 148: loss = 757.1452, delta_loss = 5.11679 learning_Rate = 0.01000 rmse=1.06935 mae=0.82874\n",
      "<class 'data.RSContext'> iteration 149: loss = 752.1129, delta_loss = 5.03238 learning_Rate = 0.01000 rmse=1.06989 mae=0.82914\n",
      "<class 'data.RSContext'> iteration 150: loss = 747.1629, delta_loss = 4.94996 learning_Rate = 0.01000 rmse=1.07043 mae=0.82955\n",
      "<class 'data.RSContext'> iteration 151: loss = 742.2934, delta_loss = 4.86947 learning_Rate = 0.01000 rmse=1.07097 mae=0.82995\n",
      "<class 'data.RSContext'> iteration 152: loss = 737.5026, delta_loss = 4.79084 learning_Rate = 0.01000 rmse=1.07149 mae=0.83035\n",
      "<class 'data.RSContext'> iteration 153: loss = 732.7886, delta_loss = 4.71402 learning_Rate = 0.01000 rmse=1.07202 mae=0.83074\n",
      "<class 'data.RSContext'> iteration 154: loss = 728.1496, delta_loss = 4.63896 learning_Rate = 0.01000 rmse=1.07254 mae=0.83113\n",
      "<class 'data.RSContext'> iteration 155: loss = 723.5840, delta_loss = 4.56561 learning_Rate = 0.01000 rmse=1.07305 mae=0.83151\n",
      "<class 'data.RSContext'> iteration 156: loss = 719.0901, delta_loss = 4.49392 learning_Rate = 0.01000 rmse=1.07356 mae=0.83189\n",
      "<class 'data.RSContext'> iteration 157: loss = 714.6662, delta_loss = 4.42384 learning_Rate = 0.01000 rmse=1.07407 mae=0.83227\n",
      "<class 'data.RSContext'> iteration 158: loss = 710.3109, delta_loss = 4.35533 learning_Rate = 0.01000 rmse=1.07456 mae=0.83264\n",
      "<class 'data.RSContext'> iteration 159: loss = 706.0226, delta_loss = 4.28834 learning_Rate = 0.01000 rmse=1.07507 mae=0.83301\n",
      "<class 'data.RSContext'> iteration 160: loss = 701.7997, delta_loss = 4.22283 learning_Rate = 0.01000 rmse=1.07555 mae=0.83338\n",
      "current best rmse is 1.07555, mae is 0.83338\n",
      "80023\n",
      "19977\n",
      "cold start users count 0\n",
      "{\n",
      "    'dataset_name': 'u',\n",
      "    'k_fold_num': 5,\n",
      "    'k_test': 0,\n",
      "    'rating_path': 'Z:/RSA/data/u_ratings.txt',\n",
      "    'rating_cv_path': 'Z:/RSA/data/cv/',\n",
      "    'trust_path': 'Z:/RSA/data/u_trust.txt',\n",
      "    'sep': ' ',\n",
      "    'random_state': 0,\n",
      "    'size': 0.8,\n",
      "    'min_val': 0.5,\n",
      "    'max_val': 4.0,\n",
      "    'coldUserRating': 5,\n",
      "    'factor': 10,\n",
      "    'threshold': 0.0001,\n",
      "    'lr': 0.01,\n",
      "    'maxIter': 100,\n",
      "    'lambdaP': 0.001,\n",
      "    'lambdaQ': 0.001,\n",
      "    'gamma': 0,\n",
      "    'isEarlyStopping': False,\n",
      "    'result_path': '../results/',\n",
      "    'model_path': 'model/',\n",
      "    'result_log_path': 'log/'\n",
      "}\n",
      "80023\n",
      "19977\n",
      "cold start users count 0\n",
      "80023\n",
      "19977\n",
      "cold start users count 0\n",
      "<class 'data.RSContext'> iteration 1: loss = 31210.7422, delta_loss = -31210.74217 learning_Rate = 0.01000 rmse=1.10364 mae=0.86450\n",
      "<class 'data.RSContext'> iteration 2: loss = 7542.1189, delta_loss = 23668.62330 learning_Rate = 0.01000 rmse=1.01482 mae=0.79392\n",
      "<class 'data.RSContext'> iteration 3: loss = 6626.6609, delta_loss = 915.45800 learning_Rate = 0.01000 rmse=1.00048 mae=0.78292\n",
      "<class 'data.RSContext'> iteration 4: loss = 6383.7590, delta_loss = 242.90188 learning_Rate = 0.01000 rmse=0.99608 mae=0.78032\n",
      "<class 'data.RSContext'> iteration 5: loss = 6257.7630, delta_loss = 125.99598 learning_Rate = 0.01000 rmse=0.99396 mae=0.77927\n",
      "<class 'data.RSContext'> iteration 6: loss = 6169.7166, delta_loss = 88.04640 learning_Rate = 0.01000 rmse=0.99265 mae=0.77857\n",
      "<class 'data.RSContext'> iteration 7: loss = 6098.5839, delta_loss = 71.13274 learning_Rate = 0.01000 rmse=0.99160 mae=0.77805\n",
      "<class 'data.RSContext'> iteration 8: loss = 6036.1218, delta_loss = 62.46208 learning_Rate = 0.01000 rmse=0.99079 mae=0.77764\n",
      "<class 'data.RSContext'> iteration 9: loss = 5978.1805, delta_loss = 57.94125 learning_Rate = 0.01000 rmse=0.99014 mae=0.77726\n",
      "<class 'data.RSContext'> iteration 10: loss = 5922.3062, delta_loss = 55.87434 learning_Rate = 0.01000 rmse=0.98958 mae=0.77690\n",
      "<class 'data.RSContext'> iteration 11: loss = 5866.8767, delta_loss = 55.42946 learning_Rate = 0.01000 rmse=0.98901 mae=0.77655\n",
      "<class 'data.RSContext'> iteration 12: loss = 5810.7264, delta_loss = 56.15035 learning_Rate = 0.01000 rmse=0.98847 mae=0.77621\n",
      "<class 'data.RSContext'> iteration 13: loss = 5752.9622, delta_loss = 57.76414 learning_Rate = 0.01000 rmse=0.98794 mae=0.77585\n",
      "<class 'data.RSContext'> iteration 14: loss = 5692.8697, delta_loss = 60.09249 learning_Rate = 0.01000 rmse=0.98739 mae=0.77547\n",
      "<class 'data.RSContext'> iteration 15: loss = 5629.8644, delta_loss = 63.00535 learning_Rate = 0.01000 rmse=0.98681 mae=0.77505\n",
      "<class 'data.RSContext'> iteration 16: loss = 5563.4698, delta_loss = 66.39456 learning_Rate = 0.01000 rmse=0.98622 mae=0.77458\n",
      "<class 'data.RSContext'> iteration 17: loss = 5493.3118, delta_loss = 70.15808 learning_Rate = 0.01000 rmse=0.98559 mae=0.77406\n",
      "<class 'data.RSContext'> iteration 18: loss = 5419.1210, delta_loss = 74.19072 learning_Rate = 0.01000 rmse=0.98492 mae=0.77349\n",
      "<class 'data.RSContext'> iteration 19: loss = 5340.7412, delta_loss = 78.37979 learning_Rate = 0.01000 rmse=0.98422 mae=0.77289\n",
      "<class 'data.RSContext'> iteration 20: loss = 5258.1363, delta_loss = 82.60497 learning_Rate = 0.01000 rmse=0.98346 mae=0.77225\n",
      "<class 'data.RSContext'> iteration 21: loss = 5171.3944, delta_loss = 86.74183 learning_Rate = 0.01000 rmse=0.98268 mae=0.77158\n",
      "<class 'data.RSContext'> iteration 22: loss = 5080.7260, delta_loss = 90.66848 learning_Rate = 0.01000 rmse=0.98185 mae=0.77086\n",
      "<class 'data.RSContext'> iteration 23: loss = 4986.4522, delta_loss = 94.27378 learning_Rate = 0.01000 rmse=0.98102 mae=0.77014\n",
      "<class 'data.RSContext'> iteration 24: loss = 4888.9866, delta_loss = 97.46558 learning_Rate = 0.01000 rmse=0.98018 mae=0.76941\n",
      "<class 'data.RSContext'> iteration 25: loss = 4788.8096, delta_loss = 100.17697 learning_Rate = 0.01000 rmse=0.97935 mae=0.76867\n",
      "<class 'data.RSContext'> iteration 26: loss = 4686.4405, delta_loss = 102.36915 learning_Rate = 0.01000 rmse=0.97856 mae=0.76794\n",
      "<class 'data.RSContext'> iteration 27: loss = 4582.4101, delta_loss = 104.03041 learning_Rate = 0.01000 rmse=0.97781 mae=0.76724\n",
      "<class 'data.RSContext'> iteration 28: loss = 4477.2382, delta_loss = 105.17187 learning_Rate = 0.01000 rmse=0.97713 mae=0.76657\n",
      "<class 'data.RSContext'> iteration 29: loss = 4371.4169, delta_loss = 105.82133 learning_Rate = 0.01000 rmse=0.97654 mae=0.76597\n",
      "<class 'data.RSContext'> iteration 30: loss = 4265.4001, delta_loss = 106.01680 learning_Rate = 0.01000 rmse=0.97603 mae=0.76544\n",
      "<class 'data.RSContext'> iteration 31: loss = 4159.5990, delta_loss = 105.80110 learning_Rate = 0.01000 rmse=0.97562 mae=0.76497\n",
      "<class 'data.RSContext'> iteration 32: loss = 4054.3811, delta_loss = 105.21787 learning_Rate = 0.01000 rmse=0.97530 mae=0.76454\n",
      "<class 'data.RSContext'> iteration 33: loss = 3950.0718, delta_loss = 104.30929 learning_Rate = 0.01000 rmse=0.97506 mae=0.76418\n",
      "<class 'data.RSContext'> iteration 34: loss = 3846.9569, delta_loss = 103.11496 learning_Rate = 0.01000 rmse=0.97492 mae=0.76391\n",
      "<class 'data.RSContext'> iteration 35: loss = 3745.2854, delta_loss = 101.67150 learning_Rate = 0.01000 rmse=0.97490 mae=0.76372\n",
      "<class 'data.RSContext'> iteration 36: loss = 3645.2728, delta_loss = 100.01256 learning_Rate = 0.01000 rmse=0.97498 mae=0.76363\n",
      "<class 'data.RSContext'> iteration 37: loss = 3547.1038, delta_loss = 98.16895 learning_Rate = 0.01000 rmse=0.97515 mae=0.76361\n",
      "<class 'data.RSContext'> iteration 38: loss = 3450.9351, delta_loss = 96.16879 learning_Rate = 0.01000 rmse=0.97541 mae=0.76366\n",
      "<class 'data.RSContext'> iteration 39: loss = 3356.8973, delta_loss = 94.03774 learning_Rate = 0.01000 rmse=0.97576 mae=0.76380\n",
      "<class 'data.RSContext'> iteration 40: loss = 3265.0982, delta_loss = 91.79916 learning_Rate = 0.01000 rmse=0.97621 mae=0.76401\n",
      "<class 'data.RSContext'> iteration 41: loss = 3175.6238, delta_loss = 89.47435 learning_Rate = 0.01000 rmse=0.97673 mae=0.76428\n",
      "<class 'data.RSContext'> iteration 42: loss = 3088.5410, delta_loss = 87.08278 learning_Rate = 0.01000 rmse=0.97732 mae=0.76461\n",
      "<class 'data.RSContext'> iteration 43: loss = 3003.8988, delta_loss = 84.64226 learning_Rate = 0.01000 rmse=0.97798 mae=0.76501\n",
      "<class 'data.RSContext'> iteration 44: loss = 2921.7296, delta_loss = 82.16916 learning_Rate = 0.01000 rmse=0.97871 mae=0.76547\n",
      "<class 'data.RSContext'> iteration 45: loss = 2842.0511, delta_loss = 79.67852 learning_Rate = 0.01000 rmse=0.97950 mae=0.76600\n",
      "<class 'data.RSContext'> iteration 46: loss = 2764.8670, delta_loss = 77.18411 learning_Rate = 0.01000 rmse=0.98035 mae=0.76657\n",
      "<class 'data.RSContext'> iteration 47: loss = 2690.1685, delta_loss = 74.69849 learning_Rate = 0.01000 rmse=0.98127 mae=0.76720\n",
      "<class 'data.RSContext'> iteration 48: loss = 2617.9355, delta_loss = 72.23303 learning_Rate = 0.01000 rmse=0.98223 mae=0.76786\n",
      "<class 'data.RSContext'> iteration 49: loss = 2548.1376, delta_loss = 69.79786 learning_Rate = 0.01000 rmse=0.98326 mae=0.76856\n",
      "<class 'data.RSContext'> iteration 50: loss = 2480.7357, delta_loss = 67.40190 learning_Rate = 0.01000 rmse=0.98432 mae=0.76929\n",
      "<class 'data.RSContext'> iteration 51: loss = 2415.6828, delta_loss = 65.05287 learning_Rate = 0.01000 rmse=0.98543 mae=0.77006\n",
      "<class 'data.RSContext'> iteration 52: loss = 2352.9256, delta_loss = 62.75728 learning_Rate = 0.01000 rmse=0.98658 mae=0.77087\n",
      "<class 'data.RSContext'> iteration 53: loss = 2292.4051, delta_loss = 60.52046 learning_Rate = 0.01000 rmse=0.98776 mae=0.77171\n",
      "<class 'data.RSContext'> iteration 54: loss = 2234.0584, delta_loss = 58.34665 learning_Rate = 0.01000 rmse=0.98898 mae=0.77259\n",
      "<class 'data.RSContext'> iteration 55: loss = 2177.8194, delta_loss = 56.23908 learning_Rate = 0.01000 rmse=0.99021 mae=0.77349\n",
      "<class 'data.RSContext'> iteration 56: loss = 2123.6194, delta_loss = 54.19999 learning_Rate = 0.01000 rmse=0.99146 mae=0.77441\n",
      "<class 'data.RSContext'> iteration 57: loss = 2071.3886, delta_loss = 52.23080 learning_Rate = 0.01000 rmse=0.99274 mae=0.77536\n",
      "<class 'data.RSContext'> iteration 58: loss = 2021.0564, delta_loss = 50.33216 learning_Rate = 0.01000 rmse=0.99403 mae=0.77632\n",
      "<class 'data.RSContext'> iteration 59: loss = 1972.5523, delta_loss = 48.50409 learning_Rate = 0.01000 rmse=0.99533 mae=0.77726\n",
      "<class 'data.RSContext'> iteration 60: loss = 1925.8063, delta_loss = 46.74605 learning_Rate = 0.01000 rmse=0.99663 mae=0.77821\n",
      "<class 'data.RSContext'> iteration 61: loss = 1880.7492, delta_loss = 45.05702 learning_Rate = 0.01000 rmse=0.99792 mae=0.77916\n",
      "<class 'data.RSContext'> iteration 62: loss = 1837.3136, delta_loss = 43.43565 learning_Rate = 0.01000 rmse=0.99921 mae=0.78011\n",
      "<class 'data.RSContext'> iteration 63: loss = 1795.4333, delta_loss = 41.88026 learning_Rate = 0.01000 rmse=1.00050 mae=0.78106\n",
      "<class 'data.RSContext'> iteration 64: loss = 1755.0444, delta_loss = 40.38897 learning_Rate = 0.01000 rmse=1.00179 mae=0.78201\n",
      "<class 'data.RSContext'> iteration 65: loss = 1716.0847, delta_loss = 38.95971 learning_Rate = 0.01000 rmse=1.00308 mae=0.78297\n",
      "<class 'data.RSContext'> iteration 66: loss = 1678.4943, delta_loss = 37.59033 learning_Rate = 0.01000 rmse=1.00436 mae=0.78393\n",
      "<class 'data.RSContext'> iteration 67: loss = 1642.2157, delta_loss = 36.27859 learning_Rate = 0.01000 rmse=1.00564 mae=0.78490\n",
      "<class 'data.RSContext'> iteration 68: loss = 1607.1935, delta_loss = 35.02222 learning_Rate = 0.01000 rmse=1.00692 mae=0.78586\n",
      "<class 'data.RSContext'> iteration 69: loss = 1573.3746, delta_loss = 33.81894 learning_Rate = 0.01000 rmse=1.00819 mae=0.78681\n",
      "<class 'data.RSContext'> iteration 70: loss = 1540.7081, delta_loss = 32.66650 learning_Rate = 0.01000 rmse=1.00945 mae=0.78774\n",
      "<class 'data.RSContext'> iteration 71: loss = 1509.1454, delta_loss = 31.56270 learning_Rate = 0.01000 rmse=1.01069 mae=0.78866\n",
      "<class 'data.RSContext'> iteration 72: loss = 1478.6400, delta_loss = 30.50536 learning_Rate = 0.01000 rmse=1.01193 mae=0.78957\n",
      "<class 'data.RSContext'> iteration 73: loss = 1449.1476, delta_loss = 29.49239 learning_Rate = 0.01000 rmse=1.01316 mae=0.79047\n",
      "<class 'data.RSContext'> iteration 74: loss = 1420.6259, delta_loss = 28.52174 learning_Rate = 0.01000 rmse=1.01438 mae=0.79136\n",
      "<class 'data.RSContext'> iteration 75: loss = 1393.0344, delta_loss = 27.59147 learning_Rate = 0.01000 rmse=1.01558 mae=0.79226\n",
      "<class 'data.RSContext'> iteration 76: loss = 1366.3347, delta_loss = 26.69970 learning_Rate = 0.01000 rmse=1.01678 mae=0.79316\n",
      "<class 'data.RSContext'> iteration 77: loss = 1340.4901, delta_loss = 25.84462 learning_Rate = 0.01000 rmse=1.01795 mae=0.79404\n",
      "<class 'data.RSContext'> iteration 78: loss = 1315.4656, delta_loss = 25.02452 learning_Rate = 0.01000 rmse=1.01911 mae=0.79491\n",
      "<class 'data.RSContext'> iteration 79: loss = 1291.2278, delta_loss = 24.23774 learning_Rate = 0.01000 rmse=1.02026 mae=0.79578\n",
      "<class 'data.RSContext'> iteration 80: loss = 1267.7451, delta_loss = 23.48273 learning_Rate = 0.01000 rmse=1.02140 mae=0.79663\n",
      "<class 'data.RSContext'> iteration 81: loss = 1244.9871, delta_loss = 22.75799 learning_Rate = 0.01000 rmse=1.02253 mae=0.79748\n",
      "<class 'data.RSContext'> iteration 82: loss = 1222.9250, delta_loss = 22.06210 learning_Rate = 0.01000 rmse=1.02364 mae=0.79832\n",
      "<class 'data.RSContext'> iteration 83: loss = 1201.5313, delta_loss = 21.39372 learning_Rate = 0.01000 rmse=1.02475 mae=0.79916\n",
      "<class 'data.RSContext'> iteration 84: loss = 1180.7797, delta_loss = 20.75156 learning_Rate = 0.01000 rmse=1.02584 mae=0.79999\n",
      "<class 'data.RSContext'> iteration 85: loss = 1160.6453, delta_loss = 20.13440 learning_Rate = 0.01000 rmse=1.02693 mae=0.80080\n",
      "<class 'data.RSContext'> iteration 86: loss = 1141.1042, delta_loss = 19.54110 learning_Rate = 0.01000 rmse=1.02799 mae=0.80159\n",
      "<class 'data.RSContext'> iteration 87: loss = 1122.1337, delta_loss = 18.97056 learning_Rate = 0.01000 rmse=1.02905 mae=0.80238\n",
      "<class 'data.RSContext'> iteration 88: loss = 1103.7119, delta_loss = 18.42172 learning_Rate = 0.01000 rmse=1.03009 mae=0.80316\n",
      "<class 'data.RSContext'> iteration 89: loss = 1085.8183, delta_loss = 17.89362 learning_Rate = 0.01000 rmse=1.03112 mae=0.80392\n",
      "<class 'data.RSContext'> iteration 90: loss = 1068.4330, delta_loss = 17.38531 learning_Rate = 0.01000 rmse=1.03214 mae=0.80467\n",
      "<class 'data.RSContext'> iteration 91: loss = 1051.5371, delta_loss = 16.89590 learning_Rate = 0.01000 rmse=1.03315 mae=0.80542\n",
      "<class 'data.RSContext'> iteration 92: loss = 1035.1125, delta_loss = 16.42456 learning_Rate = 0.01000 rmse=1.03414 mae=0.80615\n",
      "<class 'data.RSContext'> iteration 93: loss = 1019.1421, delta_loss = 15.97047 learning_Rate = 0.01000 rmse=1.03511 mae=0.80687\n",
      "<class 'data.RSContext'> iteration 94: loss = 1003.6092, delta_loss = 15.53289 learning_Rate = 0.01000 rmse=1.03608 mae=0.80758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'data.RSContext'> iteration 95: loss = 988.4981, delta_loss = 15.11109 learning_Rate = 0.01000 rmse=1.03703 mae=0.80828\n",
      "<class 'data.RSContext'> iteration 96: loss = 973.7937, delta_loss = 14.70438 learning_Rate = 0.01000 rmse=1.03797 mae=0.80897\n",
      "<class 'data.RSContext'> iteration 97: loss = 959.4816, delta_loss = 14.31212 learning_Rate = 0.01000 rmse=1.03890 mae=0.80965\n",
      "<class 'data.RSContext'> iteration 98: loss = 945.5479, delta_loss = 13.93368 learning_Rate = 0.01000 rmse=1.03982 mae=0.81033\n",
      "<class 'data.RSContext'> iteration 99: loss = 931.9794, delta_loss = 13.56849 learning_Rate = 0.01000 rmse=1.04073 mae=0.81100\n",
      "<class 'data.RSContext'> iteration 100: loss = 918.7634, delta_loss = 13.21598 learning_Rate = 0.01000 rmse=1.04162 mae=0.81166\n",
      "<class 'data.RSContext'> iteration 101: loss = 905.8878, delta_loss = 12.87562 learning_Rate = 0.01000 rmse=1.04250 mae=0.81231\n",
      "<class 'data.RSContext'> iteration 102: loss = 893.3409, delta_loss = 12.54690 learning_Rate = 0.01000 rmse=1.04337 mae=0.81296\n",
      "<class 'data.RSContext'> iteration 103: loss = 881.1116, delta_loss = 12.22936 learning_Rate = 0.01000 rmse=1.04423 mae=0.81359\n",
      "<class 'data.RSContext'> iteration 104: loss = 869.1891, delta_loss = 11.92252 learning_Rate = 0.01000 rmse=1.04508 mae=0.81423\n",
      "<class 'data.RSContext'> iteration 105: loss = 857.5631, delta_loss = 11.62595 learning_Rate = 0.01000 rmse=1.04593 mae=0.81485\n",
      "<class 'data.RSContext'> iteration 106: loss = 846.2239, delta_loss = 11.33925 learning_Rate = 0.01000 rmse=1.04675 mae=0.81546\n",
      "<class 'data.RSContext'> iteration 107: loss = 835.1619, delta_loss = 11.06200 learning_Rate = 0.01000 rmse=1.04757 mae=0.81607\n",
      "<class 'data.RSContext'> iteration 108: loss = 824.3680, delta_loss = 10.79384 learning_Rate = 0.01000 rmse=1.04837 mae=0.81666\n",
      "<class 'data.RSContext'> iteration 109: loss = 813.8336, delta_loss = 10.53441 learning_Rate = 0.01000 rmse=1.04917 mae=0.81724\n",
      "<class 'data.RSContext'> iteration 110: loss = 803.5503, delta_loss = 10.28335 learning_Rate = 0.01000 rmse=1.04995 mae=0.81781\n",
      "<class 'data.RSContext'> iteration 111: loss = 793.5099, delta_loss = 10.04036 learning_Rate = 0.01000 rmse=1.05071 mae=0.81837\n",
      "<class 'data.RSContext'> iteration 112: loss = 783.7048, delta_loss = 9.80510 learning_Rate = 0.01000 rmse=1.05147 mae=0.81893\n",
      "<class 'data.RSContext'> iteration 113: loss = 774.1275, delta_loss = 9.57728 learning_Rate = 0.01000 rmse=1.05222 mae=0.81947\n",
      "<class 'data.RSContext'> iteration 114: loss = 764.7709, delta_loss = 9.35663 learning_Rate = 0.01000 rmse=1.05296 mae=0.82000\n",
      "<class 'data.RSContext'> iteration 115: loss = 755.6280, delta_loss = 9.14285 learning_Rate = 0.01000 rmse=1.05369 mae=0.82053\n",
      "<class 'data.RSContext'> iteration 116: loss = 746.6923, delta_loss = 8.93570 learning_Rate = 0.01000 rmse=1.05441 mae=0.82105\n",
      "<class 'data.RSContext'> iteration 117: loss = 737.9574, delta_loss = 8.73493 learning_Rate = 0.01000 rmse=1.05513 mae=0.82156\n",
      "<class 'data.RSContext'> iteration 118: loss = 729.4171, delta_loss = 8.54029 learning_Rate = 0.01000 rmse=1.05583 mae=0.82207\n",
      "<class 'data.RSContext'> iteration 119: loss = 721.0656, delta_loss = 8.35155 learning_Rate = 0.01000 rmse=1.05653 mae=0.82257\n",
      "<class 'data.RSContext'> iteration 120: loss = 712.8971, delta_loss = 8.16850 learning_Rate = 0.01000 rmse=1.05721 mae=0.82306\n",
      "<class 'data.RSContext'> iteration 121: loss = 704.9061, delta_loss = 7.99093 learning_Rate = 0.01000 rmse=1.05789 mae=0.82355\n",
      "<class 'data.RSContext'> iteration 122: loss = 697.0875, delta_loss = 7.81864 learning_Rate = 0.01000 rmse=1.05856 mae=0.82403\n",
      "<class 'data.RSContext'> iteration 123: loss = 689.4361, delta_loss = 7.65143 learning_Rate = 0.01000 rmse=1.05923 mae=0.82450\n",
      "<class 'data.RSContext'> iteration 124: loss = 681.9469, delta_loss = 7.48912 learning_Rate = 0.01000 rmse=1.05988 mae=0.82498\n",
      "<class 'data.RSContext'> iteration 125: loss = 674.6154, delta_loss = 7.33154 learning_Rate = 0.01000 rmse=1.06053 mae=0.82545\n",
      "<class 'data.RSContext'> iteration 126: loss = 667.4369, delta_loss = 7.17852 learning_Rate = 0.01000 rmse=1.06118 mae=0.82591\n",
      "<class 'data.RSContext'> iteration 127: loss = 660.4070, delta_loss = 7.02989 learning_Rate = 0.01000 rmse=1.06181 mae=0.82636\n",
      "<class 'data.RSContext'> iteration 128: loss = 653.5215, delta_loss = 6.88549 learning_Rate = 0.01000 rmse=1.06244 mae=0.82682\n",
      "<class 'data.RSContext'> iteration 129: loss = 646.7763, delta_loss = 6.74519 learning_Rate = 0.01000 rmse=1.06306 mae=0.82727\n",
      "<class 'data.RSContext'> iteration 130: loss = 640.1675, delta_loss = 6.60883 learning_Rate = 0.01000 rmse=1.06368 mae=0.82772\n",
      "<class 'data.RSContext'> iteration 131: loss = 633.6912, delta_loss = 6.47628 learning_Rate = 0.01000 rmse=1.06429 mae=0.82816\n",
      "<class 'data.RSContext'> iteration 132: loss = 627.3438, delta_loss = 6.34740 learning_Rate = 0.01000 rmse=1.06489 mae=0.82859\n",
      "<class 'data.RSContext'> iteration 133: loss = 621.1217, delta_loss = 6.22208 learning_Rate = 0.01000 rmse=1.06548 mae=0.82903\n",
      "<class 'data.RSContext'> iteration 134: loss = 615.0215, delta_loss = 6.10019 learning_Rate = 0.01000 rmse=1.06607 mae=0.82945\n",
      "<class 'data.RSContext'> iteration 135: loss = 609.0399, delta_loss = 5.98160 learning_Rate = 0.01000 rmse=1.06665 mae=0.82988\n",
      "<class 'data.RSContext'> iteration 136: loss = 603.1737, delta_loss = 5.86622 learning_Rate = 0.01000 rmse=1.06723 mae=0.83030\n",
      "<class 'data.RSContext'> iteration 137: loss = 597.4198, delta_loss = 5.75393 learning_Rate = 0.01000 rmse=1.06780 mae=0.83072\n",
      "<class 'data.RSContext'> iteration 138: loss = 591.7752, delta_loss = 5.64463 learning_Rate = 0.01000 rmse=1.06836 mae=0.83113\n",
      "<class 'data.RSContext'> iteration 139: loss = 586.2369, delta_loss = 5.53822 learning_Rate = 0.01000 rmse=1.06892 mae=0.83154\n",
      "<class 'data.RSContext'> iteration 140: loss = 580.8023, delta_loss = 5.43461 learning_Rate = 0.01000 rmse=1.06947 mae=0.83194\n",
      "<class 'data.RSContext'> iteration 141: loss = 575.4686, delta_loss = 5.33369 learning_Rate = 0.01000 rmse=1.07002 mae=0.83233\n",
      "<class 'data.RSContext'> iteration 142: loss = 570.2332, delta_loss = 5.23540 learning_Rate = 0.01000 rmse=1.07055 mae=0.83272\n",
      "<class 'data.RSContext'> iteration 143: loss = 565.0936, delta_loss = 5.13963 learning_Rate = 0.01000 rmse=1.07109 mae=0.83311\n",
      "<class 'data.RSContext'> iteration 144: loss = 560.0473, delta_loss = 5.04631 learning_Rate = 0.01000 rmse=1.07162 mae=0.83349\n",
      "<class 'data.RSContext'> iteration 145: loss = 555.0920, delta_loss = 4.95535 learning_Rate = 0.01000 rmse=1.07215 mae=0.83387\n",
      "<class 'data.RSContext'> iteration 146: loss = 550.2253, delta_loss = 4.86669 learning_Rate = 0.01000 rmse=1.07266 mae=0.83424\n",
      "<class 'data.RSContext'> iteration 147: loss = 545.4450, delta_loss = 4.78026 learning_Rate = 0.01000 rmse=1.07318 mae=0.83461\n",
      "<class 'data.RSContext'> iteration 148: loss = 540.7490, delta_loss = 4.69597 learning_Rate = 0.01000 rmse=1.07368 mae=0.83498\n",
      "<class 'data.RSContext'> iteration 149: loss = 536.1353, delta_loss = 4.61377 learning_Rate = 0.01000 rmse=1.07419 mae=0.83535\n",
      "<class 'data.RSContext'> iteration 150: loss = 531.6017, delta_loss = 4.53358 learning_Rate = 0.01000 rmse=1.07469 mae=0.83572\n",
      "<class 'data.RSContext'> iteration 151: loss = 527.1463, delta_loss = 4.45535 learning_Rate = 0.01000 rmse=1.07518 mae=0.83609\n",
      "<class 'data.RSContext'> iteration 152: loss = 522.7673, delta_loss = 4.37902 learning_Rate = 0.01000 rmse=1.07568 mae=0.83645\n",
      "<class 'data.RSContext'> iteration 153: loss = 518.4628, delta_loss = 4.30452 learning_Rate = 0.01000 rmse=1.07616 mae=0.83681\n",
      "<class 'data.RSContext'> iteration 154: loss = 514.2310, delta_loss = 4.23180 learning_Rate = 0.01000 rmse=1.07664 mae=0.83717\n",
      "<class 'data.RSContext'> iteration 155: loss = 510.0702, delta_loss = 4.16082 learning_Rate = 0.01000 rmse=1.07711 mae=0.83751\n",
      "<class 'data.RSContext'> iteration 156: loss = 505.9787, delta_loss = 4.09150 learning_Rate = 0.01000 rmse=1.07759 mae=0.83786\n",
      "<class 'data.RSContext'> iteration 157: loss = 501.9549, delta_loss = 4.02382 learning_Rate = 0.01000 rmse=1.07805 mae=0.83820\n",
      "<class 'data.RSContext'> iteration 158: loss = 497.9972, delta_loss = 3.95771 learning_Rate = 0.01000 rmse=1.07851 mae=0.83854\n",
      "<class 'data.RSContext'> iteration 159: loss = 494.1040, delta_loss = 3.89313 learning_Rate = 0.01000 rmse=1.07896 mae=0.83888\n",
      "<class 'data.RSContext'> iteration 160: loss = 490.2740, delta_loss = 3.83003 learning_Rate = 0.01000 rmse=1.07941 mae=0.83921\n",
      "current best rmse is 1.07941, mae is 0.83921\n",
      "80023\n",
      "19977\n",
      "cold start users count 0\n",
      "{\n",
      "    'dataset_name': 'u',\n",
      "    'k_fold_num': 5,\n",
      "    'k_test': 0,\n",
      "    'rating_path': 'Z:/RSA/data/u_ratings.txt',\n",
      "    'rating_cv_path': 'Z:/RSA/data/cv/',\n",
      "    'trust_path': 'Z:/RSA/data/u_trust.txt',\n",
      "    'sep': ' ',\n",
      "    'random_state': 0,\n",
      "    'size': 0.8,\n",
      "    'min_val': 0.5,\n",
      "    'max_val': 4.0,\n",
      "    'coldUserRating': 5,\n",
      "    'factor': 10,\n",
      "    'threshold': 0.0001,\n",
      "    'lr': 0.01,\n",
      "    'maxIter': 100,\n",
      "    'lambdaP': 0.001,\n",
      "    'lambdaQ': 0.001,\n",
      "    'gamma': 0,\n",
      "    'isEarlyStopping': False,\n",
      "    'result_path': '../results/',\n",
      "    'model_path': 'model/',\n",
      "    'result_log_path': 'log/'\n",
      "}\n",
      "80023\n",
      "19977\n",
      "cold start users count 0\n",
      "80023\n",
      "19977\n",
      "cold start users count 0\n",
      "<class 'data.RSContext'> iteration 1: loss = 30872.1540, delta_loss = -30872.15405 learning_Rate = 0.01000 rmse=1.09929 mae=0.86046\n",
      "<class 'data.RSContext'> iteration 2: loss = 7513.5085, delta_loss = 23358.64552 learning_Rate = 0.01000 rmse=1.01335 mae=0.79249\n",
      "<class 'data.RSContext'> iteration 3: loss = 6609.2580, delta_loss = 904.25050 learning_Rate = 0.01000 rmse=0.99917 mae=0.78170\n",
      "<class 'data.RSContext'> iteration 4: loss = 6369.7091, delta_loss = 239.54892 learning_Rate = 0.01000 rmse=0.99490 mae=0.77919\n",
      "<class 'data.RSContext'> iteration 5: loss = 6245.1640, delta_loss = 124.54510 learning_Rate = 0.01000 rmse=0.99268 mae=0.77810\n",
      "<class 'data.RSContext'> iteration 6: loss = 6157.6042, delta_loss = 87.55979 learning_Rate = 0.01000 rmse=0.99119 mae=0.77728\n",
      "<class 'data.RSContext'> iteration 7: loss = 6086.4295, delta_loss = 71.17470 learning_Rate = 0.01000 rmse=0.99011 mae=0.77664\n",
      "<class 'data.RSContext'> iteration 8: loss = 6023.6016, delta_loss = 62.82788 learning_Rate = 0.01000 rmse=0.98929 mae=0.77613\n",
      "<class 'data.RSContext'> iteration 9: loss = 5965.0563, delta_loss = 58.54531 learning_Rate = 0.01000 rmse=0.98858 mae=0.77570\n",
      "<class 'data.RSContext'> iteration 10: loss = 5908.3684, delta_loss = 56.68793 learning_Rate = 0.01000 rmse=0.98796 mae=0.77534\n",
      "<class 'data.RSContext'> iteration 11: loss = 5851.9174, delta_loss = 56.45101 learning_Rate = 0.01000 rmse=0.98732 mae=0.77499\n",
      "<class 'data.RSContext'> iteration 12: loss = 5794.5256, delta_loss = 57.39175 learning_Rate = 0.01000 rmse=0.98668 mae=0.77459\n",
      "<class 'data.RSContext'> iteration 13: loss = 5735.2818, delta_loss = 59.24386 learning_Rate = 0.01000 rmse=0.98605 mae=0.77419\n",
      "<class 'data.RSContext'> iteration 14: loss = 5673.4504, delta_loss = 61.83134 learning_Rate = 0.01000 rmse=0.98539 mae=0.77374\n",
      "<class 'data.RSContext'> iteration 15: loss = 5608.4274, delta_loss = 65.02305 learning_Rate = 0.01000 rmse=0.98470 mae=0.77322\n",
      "<class 'data.RSContext'> iteration 16: loss = 5539.7211, delta_loss = 68.70633 learning_Rate = 0.01000 rmse=0.98397 mae=0.77266\n",
      "<class 'data.RSContext'> iteration 17: loss = 5466.9500, delta_loss = 72.77105 learning_Rate = 0.01000 rmse=0.98319 mae=0.77205\n",
      "<class 'data.RSContext'> iteration 18: loss = 5389.8496, delta_loss = 77.10041 learning_Rate = 0.01000 rmse=0.98236 mae=0.77139\n",
      "<class 'data.RSContext'> iteration 19: loss = 5308.2826, delta_loss = 81.56698 learning_Rate = 0.01000 rmse=0.98147 mae=0.77066\n",
      "<class 'data.RSContext'> iteration 20: loss = 5222.2489, delta_loss = 86.03375 learning_Rate = 0.01000 rmse=0.98053 mae=0.76989\n",
      "<class 'data.RSContext'> iteration 21: loss = 5131.8892, delta_loss = 90.35963 learning_Rate = 0.01000 rmse=0.97955 mae=0.76906\n",
      "<class 'data.RSContext'> iteration 22: loss = 5037.4807, delta_loss = 94.40856 learning_Rate = 0.01000 rmse=0.97853 mae=0.76819\n",
      "<class 'data.RSContext'> iteration 23: loss = 4939.4202, delta_loss = 98.06049 learning_Rate = 0.01000 rmse=0.97748 mae=0.76728\n",
      "<class 'data.RSContext'> iteration 24: loss = 4838.1985, delta_loss = 101.22172 learning_Rate = 0.01000 rmse=0.97643 mae=0.76636\n",
      "<class 'data.RSContext'> iteration 25: loss = 4734.3665, delta_loss = 103.83194 learning_Rate = 0.01000 rmse=0.97539 mae=0.76545\n",
      "<class 'data.RSContext'> iteration 26: loss = 4628.5001, delta_loss = 105.86640 learning_Rate = 0.01000 rmse=0.97438 mae=0.76456\n",
      "<class 'data.RSContext'> iteration 27: loss = 4521.1676, delta_loss = 107.33250 learning_Rate = 0.01000 rmse=0.97344 mae=0.76371\n",
      "<class 'data.RSContext'> iteration 28: loss = 4412.9052, delta_loss = 108.26241 learning_Rate = 0.01000 rmse=0.97255 mae=0.76290\n",
      "<class 'data.RSContext'> iteration 29: loss = 4304.2015, delta_loss = 108.70367 learning_Rate = 0.01000 rmse=0.97172 mae=0.76214\n",
      "<class 'data.RSContext'> iteration 30: loss = 4195.4912, delta_loss = 108.71037 learning_Rate = 0.01000 rmse=0.97096 mae=0.76145\n",
      "<class 'data.RSContext'> iteration 31: loss = 4087.1548, delta_loss = 108.33635 learning_Rate = 0.01000 rmse=0.97026 mae=0.76080\n",
      "<class 'data.RSContext'> iteration 32: loss = 3979.5238, delta_loss = 107.63103 learning_Rate = 0.01000 rmse=0.96968 mae=0.76023\n",
      "<class 'data.RSContext'> iteration 33: loss = 3872.8861, delta_loss = 106.63773 learning_Rate = 0.01000 rmse=0.96920 mae=0.75975\n",
      "<class 'data.RSContext'> iteration 34: loss = 3767.4926, delta_loss = 105.39344 learning_Rate = 0.01000 rmse=0.96881 mae=0.75932\n",
      "<class 'data.RSContext'> iteration 35: loss = 3663.5630, delta_loss = 103.92961 learning_Rate = 0.01000 rmse=0.96852 mae=0.75899\n",
      "<class 'data.RSContext'> iteration 36: loss = 3561.2898, delta_loss = 102.27323 learning_Rate = 0.01000 rmse=0.96836 mae=0.75877\n",
      "<class 'data.RSContext'> iteration 37: loss = 3460.8419, delta_loss = 100.44788 learning_Rate = 0.01000 rmse=0.96829 mae=0.75862\n",
      "<class 'data.RSContext'> iteration 38: loss = 3362.3672, delta_loss = 98.47473 learning_Rate = 0.01000 rmse=0.96832 mae=0.75856\n",
      "<class 'data.RSContext'> iteration 39: loss = 3265.9939, delta_loss = 96.37330 learning_Rate = 0.01000 rmse=0.96845 mae=0.75857\n",
      "<class 'data.RSContext'> iteration 40: loss = 3171.8319, delta_loss = 94.16199 learning_Rate = 0.01000 rmse=0.96869 mae=0.75869\n",
      "<class 'data.RSContext'> iteration 41: loss = 3079.9734, delta_loss = 91.85848 learning_Rate = 0.01000 rmse=0.96902 mae=0.75890\n",
      "<class 'data.RSContext'> iteration 42: loss = 2990.4934, delta_loss = 89.47996 learning_Rate = 0.01000 rmse=0.96946 mae=0.75917\n",
      "<class 'data.RSContext'> iteration 43: loss = 2903.4503, delta_loss = 87.04311 learning_Rate = 0.01000 rmse=0.96997 mae=0.75950\n",
      "<class 'data.RSContext'> iteration 44: loss = 2818.8862, delta_loss = 84.56408 learning_Rate = 0.01000 rmse=0.97056 mae=0.75990\n",
      "<class 'data.RSContext'> iteration 45: loss = 2736.8279, delta_loss = 82.05837 learning_Rate = 0.01000 rmse=0.97123 mae=0.76035\n",
      "<class 'data.RSContext'> iteration 46: loss = 2657.2873, delta_loss = 79.54059 learning_Rate = 0.01000 rmse=0.97197 mae=0.76084\n",
      "<class 'data.RSContext'> iteration 47: loss = 2580.2629, delta_loss = 77.02437 learning_Rate = 0.01000 rmse=0.97277 mae=0.76139\n",
      "<class 'data.RSContext'> iteration 48: loss = 2505.7408, delta_loss = 74.52215 learning_Rate = 0.01000 rmse=0.97363 mae=0.76198\n",
      "<class 'data.RSContext'> iteration 49: loss = 2433.6957, delta_loss = 72.04511 learning_Rate = 0.01000 rmse=0.97455 mae=0.76261\n",
      "<class 'data.RSContext'> iteration 50: loss = 2364.0926, delta_loss = 69.60306 learning_Rate = 0.01000 rmse=0.97553 mae=0.76328\n",
      "<class 'data.RSContext'> iteration 51: loss = 2296.8881, delta_loss = 67.20449 learning_Rate = 0.01000 rmse=0.97654 mae=0.76398\n",
      "<class 'data.RSContext'> iteration 52: loss = 2232.0316, delta_loss = 64.85651 learning_Rate = 0.01000 rmse=0.97759 mae=0.76473\n",
      "<class 'data.RSContext'> iteration 53: loss = 2169.4666, delta_loss = 62.56496 learning_Rate = 0.01000 rmse=0.97867 mae=0.76548\n",
      "<class 'data.RSContext'> iteration 54: loss = 2109.1322, delta_loss = 60.33448 learning_Rate = 0.01000 rmse=0.97978 mae=0.76628\n",
      "<class 'data.RSContext'> iteration 55: loss = 2050.9636, delta_loss = 58.16858 learning_Rate = 0.01000 rmse=0.98090 mae=0.76711\n",
      "<class 'data.RSContext'> iteration 56: loss = 1994.8938, delta_loss = 56.06980 learning_Rate = 0.01000 rmse=0.98204 mae=0.76793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'data.RSContext'> iteration 57: loss = 1940.8540, delta_loss = 54.03976 learning_Rate = 0.01000 rmse=0.98319 mae=0.76877\n",
      "<class 'data.RSContext'> iteration 58: loss = 1888.7747, delta_loss = 52.07933 learning_Rate = 0.01000 rmse=0.98434 mae=0.76961\n",
      "<class 'data.RSContext'> iteration 59: loss = 1838.5860, delta_loss = 50.18870 learning_Rate = 0.01000 rmse=0.98549 mae=0.77045\n",
      "<class 'data.RSContext'> iteration 60: loss = 1790.2185, delta_loss = 48.36752 learning_Rate = 0.01000 rmse=0.98666 mae=0.77129\n",
      "<class 'data.RSContext'> iteration 61: loss = 1743.6035, delta_loss = 46.61496 learning_Rate = 0.01000 rmse=0.98782 mae=0.77213\n",
      "<class 'data.RSContext'> iteration 62: loss = 1698.6737, delta_loss = 44.92981 learning_Rate = 0.01000 rmse=0.98898 mae=0.77297\n",
      "<class 'data.RSContext'> iteration 63: loss = 1655.3631, delta_loss = 43.31056 learning_Rate = 0.01000 rmse=0.99014 mae=0.77382\n",
      "<class 'data.RSContext'> iteration 64: loss = 1613.6077, delta_loss = 41.75548 learning_Rate = 0.01000 rmse=0.99129 mae=0.77464\n",
      "<class 'data.RSContext'> iteration 65: loss = 1573.3450, delta_loss = 40.26267 learning_Rate = 0.01000 rmse=0.99244 mae=0.77546\n",
      "<class 'data.RSContext'> iteration 66: loss = 1534.5149, delta_loss = 38.83009 learning_Rate = 0.01000 rmse=0.99358 mae=0.77628\n",
      "<class 'data.RSContext'> iteration 67: loss = 1497.0592, delta_loss = 37.45565 learning_Rate = 0.01000 rmse=0.99473 mae=0.77710\n",
      "<class 'data.RSContext'> iteration 68: loss = 1460.9221, delta_loss = 36.13718 learning_Rate = 0.01000 rmse=0.99587 mae=0.77792\n",
      "<class 'data.RSContext'> iteration 69: loss = 1426.0495, delta_loss = 34.87254 learning_Rate = 0.01000 rmse=0.99698 mae=0.77873\n",
      "<class 'data.RSContext'> iteration 70: loss = 1392.3899, delta_loss = 33.65958 learning_Rate = 0.01000 rmse=0.99809 mae=0.77954\n",
      "<class 'data.RSContext'> iteration 71: loss = 1359.8938, delta_loss = 32.49617 learning_Rate = 0.01000 rmse=0.99919 mae=0.78034\n",
      "<class 'data.RSContext'> iteration 72: loss = 1328.5135, delta_loss = 31.38025 learning_Rate = 0.01000 rmse=1.00028 mae=0.78113\n",
      "<class 'data.RSContext'> iteration 73: loss = 1298.2037, delta_loss = 30.30979 learning_Rate = 0.01000 rmse=1.00137 mae=0.78193\n",
      "<class 'data.RSContext'> iteration 74: loss = 1268.9209, delta_loss = 29.28284 learning_Rate = 0.01000 rmse=1.00245 mae=0.78273\n",
      "<class 'data.RSContext'> iteration 75: loss = 1240.6234, delta_loss = 28.29751 learning_Rate = 0.01000 rmse=1.00352 mae=0.78351\n",
      "<class 'data.RSContext'> iteration 76: loss = 1213.2714, delta_loss = 27.35199 learning_Rate = 0.01000 rmse=1.00459 mae=0.78428\n",
      "<class 'data.RSContext'> iteration 77: loss = 1186.8269, delta_loss = 26.44452 learning_Rate = 0.01000 rmse=1.00564 mae=0.78506\n",
      "<class 'data.RSContext'> iteration 78: loss = 1161.2534, delta_loss = 25.57344 learning_Rate = 0.01000 rmse=1.00668 mae=0.78582\n",
      "<class 'data.RSContext'> iteration 79: loss = 1136.5163, delta_loss = 24.73715 learning_Rate = 0.01000 rmse=1.00771 mae=0.78657\n",
      "<class 'data.RSContext'> iteration 80: loss = 1112.5822, delta_loss = 23.93412 learning_Rate = 0.01000 rmse=1.00873 mae=0.78731\n",
      "<class 'data.RSContext'> iteration 81: loss = 1089.4193, delta_loss = 23.16288 learning_Rate = 0.01000 rmse=1.00973 mae=0.78803\n",
      "<class 'data.RSContext'> iteration 82: loss = 1066.9972, delta_loss = 22.42205 learning_Rate = 0.01000 rmse=1.01073 mae=0.78875\n",
      "<class 'data.RSContext'> iteration 83: loss = 1045.2870, delta_loss = 21.71028 learning_Rate = 0.01000 rmse=1.01171 mae=0.78946\n",
      "<class 'data.RSContext'> iteration 84: loss = 1024.2606, delta_loss = 21.02632 learning_Rate = 0.01000 rmse=1.01268 mae=0.79015\n",
      "<class 'data.RSContext'> iteration 85: loss = 1003.8917, delta_loss = 20.36894 learning_Rate = 0.01000 rmse=1.01363 mae=0.79083\n",
      "<class 'data.RSContext'> iteration 86: loss = 984.1547, delta_loss = 19.73699 learning_Rate = 0.01000 rmse=1.01458 mae=0.79150\n",
      "<class 'data.RSContext'> iteration 87: loss = 965.0253, delta_loss = 19.12938 learning_Rate = 0.01000 rmse=1.01551 mae=0.79216\n",
      "<class 'data.RSContext'> iteration 88: loss = 946.4803, delta_loss = 18.54503 learning_Rate = 0.01000 rmse=1.01642 mae=0.79282\n",
      "<class 'data.RSContext'> iteration 89: loss = 928.4973, delta_loss = 17.98296 learning_Rate = 0.01000 rmse=1.01732 mae=0.79347\n",
      "<class 'data.RSContext'> iteration 90: loss = 911.0551, delta_loss = 17.44219 learning_Rate = 0.01000 rmse=1.01822 mae=0.79411\n",
      "<class 'data.RSContext'> iteration 91: loss = 894.1333, delta_loss = 16.92182 learning_Rate = 0.01000 rmse=1.01910 mae=0.79474\n",
      "<class 'data.RSContext'> iteration 92: loss = 877.7124, delta_loss = 16.42097 learning_Rate = 0.01000 rmse=1.01996 mae=0.79537\n",
      "<class 'data.RSContext'> iteration 93: loss = 861.7735, delta_loss = 15.93881 learning_Rate = 0.01000 rmse=1.02081 mae=0.79599\n",
      "<class 'data.RSContext'> iteration 94: loss = 846.2990, delta_loss = 15.47453 learning_Rate = 0.01000 rmse=1.02166 mae=0.79659\n",
      "<class 'data.RSContext'> iteration 95: loss = 831.2716, delta_loss = 15.02738 learning_Rate = 0.01000 rmse=1.02249 mae=0.79719\n",
      "<class 'data.RSContext'> iteration 96: loss = 816.6750, delta_loss = 14.59663 learning_Rate = 0.01000 rmse=1.02331 mae=0.79779\n",
      "<class 'data.RSContext'> iteration 97: loss = 802.4934, delta_loss = 14.18159 learning_Rate = 0.01000 rmse=1.02412 mae=0.79836\n",
      "<class 'data.RSContext'> iteration 98: loss = 788.7118, delta_loss = 13.78159 learning_Rate = 0.01000 rmse=1.02493 mae=0.79894\n",
      "<class 'data.RSContext'> iteration 99: loss = 775.3158, delta_loss = 13.39601 learning_Rate = 0.01000 rmse=1.02571 mae=0.79950\n",
      "<class 'data.RSContext'> iteration 100: loss = 762.2916, delta_loss = 13.02424 learning_Rate = 0.01000 rmse=1.02649 mae=0.80005\n",
      "<class 'data.RSContext'> iteration 101: loss = 749.6259, delta_loss = 12.66570 learning_Rate = 0.01000 rmse=1.02726 mae=0.80059\n",
      "<class 'data.RSContext'> iteration 102: loss = 737.3060, delta_loss = 12.31984 learning_Rate = 0.01000 rmse=1.02802 mae=0.80113\n",
      "<class 'data.RSContext'> iteration 103: loss = 725.3199, delta_loss = 11.98614 learning_Rate = 0.01000 rmse=1.02876 mae=0.80166\n",
      "<class 'data.RSContext'> iteration 104: loss = 713.6558, delta_loss = 11.66410 learning_Rate = 0.01000 rmse=1.02949 mae=0.80218\n",
      "<class 'data.RSContext'> iteration 105: loss = 702.3025, delta_loss = 11.35324 learning_Rate = 0.01000 rmse=1.03021 mae=0.80269\n",
      "<class 'data.RSContext'> iteration 106: loss = 691.2495, delta_loss = 11.05309 learning_Rate = 0.01000 rmse=1.03092 mae=0.80320\n",
      "<class 'data.RSContext'> iteration 107: loss = 680.4862, delta_loss = 10.76324 learning_Rate = 0.01000 rmse=1.03162 mae=0.80370\n",
      "<class 'data.RSContext'> iteration 108: loss = 670.0030, delta_loss = 10.48324 learning_Rate = 0.01000 rmse=1.03231 mae=0.80419\n",
      "<class 'data.RSContext'> iteration 109: loss = 659.7902, delta_loss = 10.21272 learning_Rate = 0.01000 rmse=1.03299 mae=0.80468\n",
      "<class 'data.RSContext'> iteration 110: loss = 649.8390, delta_loss = 9.95129 learning_Rate = 0.01000 rmse=1.03367 mae=0.80516\n",
      "<class 'data.RSContext'> iteration 111: loss = 640.1404, delta_loss = 9.69859 learning_Rate = 0.01000 rmse=1.03433 mae=0.80563\n",
      "<class 'data.RSContext'> iteration 112: loss = 630.6861, delta_loss = 9.45427 learning_Rate = 0.01000 rmse=1.03498 mae=0.80610\n",
      "<class 'data.RSContext'> iteration 113: loss = 621.4681, delta_loss = 9.21800 learning_Rate = 0.01000 rmse=1.03563 mae=0.80657\n",
      "<class 'data.RSContext'> iteration 114: loss = 612.4786, delta_loss = 8.98946 learning_Rate = 0.01000 rmse=1.03626 mae=0.80702\n",
      "<class 'data.RSContext'> iteration 115: loss = 603.7103, delta_loss = 8.76835 learning_Rate = 0.01000 rmse=1.03689 mae=0.80747\n",
      "<class 'data.RSContext'> iteration 116: loss = 595.1559, delta_loss = 8.55439 learning_Rate = 0.01000 rmse=1.03750 mae=0.80791\n",
      "<class 'data.RSContext'> iteration 117: loss = 586.8086, delta_loss = 8.34729 learning_Rate = 0.01000 rmse=1.03811 mae=0.80835\n",
      "<class 'data.RSContext'> iteration 118: loss = 578.6618, delta_loss = 8.14680 learning_Rate = 0.01000 rmse=1.03871 mae=0.80879\n",
      "<class 'data.RSContext'> iteration 119: loss = 570.7092, delta_loss = 7.95266 learning_Rate = 0.01000 rmse=1.03931 mae=0.80922\n",
      "<class 'data.RSContext'> iteration 120: loss = 562.9445, delta_loss = 7.76463 learning_Rate = 0.01000 rmse=1.03990 mae=0.80965\n",
      "<class 'data.RSContext'> iteration 121: loss = 555.3621, delta_loss = 7.58247 learning_Rate = 0.01000 rmse=1.04048 mae=0.81007\n",
      "<class 'data.RSContext'> iteration 122: loss = 547.9561, delta_loss = 7.40598 learning_Rate = 0.01000 rmse=1.04106 mae=0.81048\n",
      "<class 'data.RSContext'> iteration 123: loss = 540.7211, delta_loss = 7.23493 learning_Rate = 0.01000 rmse=1.04162 mae=0.81089\n",
      "<class 'data.RSContext'> iteration 124: loss = 533.6520, delta_loss = 7.06913 learning_Rate = 0.01000 rmse=1.04218 mae=0.81129\n",
      "<class 'data.RSContext'> iteration 125: loss = 526.7437, delta_loss = 6.90837 learning_Rate = 0.01000 rmse=1.04273 mae=0.81169\n",
      "<class 'data.RSContext'> iteration 126: loss = 519.9912, delta_loss = 6.75248 learning_Rate = 0.01000 rmse=1.04328 mae=0.81208\n",
      "<class 'data.RSContext'> iteration 127: loss = 513.3899, delta_loss = 6.60128 learning_Rate = 0.01000 rmse=1.04381 mae=0.81247\n",
      "<class 'data.RSContext'> iteration 128: loss = 506.9353, delta_loss = 6.45460 learning_Rate = 0.01000 rmse=1.04434 mae=0.81284\n",
      "<class 'data.RSContext'> iteration 129: loss = 500.6230, delta_loss = 6.31227 learning_Rate = 0.01000 rmse=1.04487 mae=0.81323\n",
      "<class 'data.RSContext'> iteration 130: loss = 494.4489, delta_loss = 6.17414 learning_Rate = 0.01000 rmse=1.04540 mae=0.81360\n",
      "<class 'data.RSContext'> iteration 131: loss = 488.4088, delta_loss = 6.04005 learning_Rate = 0.01000 rmse=1.04591 mae=0.81396\n",
      "<class 'data.RSContext'> iteration 132: loss = 482.4990, delta_loss = 5.90987 learning_Rate = 0.01000 rmse=1.04642 mae=0.81433\n",
      "<class 'data.RSContext'> iteration 133: loss = 476.7155, delta_loss = 5.78346 learning_Rate = 0.01000 rmse=1.04692 mae=0.81469\n",
      "<class 'data.RSContext'> iteration 134: loss = 471.0548, delta_loss = 5.66068 learning_Rate = 0.01000 rmse=1.04742 mae=0.81504\n",
      "<class 'data.RSContext'> iteration 135: loss = 465.5134, delta_loss = 5.54140 learning_Rate = 0.01000 rmse=1.04790 mae=0.81539\n",
      "<class 'data.RSContext'> iteration 136: loss = 460.0879, delta_loss = 5.42551 learning_Rate = 0.01000 rmse=1.04839 mae=0.81574\n",
      "<class 'data.RSContext'> iteration 137: loss = 454.7750, delta_loss = 5.31289 learning_Rate = 0.01000 rmse=1.04887 mae=0.81607\n",
      "<class 'data.RSContext'> iteration 138: loss = 449.5716, delta_loss = 5.20342 learning_Rate = 0.01000 rmse=1.04934 mae=0.81641\n",
      "<class 'data.RSContext'> iteration 139: loss = 444.4746, delta_loss = 5.09701 learning_Rate = 0.01000 rmse=1.04981 mae=0.81675\n",
      "<class 'data.RSContext'> iteration 140: loss = 439.4810, delta_loss = 4.99353 learning_Rate = 0.01000 rmse=1.05028 mae=0.81708\n",
      "<class 'data.RSContext'> iteration 141: loss = 434.5882, delta_loss = 4.89290 learning_Rate = 0.01000 rmse=1.05073 mae=0.81740\n",
      "<class 'data.RSContext'> iteration 142: loss = 429.7931, delta_loss = 4.79502 learning_Rate = 0.01000 rmse=1.05119 mae=0.81774\n",
      "<class 'data.RSContext'> iteration 143: loss = 425.0933, delta_loss = 4.69979 learning_Rate = 0.01000 rmse=1.05164 mae=0.81806\n",
      "<class 'data.RSContext'> iteration 144: loss = 420.4862, delta_loss = 4.60713 learning_Rate = 0.01000 rmse=1.05208 mae=0.81837\n",
      "<class 'data.RSContext'> iteration 145: loss = 415.9693, delta_loss = 4.51696 learning_Rate = 0.01000 rmse=1.05252 mae=0.81869\n",
      "<class 'data.RSContext'> iteration 146: loss = 411.5401, delta_loss = 4.42918 learning_Rate = 0.01000 rmse=1.05296 mae=0.81900\n",
      "<class 'data.RSContext'> iteration 147: loss = 407.1964, delta_loss = 4.34373 learning_Rate = 0.01000 rmse=1.05338 mae=0.81930\n",
      "<class 'data.RSContext'> iteration 148: loss = 402.9358, delta_loss = 4.26052 learning_Rate = 0.01000 rmse=1.05381 mae=0.81961\n",
      "<class 'data.RSContext'> iteration 149: loss = 398.7563, delta_loss = 4.17949 learning_Rate = 0.01000 rmse=1.05423 mae=0.81991\n",
      "<class 'data.RSContext'> iteration 150: loss = 394.6558, delta_loss = 4.10057 learning_Rate = 0.01000 rmse=1.05465 mae=0.82021\n",
      "<class 'data.RSContext'> iteration 151: loss = 390.6321, delta_loss = 4.02368 learning_Rate = 0.01000 rmse=1.05505 mae=0.82050\n",
      "<class 'data.RSContext'> iteration 152: loss = 386.6833, delta_loss = 3.94876 learning_Rate = 0.01000 rmse=1.05546 mae=0.82079\n",
      "<class 'data.RSContext'> iteration 153: loss = 382.8076, delta_loss = 3.87575 learning_Rate = 0.01000 rmse=1.05586 mae=0.82108\n",
      "<class 'data.RSContext'> iteration 154: loss = 379.0030, delta_loss = 3.80458 learning_Rate = 0.01000 rmse=1.05625 mae=0.82136\n",
      "<class 'data.RSContext'> iteration 155: loss = 375.2678, delta_loss = 3.73521 learning_Rate = 0.01000 rmse=1.05665 mae=0.82164\n",
      "<class 'data.RSContext'> iteration 156: loss = 371.6002, delta_loss = 3.66758 learning_Rate = 0.01000 rmse=1.05704 mae=0.82192\n",
      "<class 'data.RSContext'> iteration 157: loss = 367.9986, delta_loss = 3.60162 learning_Rate = 0.01000 rmse=1.05742 mae=0.82219\n",
      "<class 'data.RSContext'> iteration 158: loss = 364.4613, delta_loss = 3.53730 learning_Rate = 0.01000 rmse=1.05780 mae=0.82247\n",
      "<class 'data.RSContext'> iteration 159: loss = 360.9867, delta_loss = 3.47455 learning_Rate = 0.01000 rmse=1.05818 mae=0.82274\n",
      "<class 'data.RSContext'> iteration 160: loss = 357.5734, delta_loss = 3.41334 learning_Rate = 0.01000 rmse=1.05855 mae=0.82301\n",
      "current best rmse is 1.05855, mae is 0.82301\n",
      "80023\n",
      "19977\n",
      "cold start users count 0\n",
      "{\n",
      "    'dataset_name': 'u',\n",
      "    'k_fold_num': 5,\n",
      "    'k_test': 0,\n",
      "    'rating_path': 'Z:/RSA/data/u_ratings.txt',\n",
      "    'rating_cv_path': 'Z:/RSA/data/cv/',\n",
      "    'trust_path': 'Z:/RSA/data/u_trust.txt',\n",
      "    'sep': ' ',\n",
      "    'random_state': 0,\n",
      "    'size': 0.8,\n",
      "    'min_val': 0.5,\n",
      "    'max_val': 4.0,\n",
      "    'coldUserRating': 5,\n",
      "    'factor': 10,\n",
      "    'threshold': 0.0001,\n",
      "    'lr': 0.01,\n",
      "    'maxIter': 100,\n",
      "    'lambdaP': 0.001,\n",
      "    'lambdaQ': 0.001,\n",
      "    'gamma': 0,\n",
      "    'isEarlyStopping': False,\n",
      "    'result_path': '../results/',\n",
      "    'model_path': 'model/',\n",
      "    'result_log_path': 'log/'\n",
      "}\n",
      "80023\n",
      "19977\n",
      "cold start users count 0\n",
      "80023\n",
      "19977\n",
      "cold start users count 0\n",
      "<class 'data.RSContext'> iteration 1: loss = 30745.5043, delta_loss = -30745.50435 learning_Rate = 0.01000 rmse=1.09949 mae=0.86168\n",
      "<class 'data.RSContext'> iteration 2: loss = 7506.7221, delta_loss = 23238.78221 learning_Rate = 0.01000 rmse=1.01356 mae=0.79364\n",
      "<class 'data.RSContext'> iteration 3: loss = 6613.1894, delta_loss = 893.53276 learning_Rate = 0.01000 rmse=0.99966 mae=0.78292\n",
      "<class 'data.RSContext'> iteration 4: loss = 6375.9507, delta_loss = 237.23864 learning_Rate = 0.01000 rmse=0.99537 mae=0.78019\n",
      "<class 'data.RSContext'> iteration 5: loss = 6252.3309, delta_loss = 123.61981 learning_Rate = 0.01000 rmse=0.99316 mae=0.77906\n",
      "<class 'data.RSContext'> iteration 6: loss = 6165.4262, delta_loss = 86.90468 learning_Rate = 0.01000 rmse=0.99170 mae=0.77824\n",
      "<class 'data.RSContext'> iteration 7: loss = 6094.7798, delta_loss = 70.64647 learning_Rate = 0.01000 rmse=0.99064 mae=0.77763\n",
      "<class 'data.RSContext'> iteration 8: loss = 6032.3681, delta_loss = 62.41168 learning_Rate = 0.01000 rmse=0.98977 mae=0.77711\n",
      "<class 'data.RSContext'> iteration 9: loss = 5974.1326, delta_loss = 58.23552 learning_Rate = 0.01000 rmse=0.98908 mae=0.77667\n",
      "<class 'data.RSContext'> iteration 10: loss = 5917.6513, delta_loss = 56.48127 learning_Rate = 0.01000 rmse=0.98846 mae=0.77629\n",
      "<class 'data.RSContext'> iteration 11: loss = 5861.3017, delta_loss = 56.34962 learning_Rate = 0.01000 rmse=0.98780 mae=0.77586\n",
      "<class 'data.RSContext'> iteration 12: loss = 5803.8971, delta_loss = 57.40461 learning_Rate = 0.01000 rmse=0.98717 mae=0.77544\n",
      "<class 'data.RSContext'> iteration 13: loss = 5744.5102, delta_loss = 59.38684 learning_Rate = 0.01000 rmse=0.98655 mae=0.77500\n",
      "<class 'data.RSContext'> iteration 14: loss = 5682.3835, delta_loss = 62.12677 learning_Rate = 0.01000 rmse=0.98589 mae=0.77453\n",
      "<class 'data.RSContext'> iteration 15: loss = 5616.8846, delta_loss = 65.49885 learning_Rate = 0.01000 rmse=0.98521 mae=0.77402\n",
      "<class 'data.RSContext'> iteration 16: loss = 5547.4900, delta_loss = 69.39468 learning_Rate = 0.01000 rmse=0.98445 mae=0.77343\n",
      "<class 'data.RSContext'> iteration 17: loss = 5473.7836, delta_loss = 73.70632 learning_Rate = 0.01000 rmse=0.98365 mae=0.77277\n",
      "<class 'data.RSContext'> iteration 18: loss = 5395.4675, delta_loss = 78.31611 learning_Rate = 0.01000 rmse=0.98278 mae=0.77204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'data.RSContext'> iteration 19: loss = 5312.3757, delta_loss = 83.09183 learning_Rate = 0.01000 rmse=0.98185 mae=0.77126\n",
      "<class 'data.RSContext'> iteration 20: loss = 5224.4885, delta_loss = 87.88716 learning_Rate = 0.01000 rmse=0.98087 mae=0.77042\n",
      "<class 'data.RSContext'> iteration 21: loss = 5131.9412, delta_loss = 92.54735 learning_Rate = 0.01000 rmse=0.97985 mae=0.76953\n",
      "<class 'data.RSContext'> iteration 22: loss = 5035.0216, delta_loss = 96.91961 learning_Rate = 0.01000 rmse=0.97877 mae=0.76857\n",
      "<class 'data.RSContext'> iteration 23: loss = 4934.1550, delta_loss = 100.86654 learning_Rate = 0.01000 rmse=0.97766 mae=0.76758\n",
      "<class 'data.RSContext'> iteration 24: loss = 4829.8754, delta_loss = 104.27967 learning_Rate = 0.01000 rmse=0.97655 mae=0.76660\n",
      "<class 'data.RSContext'> iteration 25: loss = 4722.7857, delta_loss = 107.08971 learning_Rate = 0.01000 rmse=0.97547 mae=0.76564\n",
      "<class 'data.RSContext'> iteration 26: loss = 4613.5151, delta_loss = 109.27058 learning_Rate = 0.01000 rmse=0.97442 mae=0.76471\n",
      "<class 'data.RSContext'> iteration 27: loss = 4502.6790, delta_loss = 110.83603 learning_Rate = 0.01000 rmse=0.97343 mae=0.76381\n",
      "<class 'data.RSContext'> iteration 28: loss = 4390.8490, delta_loss = 111.83006 learning_Rate = 0.01000 rmse=0.97253 mae=0.76294\n",
      "<class 'data.RSContext'> iteration 29: loss = 4278.5349, delta_loss = 112.31411 learning_Rate = 0.01000 rmse=0.97169 mae=0.76212\n",
      "<class 'data.RSContext'> iteration 30: loss = 4166.1802, delta_loss = 112.35464 learning_Rate = 0.01000 rmse=0.97093 mae=0.76136\n",
      "<class 'data.RSContext'> iteration 31: loss = 4054.1664, delta_loss = 112.01386 learning_Rate = 0.01000 rmse=0.97026 mae=0.76065\n",
      "<class 'data.RSContext'> iteration 32: loss = 3942.8217, delta_loss = 111.34470 learning_Rate = 0.01000 rmse=0.96967 mae=0.76000\n",
      "<class 'data.RSContext'> iteration 33: loss = 3832.4321, delta_loss = 110.38962 learning_Rate = 0.01000 rmse=0.96917 mae=0.75942\n",
      "<class 'data.RSContext'> iteration 34: loss = 3723.2501, delta_loss = 109.18198 learning_Rate = 0.01000 rmse=0.96875 mae=0.75894\n",
      "<class 'data.RSContext'> iteration 35: loss = 3615.5017, delta_loss = 107.74840 learning_Rate = 0.01000 rmse=0.96843 mae=0.75855\n",
      "<class 'data.RSContext'> iteration 36: loss = 3509.3904, delta_loss = 106.11124 learning_Rate = 0.01000 rmse=0.96822 mae=0.75825\n",
      "<class 'data.RSContext'> iteration 37: loss = 3405.0999, delta_loss = 104.29048 learning_Rate = 0.01000 rmse=0.96811 mae=0.75804\n",
      "<class 'data.RSContext'> iteration 38: loss = 3302.7949, delta_loss = 102.30505 learning_Rate = 0.01000 rmse=0.96809 mae=0.75792\n",
      "<class 'data.RSContext'> iteration 39: loss = 3202.6214, delta_loss = 100.17352 learning_Rate = 0.01000 rmse=0.96818 mae=0.75787\n",
      "<class 'data.RSContext'> iteration 40: loss = 3104.7070, delta_loss = 97.91441 learning_Rate = 0.01000 rmse=0.96836 mae=0.75787\n",
      "<class 'data.RSContext'> iteration 41: loss = 3009.1606, delta_loss = 95.54635 learning_Rate = 0.01000 rmse=0.96864 mae=0.75797\n",
      "<class 'data.RSContext'> iteration 42: loss = 2916.0727, delta_loss = 93.08795 learning_Rate = 0.01000 rmse=0.96900 mae=0.75813\n",
      "<class 'data.RSContext'> iteration 43: loss = 2825.5150, delta_loss = 90.55766 learning_Rate = 0.01000 rmse=0.96943 mae=0.75837\n",
      "<class 'data.RSContext'> iteration 44: loss = 2737.5414, delta_loss = 87.97357 learning_Rate = 0.01000 rmse=0.96995 mae=0.75869\n",
      "<class 'data.RSContext'> iteration 45: loss = 2652.1883, delta_loss = 85.35316 learning_Rate = 0.01000 rmse=0.97052 mae=0.75907\n",
      "<class 'data.RSContext'> iteration 46: loss = 2569.4753, delta_loss = 82.71302 learning_Rate = 0.01000 rmse=0.97116 mae=0.75950\n",
      "<class 'data.RSContext'> iteration 47: loss = 2489.4066, delta_loss = 80.06866 learning_Rate = 0.01000 rmse=0.97186 mae=0.75998\n",
      "<class 'data.RSContext'> iteration 48: loss = 2411.9723, delta_loss = 77.43428 learning_Rate = 0.01000 rmse=0.97261 mae=0.76048\n",
      "<class 'data.RSContext'> iteration 49: loss = 2337.1497, delta_loss = 74.82262 learning_Rate = 0.01000 rmse=0.97341 mae=0.76103\n",
      "<class 'data.RSContext'> iteration 50: loss = 2264.9048, delta_loss = 72.24488 learning_Rate = 0.01000 rmse=0.97425 mae=0.76162\n",
      "<class 'data.RSContext'> iteration 51: loss = 2195.1941, delta_loss = 69.71069 learning_Rate = 0.01000 rmse=0.97514 mae=0.76225\n",
      "<class 'data.RSContext'> iteration 52: loss = 2127.9660, delta_loss = 67.22812 learning_Rate = 0.01000 rmse=0.97606 mae=0.76289\n",
      "<class 'data.RSContext'> iteration 53: loss = 2063.1623, delta_loss = 64.80373 learning_Rate = 0.01000 rmse=0.97700 mae=0.76357\n",
      "<class 'data.RSContext'> iteration 54: loss = 2000.7196, delta_loss = 62.44271 learning_Rate = 0.01000 rmse=0.97799 mae=0.76428\n",
      "<class 'data.RSContext'> iteration 55: loss = 1940.5706, delta_loss = 60.14900 learning_Rate = 0.01000 rmse=0.97899 mae=0.76501\n",
      "<class 'data.RSContext'> iteration 56: loss = 1882.6452, delta_loss = 57.92538 learning_Rate = 0.01000 rmse=0.98000 mae=0.76574\n",
      "<class 'data.RSContext'> iteration 57: loss = 1826.8715, delta_loss = 55.77368 learning_Rate = 0.01000 rmse=0.98105 mae=0.76649\n",
      "<class 'data.RSContext'> iteration 58: loss = 1773.1767, delta_loss = 53.69486 learning_Rate = 0.01000 rmse=0.98210 mae=0.76725\n",
      "<class 'data.RSContext'> iteration 59: loss = 1721.4875, delta_loss = 51.68919 learning_Rate = 0.01000 rmse=0.98316 mae=0.76803\n",
      "<class 'data.RSContext'> iteration 60: loss = 1671.7311, delta_loss = 49.75636 learning_Rate = 0.01000 rmse=0.98424 mae=0.76882\n",
      "<class 'data.RSContext'> iteration 61: loss = 1623.8356, delta_loss = 47.89556 learning_Rate = 0.01000 rmse=0.98532 mae=0.76963\n",
      "<class 'data.RSContext'> iteration 62: loss = 1577.7299, delta_loss = 46.10562 learning_Rate = 0.01000 rmse=0.98640 mae=0.77044\n",
      "<class 'data.RSContext'> iteration 63: loss = 1533.3449, delta_loss = 44.38507 learning_Rate = 0.01000 rmse=0.98749 mae=0.77124\n",
      "<class 'data.RSContext'> iteration 64: loss = 1490.6127, delta_loss = 42.73220 learning_Rate = 0.01000 rmse=0.98856 mae=0.77202\n",
      "<class 'data.RSContext'> iteration 65: loss = 1449.4675, delta_loss = 41.14516 learning_Rate = 0.01000 rmse=0.98964 mae=0.77281\n",
      "<class 'data.RSContext'> iteration 66: loss = 1409.8456, delta_loss = 39.62195 learning_Rate = 0.01000 rmse=0.99071 mae=0.77358\n",
      "<class 'data.RSContext'> iteration 67: loss = 1371.6850, delta_loss = 38.16051 learning_Rate = 0.01000 rmse=0.99179 mae=0.77436\n",
      "<class 'data.RSContext'> iteration 68: loss = 1334.9263, delta_loss = 36.75872 learning_Rate = 0.01000 rmse=0.99286 mae=0.77513\n",
      "<class 'data.RSContext'> iteration 69: loss = 1299.5119, delta_loss = 35.41447 learning_Rate = 0.01000 rmse=0.99392 mae=0.77589\n",
      "<class 'data.RSContext'> iteration 70: loss = 1265.3862, delta_loss = 34.12561 learning_Rate = 0.01000 rmse=0.99496 mae=0.77665\n",
      "<class 'data.RSContext'> iteration 71: loss = 1232.4962, delta_loss = 32.89002 learning_Rate = 0.01000 rmse=0.99600 mae=0.77741\n",
      "<class 'data.RSContext'> iteration 72: loss = 1200.7906, delta_loss = 31.70563 learning_Rate = 0.01000 rmse=0.99704 mae=0.77816\n",
      "<class 'data.RSContext'> iteration 73: loss = 1170.2202, delta_loss = 30.57037 learning_Rate = 0.01000 rmse=0.99807 mae=0.77891\n",
      "<class 'data.RSContext'> iteration 74: loss = 1140.7380, delta_loss = 29.48225 learning_Rate = 0.01000 rmse=0.99909 mae=0.77965\n",
      "<class 'data.RSContext'> iteration 75: loss = 1112.2987, delta_loss = 28.43932 learning_Rate = 0.01000 rmse=1.00010 mae=0.78038\n",
      "<class 'data.RSContext'> iteration 76: loss = 1084.8590, delta_loss = 27.43967 learning_Rate = 0.01000 rmse=1.00110 mae=0.78110\n",
      "<class 'data.RSContext'> iteration 77: loss = 1058.3775, delta_loss = 26.48148 learning_Rate = 0.01000 rmse=1.00209 mae=0.78182\n",
      "<class 'data.RSContext'> iteration 78: loss = 1032.8145, delta_loss = 25.56295 learning_Rate = 0.01000 rmse=1.00307 mae=0.78253\n",
      "<class 'data.RSContext'> iteration 79: loss = 1008.1322, delta_loss = 24.68238 learning_Rate = 0.01000 rmse=1.00404 mae=0.78323\n",
      "<class 'data.RSContext'> iteration 80: loss = 984.2941, delta_loss = 23.83811 learning_Rate = 0.01000 rmse=1.00499 mae=0.78391\n",
      "<class 'data.RSContext'> iteration 81: loss = 961.2655, delta_loss = 23.02855 learning_Rate = 0.01000 rmse=1.00593 mae=0.78459\n",
      "<class 'data.RSContext'> iteration 82: loss = 939.0133, delta_loss = 22.25216 learning_Rate = 0.01000 rmse=1.00685 mae=0.78524\n",
      "<class 'data.RSContext'> iteration 83: loss = 917.5059, delta_loss = 21.50748 learning_Rate = 0.01000 rmse=1.00777 mae=0.78589\n",
      "<class 'data.RSContext'> iteration 84: loss = 896.7128, delta_loss = 20.79309 learning_Rate = 0.01000 rmse=1.00867 mae=0.78653\n",
      "<class 'data.RSContext'> iteration 85: loss = 876.6051, delta_loss = 20.10764 learning_Rate = 0.01000 rmse=1.00956 mae=0.78716\n",
      "<class 'data.RSContext'> iteration 86: loss = 857.1553, delta_loss = 19.44984 learning_Rate = 0.01000 rmse=1.01044 mae=0.78778\n",
      "<class 'data.RSContext'> iteration 87: loss = 838.3368, delta_loss = 18.81845 learning_Rate = 0.01000 rmse=1.01131 mae=0.78841\n",
      "<class 'data.RSContext'> iteration 88: loss = 820.1245, delta_loss = 18.21229 learning_Rate = 0.01000 rmse=1.01216 mae=0.78903\n",
      "<class 'data.RSContext'> iteration 89: loss = 802.4943, delta_loss = 17.63022 learning_Rate = 0.01000 rmse=1.01300 mae=0.78964\n",
      "<class 'data.RSContext'> iteration 90: loss = 785.4232, delta_loss = 17.07116 learning_Rate = 0.01000 rmse=1.01382 mae=0.79023\n",
      "<class 'data.RSContext'> iteration 91: loss = 768.8891, delta_loss = 16.53408 learning_Rate = 0.01000 rmse=1.01464 mae=0.79082\n",
      "<class 'data.RSContext'> iteration 92: loss = 752.8711, delta_loss = 16.01800 learning_Rate = 0.01000 rmse=1.01543 mae=0.79140\n",
      "<class 'data.RSContext'> iteration 93: loss = 737.3491, delta_loss = 15.52198 learning_Rate = 0.01000 rmse=1.01623 mae=0.79197\n",
      "<class 'data.RSContext'> iteration 94: loss = 722.3040, delta_loss = 15.04512 learning_Rate = 0.01000 rmse=1.01701 mae=0.79253\n",
      "<class 'data.RSContext'> iteration 95: loss = 707.7174, delta_loss = 14.58656 learning_Rate = 0.01000 rmse=1.01778 mae=0.79310\n",
      "<class 'data.RSContext'> iteration 96: loss = 693.5719, delta_loss = 14.14550 learning_Rate = 0.01000 rmse=1.01853 mae=0.79364\n",
      "<class 'data.RSContext'> iteration 97: loss = 679.8507, delta_loss = 13.72117 learning_Rate = 0.01000 rmse=1.01928 mae=0.79418\n",
      "<class 'data.RSContext'> iteration 98: loss = 666.5379, delta_loss = 13.31281 learning_Rate = 0.01000 rmse=1.02002 mae=0.79471\n",
      "<class 'data.RSContext'> iteration 99: loss = 653.6182, delta_loss = 12.91974 learning_Rate = 0.01000 rmse=1.02073 mae=0.79523\n",
      "<class 'data.RSContext'> iteration 100: loss = 641.0769, delta_loss = 12.54128 learning_Rate = 0.01000 rmse=1.02145 mae=0.79576\n",
      "<class 'data.RSContext'> iteration 101: loss = 628.9001, delta_loss = 12.17679 learning_Rate = 0.01000 rmse=1.02215 mae=0.79628\n",
      "<class 'data.RSContext'> iteration 102: loss = 617.0744, delta_loss = 11.82568 learning_Rate = 0.01000 rmse=1.02283 mae=0.79679\n",
      "<class 'data.RSContext'> iteration 103: loss = 605.5871, delta_loss = 11.48735 learning_Rate = 0.01000 rmse=1.02351 mae=0.79729\n",
      "<class 'data.RSContext'> iteration 104: loss = 594.4258, delta_loss = 11.16126 learning_Rate = 0.01000 rmse=1.02418 mae=0.79778\n",
      "<class 'data.RSContext'> iteration 105: loss = 583.5789, delta_loss = 10.84690 learning_Rate = 0.01000 rmse=1.02485 mae=0.79826\n",
      "<class 'data.RSContext'> iteration 106: loss = 573.0352, delta_loss = 10.54375 learning_Rate = 0.01000 rmse=1.02550 mae=0.79873\n",
      "<class 'data.RSContext'> iteration 107: loss = 562.7838, delta_loss = 10.25135 learning_Rate = 0.01000 rmse=1.02613 mae=0.79920\n",
      "<class 'data.RSContext'> iteration 108: loss = 552.8146, delta_loss = 9.96925 learning_Rate = 0.01000 rmse=1.02677 mae=0.79966\n",
      "<class 'data.RSContext'> iteration 109: loss = 543.1176, delta_loss = 9.69700 learning_Rate = 0.01000 rmse=1.02739 mae=0.80011\n",
      "<class 'data.RSContext'> iteration 110: loss = 533.6834, delta_loss = 9.43422 learning_Rate = 0.01000 rmse=1.02801 mae=0.80056\n",
      "<class 'data.RSContext'> iteration 111: loss = 524.5029, delta_loss = 9.18049 learning_Rate = 0.01000 rmse=1.02862 mae=0.80100\n",
      "<class 'data.RSContext'> iteration 112: loss = 515.5674, delta_loss = 8.93546 learning_Rate = 0.01000 rmse=1.02922 mae=0.80144\n",
      "<class 'data.RSContext'> iteration 113: loss = 506.8686, delta_loss = 8.69876 learning_Rate = 0.01000 rmse=1.02981 mae=0.80186\n",
      "<class 'data.RSContext'> iteration 114: loss = 498.3986, delta_loss = 8.47007 learning_Rate = 0.01000 rmse=1.03039 mae=0.80228\n",
      "<class 'data.RSContext'> iteration 115: loss = 490.1495, delta_loss = 8.24905 learning_Rate = 0.01000 rmse=1.03096 mae=0.80269\n",
      "<class 'data.RSContext'> iteration 116: loss = 482.1141, delta_loss = 8.03540 learning_Rate = 0.01000 rmse=1.03153 mae=0.80310\n",
      "<class 'data.RSContext'> iteration 117: loss = 474.2853, delta_loss = 7.82882 learning_Rate = 0.01000 rmse=1.03209 mae=0.80350\n",
      "<class 'data.RSContext'> iteration 118: loss = 466.6563, delta_loss = 7.62904 learning_Rate = 0.01000 rmse=1.03264 mae=0.80390\n",
      "<class 'data.RSContext'> iteration 119: loss = 459.2205, delta_loss = 7.43580 learning_Rate = 0.01000 rmse=1.03318 mae=0.80429\n",
      "<class 'data.RSContext'> iteration 120: loss = 451.9716, delta_loss = 7.24883 learning_Rate = 0.01000 rmse=1.03372 mae=0.80469\n",
      "<class 'data.RSContext'> iteration 121: loss = 444.9038, delta_loss = 7.06789 learning_Rate = 0.01000 rmse=1.03424 mae=0.80506\n",
      "<class 'data.RSContext'> iteration 122: loss = 438.0110, delta_loss = 6.89275 learning_Rate = 0.01000 rmse=1.03476 mae=0.80544\n",
      "<class 'data.RSContext'> iteration 123: loss = 431.2878, delta_loss = 6.72318 learning_Rate = 0.01000 rmse=1.03528 mae=0.80582\n",
      "<class 'data.RSContext'> iteration 124: loss = 424.7288, delta_loss = 6.55899 learning_Rate = 0.01000 rmse=1.03578 mae=0.80619\n",
      "<class 'data.RSContext'> iteration 125: loss = 418.3289, delta_loss = 6.39995 learning_Rate = 0.01000 rmse=1.03628 mae=0.80656\n",
      "<class 'data.RSContext'> iteration 126: loss = 412.0830, delta_loss = 6.24589 learning_Rate = 0.01000 rmse=1.03676 mae=0.80693\n",
      "<class 'data.RSContext'> iteration 127: loss = 405.9864, delta_loss = 6.09660 learning_Rate = 0.01000 rmse=1.03725 mae=0.80729\n",
      "<class 'data.RSContext'> iteration 128: loss = 400.0345, delta_loss = 5.95193 learning_Rate = 0.01000 rmse=1.03772 mae=0.80765\n",
      "<class 'data.RSContext'> iteration 129: loss = 394.2228, delta_loss = 5.81169 learning_Rate = 0.01000 rmse=1.03818 mae=0.80799\n",
      "<class 'data.RSContext'> iteration 130: loss = 388.5471, delta_loss = 5.67572 learning_Rate = 0.01000 rmse=1.03864 mae=0.80834\n",
      "<class 'data.RSContext'> iteration 131: loss = 383.0032, delta_loss = 5.54387 learning_Rate = 0.01000 rmse=1.03910 mae=0.80869\n",
      "<class 'data.RSContext'> iteration 132: loss = 377.5872, delta_loss = 5.41599 learning_Rate = 0.01000 rmse=1.03955 mae=0.80902\n",
      "<class 'data.RSContext'> iteration 133: loss = 372.2953, delta_loss = 5.29194 learning_Rate = 0.01000 rmse=1.03999 mae=0.80936\n",
      "<class 'data.RSContext'> iteration 134: loss = 367.1237, delta_loss = 5.17157 learning_Rate = 0.01000 rmse=1.04043 mae=0.80969\n",
      "<class 'data.RSContext'> iteration 135: loss = 362.0689, delta_loss = 5.05476 learning_Rate = 0.01000 rmse=1.04086 mae=0.81002\n",
      "<class 'data.RSContext'> iteration 136: loss = 357.1275, delta_loss = 4.94139 learning_Rate = 0.01000 rmse=1.04128 mae=0.81034\n",
      "<class 'data.RSContext'> iteration 137: loss = 352.2962, delta_loss = 4.83132 learning_Rate = 0.01000 rmse=1.04170 mae=0.81065\n",
      "<class 'data.RSContext'> iteration 138: loss = 347.5718, delta_loss = 4.72445 learning_Rate = 0.01000 rmse=1.04211 mae=0.81096\n",
      "<class 'data.RSContext'> iteration 139: loss = 342.9511, delta_loss = 4.62067 learning_Rate = 0.01000 rmse=1.04252 mae=0.81127\n",
      "<class 'data.RSContext'> iteration 140: loss = 338.4312, delta_loss = 4.51986 learning_Rate = 0.01000 rmse=1.04292 mae=0.81157\n",
      "<class 'data.RSContext'> iteration 141: loss = 334.0093, delta_loss = 4.42193 learning_Rate = 0.01000 rmse=1.04332 mae=0.81187\n",
      "<class 'data.RSContext'> iteration 142: loss = 329.6825, delta_loss = 4.32677 learning_Rate = 0.01000 rmse=1.04371 mae=0.81217\n",
      "<class 'data.RSContext'> iteration 143: loss = 325.4482, delta_loss = 4.23430 learning_Rate = 0.01000 rmse=1.04409 mae=0.81245\n",
      "<class 'data.RSContext'> iteration 144: loss = 321.3038, delta_loss = 4.14442 learning_Rate = 0.01000 rmse=1.04447 mae=0.81274\n",
      "<class 'data.RSContext'> iteration 145: loss = 317.2468, delta_loss = 4.05704 learning_Rate = 0.01000 rmse=1.04484 mae=0.81302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'data.RSContext'> iteration 146: loss = 313.2747, delta_loss = 3.97208 learning_Rate = 0.01000 rmse=1.04521 mae=0.81330\n",
      "<class 'data.RSContext'> iteration 147: loss = 309.3852, delta_loss = 3.88947 learning_Rate = 0.01000 rmse=1.04558 mae=0.81358\n",
      "<class 'data.RSContext'> iteration 148: loss = 305.5761, delta_loss = 3.80911 learning_Rate = 0.01000 rmse=1.04593 mae=0.81385\n",
      "<class 'data.RSContext'> iteration 149: loss = 301.8452, delta_loss = 3.73095 learning_Rate = 0.01000 rmse=1.04629 mae=0.81412\n",
      "<class 'data.RSContext'> iteration 150: loss = 298.1903, delta_loss = 3.65490 learning_Rate = 0.01000 rmse=1.04664 mae=0.81438\n",
      "<class 'data.RSContext'> iteration 151: loss = 294.6094, delta_loss = 3.58089 learning_Rate = 0.01000 rmse=1.04699 mae=0.81465\n",
      "<class 'data.RSContext'> iteration 152: loss = 291.1005, delta_loss = 3.50887 learning_Rate = 0.01000 rmse=1.04733 mae=0.81490\n",
      "<class 'data.RSContext'> iteration 153: loss = 287.6617, delta_loss = 3.43876 learning_Rate = 0.01000 rmse=1.04767 mae=0.81516\n",
      "<class 'data.RSContext'> iteration 154: loss = 284.2912, delta_loss = 3.37051 learning_Rate = 0.01000 rmse=1.04800 mae=0.81541\n",
      "<class 'data.RSContext'> iteration 155: loss = 280.9872, delta_loss = 3.30405 learning_Rate = 0.01000 rmse=1.04833 mae=0.81566\n",
      "<class 'data.RSContext'> iteration 156: loss = 277.7479, delta_loss = 3.23934 learning_Rate = 0.01000 rmse=1.04866 mae=0.81591\n",
      "<class 'data.RSContext'> iteration 157: loss = 274.5716, delta_loss = 3.17630 learning_Rate = 0.01000 rmse=1.04898 mae=0.81616\n",
      "<class 'data.RSContext'> iteration 158: loss = 271.4567, delta_loss = 3.11490 learning_Rate = 0.01000 rmse=1.04929 mae=0.81640\n",
      "<class 'data.RSContext'> iteration 159: loss = 268.4016, delta_loss = 3.05507 learning_Rate = 0.01000 rmse=1.04961 mae=0.81664\n",
      "<class 'data.RSContext'> iteration 160: loss = 265.4048, delta_loss = 2.99678 learning_Rate = 0.01000 rmse=1.04992 mae=0.81688\n",
      "current best rmse is 1.04992, mae is 0.81688\n",
      "80023\n",
      "19977\n",
      "cold start users count 0\n",
      "{\n",
      "    'dataset_name': 'u',\n",
      "    'k_fold_num': 5,\n",
      "    'k_test': 0,\n",
      "    'rating_path': 'Z:/RSA/data/u_ratings.txt',\n",
      "    'rating_cv_path': 'Z:/RSA/data/cv/',\n",
      "    'trust_path': 'Z:/RSA/data/u_trust.txt',\n",
      "    'sep': ' ',\n",
      "    'random_state': 0,\n",
      "    'size': 0.8,\n",
      "    'min_val': 0.5,\n",
      "    'max_val': 4.0,\n",
      "    'coldUserRating': 5,\n",
      "    'factor': 10,\n",
      "    'threshold': 0.0001,\n",
      "    'lr': 0.01,\n",
      "    'maxIter': 100,\n",
      "    'lambdaP': 0.001,\n",
      "    'lambdaQ': 0.001,\n",
      "    'gamma': 0,\n",
      "    'isEarlyStopping': False,\n",
      "    'result_path': '../results/',\n",
      "    'model_path': 'model/',\n",
      "    'result_log_path': 'log/'\n",
      "}\n",
      "80023\n",
      "19977\n",
      "cold start users count 0\n",
      "80023\n",
      "19977\n",
      "cold start users count 0\n",
      "<class 'data.RSContext'> iteration 1: loss = 30683.6297, delta_loss = -30683.62969 learning_Rate = 0.01000 rmse=1.10008 mae=0.86277\n",
      "<class 'data.RSContext'> iteration 2: loss = 7507.3942, delta_loss = 23176.23553 learning_Rate = 0.01000 rmse=1.01404 mae=0.79444\n",
      "<class 'data.RSContext'> iteration 3: loss = 6616.6518, delta_loss = 890.74241 learning_Rate = 0.01000 rmse=0.99984 mae=0.78340\n",
      "<class 'data.RSContext'> iteration 4: loss = 6380.3368, delta_loss = 236.31493 learning_Rate = 0.01000 rmse=0.99557 mae=0.78078\n",
      "<class 'data.RSContext'> iteration 5: loss = 6257.2851, delta_loss = 123.05170 learning_Rate = 0.01000 rmse=0.99354 mae=0.77972\n",
      "<class 'data.RSContext'> iteration 6: loss = 6170.7404, delta_loss = 86.54471 learning_Rate = 0.01000 rmse=0.99214 mae=0.77891\n",
      "<class 'data.RSContext'> iteration 7: loss = 6100.2823, delta_loss = 70.45808 learning_Rate = 0.01000 rmse=0.99106 mae=0.77826\n",
      "<class 'data.RSContext'> iteration 8: loss = 6037.9112, delta_loss = 62.37115 learning_Rate = 0.01000 rmse=0.99021 mae=0.77780\n",
      "<class 'data.RSContext'> iteration 9: loss = 5979.5884, delta_loss = 58.32274 learning_Rate = 0.01000 rmse=0.98953 mae=0.77738\n",
      "<class 'data.RSContext'> iteration 10: loss = 5922.9081, delta_loss = 56.68033 learning_Rate = 0.01000 rmse=0.98890 mae=0.77699\n",
      "<class 'data.RSContext'> iteration 11: loss = 5866.2592, delta_loss = 56.64895 learning_Rate = 0.01000 rmse=0.98826 mae=0.77657\n",
      "<class 'data.RSContext'> iteration 12: loss = 5808.4631, delta_loss = 57.79609 learning_Rate = 0.01000 rmse=0.98766 mae=0.77619\n",
      "<class 'data.RSContext'> iteration 13: loss = 5748.5985, delta_loss = 59.86455 learning_Rate = 0.01000 rmse=0.98704 mae=0.77577\n",
      "<class 'data.RSContext'> iteration 14: loss = 5685.9128, delta_loss = 62.68568 learning_Rate = 0.01000 rmse=0.98639 mae=0.77530\n",
      "<class 'data.RSContext'> iteration 15: loss = 5619.7791, delta_loss = 66.13370 learning_Rate = 0.01000 rmse=0.98568 mae=0.77477\n",
      "<class 'data.RSContext'> iteration 16: loss = 5549.6799, delta_loss = 70.09925 learning_Rate = 0.01000 rmse=0.98490 mae=0.77419\n",
      "<class 'data.RSContext'> iteration 17: loss = 5475.2067, delta_loss = 74.47315 learning_Rate = 0.01000 rmse=0.98405 mae=0.77354\n",
      "<class 'data.RSContext'> iteration 18: loss = 5396.0697, delta_loss = 79.13701 learning_Rate = 0.01000 rmse=0.98315 mae=0.77285\n",
      "<class 'data.RSContext'> iteration 19: loss = 5312.1104, delta_loss = 83.95936 learning_Rate = 0.01000 rmse=0.98218 mae=0.77208\n",
      "<class 'data.RSContext'> iteration 20: loss = 5223.3133, delta_loss = 88.79710 learning_Rate = 0.01000 rmse=0.98113 mae=0.77123\n",
      "<class 'data.RSContext'> iteration 21: loss = 5129.8113, delta_loss = 93.50201 learning_Rate = 0.01000 rmse=0.98002 mae=0.77030\n",
      "<class 'data.RSContext'> iteration 22: loss = 5031.8801, delta_loss = 97.93115 learning_Rate = 0.01000 rmse=0.97886 mae=0.76931\n",
      "<class 'data.RSContext'> iteration 23: loss = 4929.9209, delta_loss = 101.95915 learning_Rate = 0.01000 rmse=0.97767 mae=0.76828\n",
      "<class 'data.RSContext'> iteration 24: loss = 4824.4316, delta_loss = 105.48934 learning_Rate = 0.01000 rmse=0.97647 mae=0.76725\n",
      "<class 'data.RSContext'> iteration 25: loss = 4715.9709, delta_loss = 108.46073 learning_Rate = 0.01000 rmse=0.97528 mae=0.76622\n",
      "<class 'data.RSContext'> iteration 26: loss = 4605.1218, delta_loss = 110.84905 learning_Rate = 0.01000 rmse=0.97411 mae=0.76522\n",
      "<class 'data.RSContext'> iteration 27: loss = 4492.4601, delta_loss = 112.66178 learning_Rate = 0.01000 rmse=0.97297 mae=0.76424\n",
      "<class 'data.RSContext'> iteration 28: loss = 4378.5308, delta_loss = 113.92930 learning_Rate = 0.01000 rmse=0.97187 mae=0.76327\n",
      "<class 'data.RSContext'> iteration 29: loss = 4263.8358, delta_loss = 114.69496 learning_Rate = 0.01000 rmse=0.97084 mae=0.76234\n",
      "<class 'data.RSContext'> iteration 30: loss = 4148.8292, delta_loss = 115.00657 learning_Rate = 0.01000 rmse=0.96989 mae=0.76146\n",
      "<class 'data.RSContext'> iteration 31: loss = 4033.9185, delta_loss = 114.91077 learning_Rate = 0.01000 rmse=0.96904 mae=0.76067\n",
      "<class 'data.RSContext'> iteration 32: loss = 3919.4683, delta_loss = 114.45016 learning_Rate = 0.01000 rmse=0.96829 mae=0.75996\n",
      "<class 'data.RSContext'> iteration 33: loss = 3805.8058, delta_loss = 113.66254 learning_Rate = 0.01000 rmse=0.96765 mae=0.75932\n",
      "<class 'data.RSContext'> iteration 34: loss = 3693.2246, delta_loss = 112.58117 learning_Rate = 0.01000 rmse=0.96712 mae=0.75878\n",
      "<class 'data.RSContext'> iteration 35: loss = 3581.9891, delta_loss = 111.23549 learning_Rate = 0.01000 rmse=0.96671 mae=0.75835\n",
      "<class 'data.RSContext'> iteration 36: loss = 3472.3372, delta_loss = 109.65190 learning_Rate = 0.01000 rmse=0.96640 mae=0.75799\n",
      "<class 'data.RSContext'> iteration 37: loss = 3364.4828, delta_loss = 107.85441 learning_Rate = 0.01000 rmse=0.96620 mae=0.75771\n",
      "<class 'data.RSContext'> iteration 38: loss = 3258.6174, delta_loss = 105.86533 learning_Rate = 0.01000 rmse=0.96611 mae=0.75752\n",
      "<class 'data.RSContext'> iteration 39: loss = 3154.9116, delta_loss = 103.70585 learning_Rate = 0.01000 rmse=0.96613 mae=0.75741\n",
      "<class 'data.RSContext'> iteration 40: loss = 3053.5151, delta_loss = 101.39654 learning_Rate = 0.01000 rmse=0.96625 mae=0.75739\n",
      "<class 'data.RSContext'> iteration 41: loss = 2954.5574, delta_loss = 98.95769 learning_Rate = 0.01000 rmse=0.96646 mae=0.75744\n",
      "<class 'data.RSContext'> iteration 42: loss = 2858.1478, delta_loss = 96.40955 learning_Rate = 0.01000 rmse=0.96677 mae=0.75756\n",
      "<class 'data.RSContext'> iteration 43: loss = 2764.3755, delta_loss = 93.77230 learning_Rate = 0.01000 rmse=0.96716 mae=0.75774\n",
      "<class 'data.RSContext'> iteration 44: loss = 2673.3096, delta_loss = 91.06594 learning_Rate = 0.01000 rmse=0.96762 mae=0.75799\n",
      "<class 'data.RSContext'> iteration 45: loss = 2584.9996, delta_loss = 88.31000 learning_Rate = 0.01000 rmse=0.96817 mae=0.75831\n",
      "<class 'data.RSContext'> iteration 46: loss = 2499.4762, delta_loss = 85.52332 learning_Rate = 0.01000 rmse=0.96878 mae=0.75869\n",
      "<class 'data.RSContext'> iteration 47: loss = 2416.7526, delta_loss = 82.72363 learning_Rate = 0.01000 rmse=0.96946 mae=0.75913\n",
      "<class 'data.RSContext'> iteration 48: loss = 2336.8252, delta_loss = 79.92738 learning_Rate = 0.01000 rmse=0.97021 mae=0.75963\n",
      "<class 'data.RSContext'> iteration 49: loss = 2259.6758, delta_loss = 77.14948 learning_Rate = 0.01000 rmse=0.97100 mae=0.76018\n",
      "<class 'data.RSContext'> iteration 50: loss = 2185.2726, delta_loss = 74.40316 learning_Rate = 0.01000 rmse=0.97184 mae=0.76075\n",
      "<class 'data.RSContext'> iteration 51: loss = 2113.5727, delta_loss = 71.69994 learning_Rate = 0.01000 rmse=0.97271 mae=0.76137\n",
      "<class 'data.RSContext'> iteration 52: loss = 2044.5231, delta_loss = 69.04959 learning_Rate = 0.01000 rmse=0.97361 mae=0.76202\n",
      "<class 'data.RSContext'> iteration 53: loss = 1978.0628, delta_loss = 66.46023 learning_Rate = 0.01000 rmse=0.97455 mae=0.76270\n",
      "<class 'data.RSContext'> iteration 54: loss = 1914.1244, delta_loss = 63.93839 learning_Rate = 0.01000 rmse=0.97552 mae=0.76340\n",
      "<class 'data.RSContext'> iteration 55: loss = 1852.6353, delta_loss = 61.48915 learning_Rate = 0.01000 rmse=0.97652 mae=0.76414\n",
      "<class 'data.RSContext'> iteration 56: loss = 1793.5190, delta_loss = 59.11627 learning_Rate = 0.01000 rmse=0.97754 mae=0.76489\n",
      "<class 'data.RSContext'> iteration 57: loss = 1736.6967, delta_loss = 56.82237 learning_Rate = 0.01000 rmse=0.97857 mae=0.76565\n",
      "<class 'data.RSContext'> iteration 58: loss = 1682.0876, delta_loss = 54.60902 learning_Rate = 0.01000 rmse=0.97961 mae=0.76642\n",
      "<class 'data.RSContext'> iteration 59: loss = 1629.6107, delta_loss = 52.47692 learning_Rate = 0.01000 rmse=0.98067 mae=0.76720\n",
      "<class 'data.RSContext'> iteration 60: loss = 1579.1847, delta_loss = 50.42603 learning_Rate = 0.01000 rmse=0.98173 mae=0.76800\n",
      "<class 'data.RSContext'> iteration 61: loss = 1530.7290, delta_loss = 48.45566 learning_Rate = 0.01000 rmse=0.98280 mae=0.76880\n",
      "<class 'data.RSContext'> iteration 62: loss = 1484.1644, delta_loss = 46.56462 learning_Rate = 0.01000 rmse=0.98387 mae=0.76961\n",
      "<class 'data.RSContext'> iteration 63: loss = 1439.4131, delta_loss = 44.75130 learning_Rate = 0.01000 rmse=0.98495 mae=0.77043\n",
      "<class 'data.RSContext'> iteration 64: loss = 1396.3994, delta_loss = 43.01375 learning_Rate = 0.01000 rmse=0.98602 mae=0.77125\n",
      "<class 'data.RSContext'> iteration 65: loss = 1355.0496, delta_loss = 41.34979 learning_Rate = 0.01000 rmse=0.98709 mae=0.77208\n",
      "<class 'data.RSContext'> iteration 66: loss = 1315.2926, delta_loss = 39.75701 learning_Rate = 0.01000 rmse=0.98814 mae=0.77289\n",
      "<class 'data.RSContext'> iteration 67: loss = 1277.0597, delta_loss = 38.23291 learning_Rate = 0.01000 rmse=0.98919 mae=0.77370\n",
      "<class 'data.RSContext'> iteration 68: loss = 1240.2848, delta_loss = 36.77488 learning_Rate = 0.01000 rmse=0.99023 mae=0.77449\n",
      "<class 'data.RSContext'> iteration 69: loss = 1204.9045, delta_loss = 35.38030 learning_Rate = 0.01000 rmse=0.99125 mae=0.77527\n",
      "<class 'data.RSContext'> iteration 70: loss = 1170.8580, delta_loss = 34.04652 learning_Rate = 0.01000 rmse=0.99226 mae=0.77603\n",
      "<class 'data.RSContext'> iteration 71: loss = 1138.0870, delta_loss = 32.77091 learning_Rate = 0.01000 rmse=0.99325 mae=0.77678\n",
      "<class 'data.RSContext'> iteration 72: loss = 1106.5362, delta_loss = 31.55089 learning_Rate = 0.01000 rmse=0.99424 mae=0.77752\n",
      "<class 'data.RSContext'> iteration 73: loss = 1076.1522, delta_loss = 30.38395 learning_Rate = 0.01000 rmse=0.99522 mae=0.77825\n",
      "<class 'data.RSContext'> iteration 74: loss = 1046.8846, delta_loss = 29.26764 learning_Rate = 0.01000 rmse=0.99618 mae=0.77896\n",
      "<class 'data.RSContext'> iteration 75: loss = 1018.6850, delta_loss = 28.19958 learning_Rate = 0.01000 rmse=0.99714 mae=0.77967\n",
      "<class 'data.RSContext'> iteration 76: loss = 991.5075, delta_loss = 27.17752 learning_Rate = 0.01000 rmse=0.99808 mae=0.78036\n",
      "<class 'data.RSContext'> iteration 77: loss = 965.3082, delta_loss = 26.19927 learning_Rate = 0.01000 rmse=0.99901 mae=0.78105\n",
      "<class 'data.RSContext'> iteration 78: loss = 940.0455, delta_loss = 25.26273 learning_Rate = 0.01000 rmse=0.99992 mae=0.78173\n",
      "<class 'data.RSContext'> iteration 79: loss = 915.6795, delta_loss = 24.36593 learning_Rate = 0.01000 rmse=1.00082 mae=0.78239\n",
      "<class 'data.RSContext'> iteration 80: loss = 892.1726, delta_loss = 23.50697 learning_Rate = 0.01000 rmse=1.00171 mae=0.78305\n",
      "<class 'data.RSContext'> iteration 81: loss = 869.4885, delta_loss = 22.68404 learning_Rate = 0.01000 rmse=1.00258 mae=0.78370\n",
      "<class 'data.RSContext'> iteration 82: loss = 847.5931, delta_loss = 21.89544 learning_Rate = 0.01000 rmse=1.00345 mae=0.78433\n",
      "<class 'data.RSContext'> iteration 83: loss = 826.4536, delta_loss = 21.13953 learning_Rate = 0.01000 rmse=1.00430 mae=0.78497\n",
      "<class 'data.RSContext'> iteration 84: loss = 806.0388, delta_loss = 20.41479 learning_Rate = 0.01000 rmse=1.00513 mae=0.78558\n",
      "<class 'data.RSContext'> iteration 85: loss = 786.3190, delta_loss = 19.71976 learning_Rate = 0.01000 rmse=1.00596 mae=0.78619\n",
      "<class 'data.RSContext'> iteration 86: loss = 767.2660, delta_loss = 19.05303 learning_Rate = 0.01000 rmse=1.00677 mae=0.78679\n",
      "<class 'data.RSContext'> iteration 87: loss = 748.8527, delta_loss = 18.41332 learning_Rate = 0.01000 rmse=1.00757 mae=0.78737\n",
      "<class 'data.RSContext'> iteration 88: loss = 731.0533, delta_loss = 17.79936 learning_Rate = 0.01000 rmse=1.00835 mae=0.78795\n",
      "<class 'data.RSContext'> iteration 89: loss = 713.8433, delta_loss = 17.20999 learning_Rate = 0.01000 rmse=1.00911 mae=0.78851\n",
      "<class 'data.RSContext'> iteration 90: loss = 697.1992, delta_loss = 16.64408 learning_Rate = 0.01000 rmse=1.00986 mae=0.78907\n",
      "<class 'data.RSContext'> iteration 91: loss = 681.0986, delta_loss = 16.10058 learning_Rate = 0.01000 rmse=1.01060 mae=0.78961\n",
      "<class 'data.RSContext'> iteration 92: loss = 665.5202, delta_loss = 15.57847 learning_Rate = 0.01000 rmse=1.01132 mae=0.79014\n",
      "<class 'data.RSContext'> iteration 93: loss = 650.4433, delta_loss = 15.07681 learning_Rate = 0.01000 rmse=1.01204 mae=0.79067\n",
      "<class 'data.RSContext'> iteration 94: loss = 635.8487, delta_loss = 14.59468 learning_Rate = 0.01000 rmse=1.01274 mae=0.79119\n",
      "<class 'data.RSContext'> iteration 95: loss = 621.7174, delta_loss = 14.13122 learning_Rate = 0.01000 rmse=1.01343 mae=0.79169\n",
      "<class 'data.RSContext'> iteration 96: loss = 608.0318, delta_loss = 13.68562 learning_Rate = 0.01000 rmse=1.01411 mae=0.79219\n",
      "<class 'data.RSContext'> iteration 97: loss = 594.7747, delta_loss = 13.25708 learning_Rate = 0.01000 rmse=1.01478 mae=0.79267\n",
      "<class 'data.RSContext'> iteration 98: loss = 581.9299, delta_loss = 12.84488 learning_Rate = 0.01000 rmse=1.01544 mae=0.79315\n",
      "<class 'data.RSContext'> iteration 99: loss = 569.4816, delta_loss = 12.44830 learning_Rate = 0.01000 rmse=1.01609 mae=0.79362\n",
      "<class 'data.RSContext'> iteration 100: loss = 557.4149, delta_loss = 12.06667 learning_Rate = 0.01000 rmse=1.01673 mae=0.79408\n",
      "<class 'data.RSContext'> iteration 101: loss = 545.7155, delta_loss = 11.69936 learning_Rate = 0.01000 rmse=1.01736 mae=0.79453\n",
      "<class 'data.RSContext'> iteration 102: loss = 534.3698, delta_loss = 11.34575 learning_Rate = 0.01000 rmse=1.01798 mae=0.79498\n",
      "<class 'data.RSContext'> iteration 103: loss = 523.3645, delta_loss = 11.00526 learning_Rate = 0.01000 rmse=1.01859 mae=0.79541\n",
      "<class 'data.RSContext'> iteration 104: loss = 512.6872, delta_loss = 10.67734 learning_Rate = 0.01000 rmse=1.01919 mae=0.79585\n",
      "<class 'data.RSContext'> iteration 105: loss = 502.3257, delta_loss = 10.36145 learning_Rate = 0.01000 rmse=1.01979 mae=0.79628\n",
      "<class 'data.RSContext'> iteration 106: loss = 492.2686, delta_loss = 10.05710 learning_Rate = 0.01000 rmse=1.02037 mae=0.79670\n",
      "<class 'data.RSContext'> iteration 107: loss = 482.5048, delta_loss = 9.76381 learning_Rate = 0.01000 rmse=1.02095 mae=0.79711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'data.RSContext'> iteration 108: loss = 473.0237, delta_loss = 9.48110 learning_Rate = 0.01000 rmse=1.02151 mae=0.79752\n",
      "<class 'data.RSContext'> iteration 109: loss = 463.8152, delta_loss = 9.20856 learning_Rate = 0.01000 rmse=1.02207 mae=0.79793\n",
      "<class 'data.RSContext'> iteration 110: loss = 454.8694, delta_loss = 8.94575 learning_Rate = 0.01000 rmse=1.02262 mae=0.79833\n",
      "<class 'data.RSContext'> iteration 111: loss = 446.1771, delta_loss = 8.69227 learning_Rate = 0.01000 rmse=1.02317 mae=0.79872\n",
      "<class 'data.RSContext'> iteration 112: loss = 437.7294, delta_loss = 8.44776 learning_Rate = 0.01000 rmse=1.02370 mae=0.79911\n",
      "<class 'data.RSContext'> iteration 113: loss = 429.5176, delta_loss = 8.21183 learning_Rate = 0.01000 rmse=1.02423 mae=0.79950\n",
      "<class 'data.RSContext'> iteration 114: loss = 421.5334, delta_loss = 7.98415 learning_Rate = 0.01000 rmse=1.02475 mae=0.79988\n",
      "<class 'data.RSContext'> iteration 115: loss = 413.7690, delta_loss = 7.76438 learning_Rate = 0.01000 rmse=1.02526 mae=0.80025\n",
      "<class 'data.RSContext'> iteration 116: loss = 406.2168, delta_loss = 7.55221 learning_Rate = 0.01000 rmse=1.02576 mae=0.80061\n",
      "<class 'data.RSContext'> iteration 117: loss = 398.8695, delta_loss = 7.34732 learning_Rate = 0.01000 rmse=1.02625 mae=0.80097\n",
      "<class 'data.RSContext'> iteration 118: loss = 391.7201, delta_loss = 7.14943 learning_Rate = 0.01000 rmse=1.02674 mae=0.80133\n",
      "<class 'data.RSContext'> iteration 119: loss = 384.7618, delta_loss = 6.95825 learning_Rate = 0.01000 rmse=1.02721 mae=0.80168\n",
      "<class 'data.RSContext'> iteration 120: loss = 377.9883, delta_loss = 6.77354 learning_Rate = 0.01000 rmse=1.02768 mae=0.80202\n",
      "<class 'data.RSContext'> iteration 121: loss = 371.3933, delta_loss = 6.59502 learning_Rate = 0.01000 rmse=1.02814 mae=0.80236\n",
      "<class 'data.RSContext'> iteration 122: loss = 364.9708, delta_loss = 6.42246 learning_Rate = 0.01000 rmse=1.02860 mae=0.80269\n",
      "<class 'data.RSContext'> iteration 123: loss = 358.7152, delta_loss = 6.25563 learning_Rate = 0.01000 rmse=1.02905 mae=0.80302\n",
      "<class 'data.RSContext'> iteration 124: loss = 352.6209, delta_loss = 6.09429 learning_Rate = 0.01000 rmse=1.02949 mae=0.80333\n",
      "<class 'data.RSContext'> iteration 125: loss = 346.6826, delta_loss = 5.93825 learning_Rate = 0.01000 rmse=1.02993 mae=0.80365\n",
      "<class 'data.RSContext'> iteration 126: loss = 340.8953, delta_loss = 5.78729 learning_Rate = 0.01000 rmse=1.03036 mae=0.80395\n",
      "<class 'data.RSContext'> iteration 127: loss = 335.2541, delta_loss = 5.64122 learning_Rate = 0.01000 rmse=1.03078 mae=0.80426\n",
      "<class 'data.RSContext'> iteration 128: loss = 329.7543, delta_loss = 5.49985 learning_Rate = 0.01000 rmse=1.03120 mae=0.80456\n",
      "<class 'data.RSContext'> iteration 129: loss = 324.3913, delta_loss = 5.36301 learning_Rate = 0.01000 rmse=1.03161 mae=0.80486\n",
      "<class 'data.RSContext'> iteration 130: loss = 319.1607, delta_loss = 5.23053 learning_Rate = 0.01000 rmse=1.03201 mae=0.80515\n",
      "<class 'data.RSContext'> iteration 131: loss = 314.0585, delta_loss = 5.10223 learning_Rate = 0.01000 rmse=1.03241 mae=0.80544\n",
      "<class 'data.RSContext'> iteration 132: loss = 309.0805, delta_loss = 4.97796 learning_Rate = 0.01000 rmse=1.03280 mae=0.80572\n",
      "<class 'data.RSContext'> iteration 133: loss = 304.2230, delta_loss = 4.85758 learning_Rate = 0.01000 rmse=1.03319 mae=0.80600\n",
      "<class 'data.RSContext'> iteration 134: loss = 299.4820, delta_loss = 4.74094 learning_Rate = 0.01000 rmse=1.03357 mae=0.80627\n",
      "<class 'data.RSContext'> iteration 135: loss = 294.8541, delta_loss = 4.62789 learning_Rate = 0.01000 rmse=1.03395 mae=0.80655\n",
      "<class 'data.RSContext'> iteration 136: loss = 290.3358, delta_loss = 4.51831 learning_Rate = 0.01000 rmse=1.03432 mae=0.80681\n",
      "<class 'data.RSContext'> iteration 137: loss = 285.9237, delta_loss = 4.41208 learning_Rate = 0.01000 rmse=1.03469 mae=0.80708\n",
      "<class 'data.RSContext'> iteration 138: loss = 281.6147, delta_loss = 4.30906 learning_Rate = 0.01000 rmse=1.03504 mae=0.80734\n",
      "<class 'data.RSContext'> iteration 139: loss = 277.4055, delta_loss = 4.20915 learning_Rate = 0.01000 rmse=1.03540 mae=0.80760\n",
      "<class 'data.RSContext'> iteration 140: loss = 273.2933, delta_loss = 4.11222 learning_Rate = 0.01000 rmse=1.03575 mae=0.80785\n",
      "<class 'data.RSContext'> iteration 141: loss = 269.2751, delta_loss = 4.01818 learning_Rate = 0.01000 rmse=1.03610 mae=0.80810\n",
      "<class 'data.RSContext'> iteration 142: loss = 265.3482, delta_loss = 3.92692 learning_Rate = 0.01000 rmse=1.03644 mae=0.80835\n",
      "<class 'data.RSContext'> iteration 143: loss = 261.5099, delta_loss = 3.83835 learning_Rate = 0.01000 rmse=1.03677 mae=0.80860\n",
      "<class 'data.RSContext'> iteration 144: loss = 257.7575, delta_loss = 3.75235 learning_Rate = 0.01000 rmse=1.03710 mae=0.80884\n",
      "<class 'data.RSContext'> iteration 145: loss = 254.0886, delta_loss = 3.66886 learning_Rate = 0.01000 rmse=1.03744 mae=0.80908\n",
      "<class 'data.RSContext'> iteration 146: loss = 250.5009, delta_loss = 3.58777 learning_Rate = 0.01000 rmse=1.03775 mae=0.80932\n",
      "<class 'data.RSContext'> iteration 147: loss = 246.9919, delta_loss = 3.50901 learning_Rate = 0.01000 rmse=1.03807 mae=0.80955\n",
      "<class 'data.RSContext'> iteration 148: loss = 243.5594, delta_loss = 3.43249 learning_Rate = 0.01000 rmse=1.03839 mae=0.80979\n",
      "<class 'data.RSContext'> iteration 149: loss = 240.2012, delta_loss = 3.35814 learning_Rate = 0.01000 rmse=1.03870 mae=0.81002\n",
      "<class 'data.RSContext'> iteration 150: loss = 236.9153, delta_loss = 3.28589 learning_Rate = 0.01000 rmse=1.03900 mae=0.81024\n",
      "<class 'data.RSContext'> iteration 151: loss = 233.6997, delta_loss = 3.21565 learning_Rate = 0.01000 rmse=1.03930 mae=0.81047\n",
      "<class 'data.RSContext'> iteration 152: loss = 230.5523, delta_loss = 3.14737 learning_Rate = 0.01000 rmse=1.03960 mae=0.81069\n",
      "<class 'data.RSContext'> iteration 153: loss = 227.4713, delta_loss = 3.08098 learning_Rate = 0.01000 rmse=1.03990 mae=0.81091\n",
      "<class 'data.RSContext'> iteration 154: loss = 224.4549, delta_loss = 3.01641 learning_Rate = 0.01000 rmse=1.04018 mae=0.81112\n",
      "<class 'data.RSContext'> iteration 155: loss = 221.5013, delta_loss = 2.95360 learning_Rate = 0.01000 rmse=1.04046 mae=0.81133\n",
      "<class 'data.RSContext'> iteration 156: loss = 218.6088, delta_loss = 2.89250 learning_Rate = 0.01000 rmse=1.04074 mae=0.81153\n",
      "<class 'data.RSContext'> iteration 157: loss = 215.7758, delta_loss = 2.83304 learning_Rate = 0.01000 rmse=1.04101 mae=0.81174\n",
      "<class 'data.RSContext'> iteration 158: loss = 213.0006, delta_loss = 2.77519 learning_Rate = 0.01000 rmse=1.04128 mae=0.81193\n",
      "<class 'data.RSContext'> iteration 159: loss = 210.2817, delta_loss = 2.71887 learning_Rate = 0.01000 rmse=1.04155 mae=0.81213\n",
      "<class 'data.RSContext'> iteration 160: loss = 207.6177, delta_loss = 2.66404 learning_Rate = 0.01000 rmse=1.04181 mae=0.81232\n",
      "current best rmse is 1.04181, mae is 0.81232\n",
      "80023\n",
      "19977\n",
      "cold start users count 0\n",
      "{\n",
      "    'dataset_name': 'u',\n",
      "    'k_fold_num': 5,\n",
      "    'k_test': 0,\n",
      "    'rating_path': 'Z:/RSA/data/u_ratings.txt',\n",
      "    'rating_cv_path': 'Z:/RSA/data/cv/',\n",
      "    'trust_path': 'Z:/RSA/data/u_trust.txt',\n",
      "    'sep': ' ',\n",
      "    'random_state': 0,\n",
      "    'size': 0.8,\n",
      "    'min_val': 0.5,\n",
      "    'max_val': 4.0,\n",
      "    'coldUserRating': 5,\n",
      "    'factor': 10,\n",
      "    'threshold': 0.0001,\n",
      "    'lr': 0.01,\n",
      "    'maxIter': 100,\n",
      "    'lambdaP': 0.001,\n",
      "    'lambdaQ': 0.001,\n",
      "    'gamma': 0,\n",
      "    'isEarlyStopping': False,\n",
      "    'result_path': '../results/',\n",
      "    'model_path': 'model/',\n",
      "    'result_log_path': 'log/'\n",
      "}\n",
      "80023\n",
      "19977\n",
      "cold start users count 0\n",
      "80023\n",
      "19977\n",
      "cold start users count 0\n",
      "<class 'data.RSContext'> iteration 1: loss = 30511.5589, delta_loss = -30511.55889 learning_Rate = 0.01000 rmse=1.09885 mae=0.86174\n",
      "<class 'data.RSContext'> iteration 2: loss = 7484.9159, delta_loss = 23026.64303 learning_Rate = 0.01000 rmse=1.01371 mae=0.79363\n",
      "<class 'data.RSContext'> iteration 3: loss = 6609.7434, delta_loss = 875.17249 learning_Rate = 0.01000 rmse=0.99971 mae=0.78286\n",
      "<class 'data.RSContext'> iteration 4: loss = 6377.7581, delta_loss = 231.98526 learning_Rate = 0.01000 rmse=0.99548 mae=0.78018\n",
      "<class 'data.RSContext'> iteration 5: loss = 6256.1096, delta_loss = 121.64848 learning_Rate = 0.01000 rmse=0.99339 mae=0.77918\n",
      "<class 'data.RSContext'> iteration 6: loss = 6169.9712, delta_loss = 86.13845 learning_Rate = 0.01000 rmse=0.99200 mae=0.77842\n",
      "<class 'data.RSContext'> iteration 7: loss = 6099.5096, delta_loss = 70.46159 learning_Rate = 0.01000 rmse=0.99089 mae=0.77780\n",
      "<class 'data.RSContext'> iteration 8: loss = 6036.9261, delta_loss = 62.58350 learning_Rate = 0.01000 rmse=0.99009 mae=0.77732\n",
      "<class 'data.RSContext'> iteration 9: loss = 5978.2562, delta_loss = 58.66988 learning_Rate = 0.01000 rmse=0.98942 mae=0.77692\n",
      "<class 'data.RSContext'> iteration 10: loss = 5921.1203, delta_loss = 57.13594 learning_Rate = 0.01000 rmse=0.98882 mae=0.77656\n",
      "<class 'data.RSContext'> iteration 11: loss = 5863.9125, delta_loss = 57.20779 learning_Rate = 0.01000 rmse=0.98819 mae=0.77619\n",
      "<class 'data.RSContext'> iteration 12: loss = 5805.4478, delta_loss = 58.46469 learning_Rate = 0.01000 rmse=0.98754 mae=0.77582\n",
      "<class 'data.RSContext'> iteration 13: loss = 5744.7896, delta_loss = 60.65823 learning_Rate = 0.01000 rmse=0.98688 mae=0.77542\n",
      "<class 'data.RSContext'> iteration 14: loss = 5681.1615, delta_loss = 63.62810 learning_Rate = 0.01000 rmse=0.98618 mae=0.77497\n",
      "<class 'data.RSContext'> iteration 15: loss = 5613.9041, delta_loss = 67.25735 learning_Rate = 0.01000 rmse=0.98544 mae=0.77448\n",
      "<class 'data.RSContext'> iteration 16: loss = 5542.4583, delta_loss = 71.44584 learning_Rate = 0.01000 rmse=0.98464 mae=0.77391\n",
      "<class 'data.RSContext'> iteration 17: loss = 5466.3648, delta_loss = 76.09344 learning_Rate = 0.01000 rmse=0.98378 mae=0.77328\n",
      "<class 'data.RSContext'> iteration 18: loss = 5385.2758, delta_loss = 81.08909 learning_Rate = 0.01000 rmse=0.98284 mae=0.77259\n",
      "<class 'data.RSContext'> iteration 19: loss = 5298.9710, delta_loss = 86.30480 learning_Rate = 0.01000 rmse=0.98183 mae=0.77184\n",
      "<class 'data.RSContext'> iteration 20: loss = 5207.3764, delta_loss = 91.59451 learning_Rate = 0.01000 rmse=0.98073 mae=0.77100\n",
      "<class 'data.RSContext'> iteration 21: loss = 5110.5783, delta_loss = 96.79812 learning_Rate = 0.01000 rmse=0.97958 mae=0.77011\n",
      "<class 'data.RSContext'> iteration 22: loss = 5008.8276, delta_loss = 101.75074 learning_Rate = 0.01000 rmse=0.97835 mae=0.76915\n",
      "<class 'data.RSContext'> iteration 23: loss = 4902.5316, delta_loss = 106.29597 learning_Rate = 0.01000 rmse=0.97709 mae=0.76813\n",
      "<class 'data.RSContext'> iteration 24: loss = 4792.2307, delta_loss = 110.30091 learning_Rate = 0.01000 rmse=0.97580 mae=0.76705\n",
      "<class 'data.RSContext'> iteration 25: loss = 4678.5613, delta_loss = 113.66944 learning_Rate = 0.01000 rmse=0.97451 mae=0.76598\n",
      "<class 'data.RSContext'> iteration 26: loss = 4562.2110, delta_loss = 116.35023 learning_Rate = 0.01000 rmse=0.97324 mae=0.76493\n",
      "<class 'data.RSContext'> iteration 27: loss = 4443.8739, delta_loss = 118.33717 learning_Rate = 0.01000 rmse=0.97202 mae=0.76390\n",
      "<class 'data.RSContext'> iteration 28: loss = 4324.2117, delta_loss = 119.66215 learning_Rate = 0.01000 rmse=0.97088 mae=0.76292\n",
      "<class 'data.RSContext'> iteration 29: loss = 4203.8292, delta_loss = 120.38251 learning_Rate = 0.01000 rmse=0.96980 mae=0.76198\n",
      "<class 'data.RSContext'> iteration 30: loss = 4083.2622, delta_loss = 120.56699 learning_Rate = 0.01000 rmse=0.96882 mae=0.76110\n",
      "<class 'data.RSContext'> iteration 31: loss = 3962.9784, delta_loss = 120.28379 learning_Rate = 0.01000 rmse=0.96794 mae=0.76027\n",
      "<class 'data.RSContext'> iteration 32: loss = 3843.3853, delta_loss = 119.59309 learning_Rate = 0.01000 rmse=0.96717 mae=0.75955\n",
      "<class 'data.RSContext'> iteration 33: loss = 3724.8411, delta_loss = 118.54426 learning_Rate = 0.01000 rmse=0.96652 mae=0.75895\n",
      "<class 'data.RSContext'> iteration 34: loss = 3607.6643, delta_loss = 117.17676 learning_Rate = 0.01000 rmse=0.96600 mae=0.75843\n",
      "<class 'data.RSContext'> iteration 35: loss = 3492.1414, delta_loss = 115.52290 learning_Rate = 0.01000 rmse=0.96561 mae=0.75801\n",
      "<class 'data.RSContext'> iteration 36: loss = 3378.5304, delta_loss = 113.61097 learning_Rate = 0.01000 rmse=0.96535 mae=0.75768\n",
      "<class 'data.RSContext'> iteration 37: loss = 3267.0627, delta_loss = 111.46776 learning_Rate = 0.01000 rmse=0.96521 mae=0.75745\n",
      "<class 'data.RSContext'> iteration 38: loss = 3157.9427, delta_loss = 109.12002 learning_Rate = 0.01000 rmse=0.96517 mae=0.75730\n",
      "<class 'data.RSContext'> iteration 39: loss = 3051.3476, delta_loss = 106.59504 learning_Rate = 0.01000 rmse=0.96525 mae=0.75724\n",
      "<class 'data.RSContext'> iteration 40: loss = 2947.4271, delta_loss = 103.92055 learning_Rate = 0.01000 rmse=0.96542 mae=0.75727\n",
      "<class 'data.RSContext'> iteration 41: loss = 2846.3028, delta_loss = 101.12430 learning_Rate = 0.01000 rmse=0.96569 mae=0.75738\n",
      "<class 'data.RSContext'> iteration 42: loss = 2748.0693, delta_loss = 98.23344 learning_Rate = 0.01000 rmse=0.96605 mae=0.75755\n",
      "<class 'data.RSContext'> iteration 43: loss = 2652.7953, delta_loss = 95.27401 learning_Rate = 0.01000 rmse=0.96649 mae=0.75778\n",
      "<class 'data.RSContext'> iteration 44: loss = 2560.5249, delta_loss = 92.27045 learning_Rate = 0.01000 rmse=0.96701 mae=0.75808\n",
      "<class 'data.RSContext'> iteration 45: loss = 2471.2796, delta_loss = 89.24523 learning_Rate = 0.01000 rmse=0.96760 mae=0.75844\n",
      "<class 'data.RSContext'> iteration 46: loss = 2385.0610, delta_loss = 86.21864 learning_Rate = 0.01000 rmse=0.96826 mae=0.75888\n",
      "<class 'data.RSContext'> iteration 47: loss = 2301.8523, delta_loss = 83.20866 learning_Rate = 0.01000 rmse=0.96898 mae=0.75936\n",
      "<class 'data.RSContext'> iteration 48: loss = 2221.6214, delta_loss = 80.23089 learning_Rate = 0.01000 rmse=0.96973 mae=0.75989\n",
      "<class 'data.RSContext'> iteration 49: loss = 2144.3228, delta_loss = 77.29859 learning_Rate = 0.01000 rmse=0.97053 mae=0.76046\n",
      "<class 'data.RSContext'> iteration 50: loss = 2069.9000, delta_loss = 74.42280 learning_Rate = 0.01000 rmse=0.97136 mae=0.76107\n",
      "<class 'data.RSContext'> iteration 51: loss = 1998.2876, delta_loss = 71.61247 learning_Rate = 0.01000 rmse=0.97223 mae=0.76170\n",
      "<class 'data.RSContext'> iteration 52: loss = 1929.4129, delta_loss = 68.87464 learning_Rate = 0.01000 rmse=0.97311 mae=0.76235\n",
      "<class 'data.RSContext'> iteration 53: loss = 1863.1983, delta_loss = 66.21462 learning_Rate = 0.01000 rmse=0.97402 mae=0.76303\n",
      "<class 'data.RSContext'> iteration 54: loss = 1799.5621, delta_loss = 63.63623 learning_Rate = 0.01000 rmse=0.97494 mae=0.76371\n",
      "<class 'data.RSContext'> iteration 55: loss = 1738.4201, delta_loss = 61.14201 learning_Rate = 0.01000 rmse=0.97587 mae=0.76440\n",
      "<class 'data.RSContext'> iteration 56: loss = 1679.6867, delta_loss = 58.73336 learning_Rate = 0.01000 rmse=0.97682 mae=0.76512\n",
      "<class 'data.RSContext'> iteration 57: loss = 1623.2759, delta_loss = 56.41081 learning_Rate = 0.01000 rmse=0.97777 mae=0.76585\n",
      "<class 'data.RSContext'> iteration 58: loss = 1569.1018, delta_loss = 54.17410 learning_Rate = 0.01000 rmse=0.97874 mae=0.76659\n",
      "<class 'data.RSContext'> iteration 59: loss = 1517.0794, delta_loss = 52.02238 learning_Rate = 0.01000 rmse=0.97970 mae=0.76733\n",
      "<class 'data.RSContext'> iteration 60: loss = 1467.1251, delta_loss = 49.95432 learning_Rate = 0.01000 rmse=0.98067 mae=0.76807\n",
      "<class 'data.RSContext'> iteration 61: loss = 1419.1569, delta_loss = 47.96823 learning_Rate = 0.01000 rmse=0.98163 mae=0.76880\n",
      "<class 'data.RSContext'> iteration 62: loss = 1373.0948, delta_loss = 46.06211 learning_Rate = 0.01000 rmse=0.98258 mae=0.76952\n",
      "<class 'data.RSContext'> iteration 63: loss = 1328.8610, delta_loss = 44.23378 learning_Rate = 0.01000 rmse=0.98353 mae=0.77022\n",
      "<class 'data.RSContext'> iteration 64: loss = 1286.3801, delta_loss = 42.48089 learning_Rate = 0.01000 rmse=0.98447 mae=0.77092\n",
      "<class 'data.RSContext'> iteration 65: loss = 1245.5791, delta_loss = 40.80101 learning_Rate = 0.01000 rmse=0.98541 mae=0.77161\n",
      "<class 'data.RSContext'> iteration 66: loss = 1206.3875, delta_loss = 39.19163 learning_Rate = 0.01000 rmse=0.98633 mae=0.77231\n",
      "<class 'data.RSContext'> iteration 67: loss = 1168.7372, delta_loss = 37.65023 learning_Rate = 0.01000 rmse=0.98724 mae=0.77298\n",
      "<class 'data.RSContext'> iteration 68: loss = 1132.5630, delta_loss = 36.17428 learning_Rate = 0.01000 rmse=0.98815 mae=0.77366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'data.RSContext'> iteration 69: loss = 1097.8017, delta_loss = 34.76126 learning_Rate = 0.01000 rmse=0.98904 mae=0.77432\n",
      "<class 'data.RSContext'> iteration 70: loss = 1064.3930, delta_loss = 33.40870 learning_Rate = 0.01000 rmse=0.98993 mae=0.77497\n",
      "<class 'data.RSContext'> iteration 71: loss = 1032.2789, delta_loss = 32.11414 learning_Rate = 0.01000 rmse=0.99080 mae=0.77562\n",
      "<class 'data.RSContext'> iteration 72: loss = 1001.4037, delta_loss = 30.87520 learning_Rate = 0.01000 rmse=0.99166 mae=0.77627\n",
      "<class 'data.RSContext'> iteration 73: loss = 971.7141, delta_loss = 29.68956 learning_Rate = 0.01000 rmse=0.99251 mae=0.77690\n",
      "<class 'data.RSContext'> iteration 74: loss = 943.1592, delta_loss = 28.55495 learning_Rate = 0.01000 rmse=0.99334 mae=0.77752\n",
      "<class 'data.RSContext'> iteration 75: loss = 915.6900, delta_loss = 27.46918 learning_Rate = 0.01000 rmse=0.99416 mae=0.77813\n",
      "<class 'data.RSContext'> iteration 76: loss = 889.2598, delta_loss = 26.43013 learning_Rate = 0.01000 rmse=0.99496 mae=0.77874\n",
      "<class 'data.RSContext'> iteration 77: loss = 863.8241, delta_loss = 25.43575 learning_Rate = 0.01000 rmse=0.99575 mae=0.77932\n",
      "<class 'data.RSContext'> iteration 78: loss = 839.3400, delta_loss = 24.48407 learning_Rate = 0.01000 rmse=0.99653 mae=0.77991\n",
      "<class 'data.RSContext'> iteration 79: loss = 815.7668, delta_loss = 23.57318 learning_Rate = 0.01000 rmse=0.99729 mae=0.78048\n",
      "<class 'data.RSContext'> iteration 80: loss = 793.0656, delta_loss = 22.70127 learning_Rate = 0.01000 rmse=0.99804 mae=0.78104\n",
      "<class 'data.RSContext'> iteration 81: loss = 771.1990, delta_loss = 21.86658 learning_Rate = 0.01000 rmse=0.99879 mae=0.78160\n",
      "<class 'data.RSContext'> iteration 82: loss = 750.1315, delta_loss = 21.06744 learning_Rate = 0.01000 rmse=0.99952 mae=0.78215\n",
      "<class 'data.RSContext'> iteration 83: loss = 729.8293, delta_loss = 20.30223 learning_Rate = 0.01000 rmse=1.00024 mae=0.78269\n",
      "<class 'data.RSContext'> iteration 84: loss = 710.2599, delta_loss = 19.56942 learning_Rate = 0.01000 rmse=1.00094 mae=0.78321\n",
      "<class 'data.RSContext'> iteration 85: loss = 691.3924, delta_loss = 18.86753 learning_Rate = 0.01000 rmse=1.00163 mae=0.78372\n",
      "<class 'data.RSContext'> iteration 86: loss = 673.1972, delta_loss = 18.19517 learning_Rate = 0.01000 rmse=1.00231 mae=0.78422\n",
      "<class 'data.RSContext'> iteration 87: loss = 655.6462, delta_loss = 17.55098 learning_Rate = 0.01000 rmse=1.00297 mae=0.78471\n",
      "<class 'data.RSContext'> iteration 88: loss = 638.7125, delta_loss = 16.93368 learning_Rate = 0.01000 rmse=1.00362 mae=0.78519\n",
      "<class 'data.RSContext'> iteration 89: loss = 622.3705, delta_loss = 16.34206 learning_Rate = 0.01000 rmse=1.00427 mae=0.78567\n",
      "<class 'data.RSContext'> iteration 90: loss = 606.5955, delta_loss = 15.77493 learning_Rate = 0.01000 rmse=1.00491 mae=0.78614\n",
      "<class 'data.RSContext'> iteration 91: loss = 591.3644, delta_loss = 15.23119 learning_Rate = 0.01000 rmse=1.00554 mae=0.78661\n",
      "<class 'data.RSContext'> iteration 92: loss = 576.6546, delta_loss = 14.70978 learning_Rate = 0.01000 rmse=1.00615 mae=0.78707\n",
      "<class 'data.RSContext'> iteration 93: loss = 562.4449, delta_loss = 14.20969 learning_Rate = 0.01000 rmse=1.00676 mae=0.78752\n",
      "<class 'data.RSContext'> iteration 94: loss = 548.7149, delta_loss = 13.72994 learning_Rate = 0.01000 rmse=1.00736 mae=0.78796\n",
      "<class 'data.RSContext'> iteration 95: loss = 535.4453, delta_loss = 13.26962 learning_Rate = 0.01000 rmse=1.00794 mae=0.78839\n",
      "<class 'data.RSContext'> iteration 96: loss = 522.6175, delta_loss = 12.82786 learning_Rate = 0.01000 rmse=1.00852 mae=0.78882\n",
      "<class 'data.RSContext'> iteration 97: loss = 510.2136, delta_loss = 12.40381 learning_Rate = 0.01000 rmse=1.00908 mae=0.78924\n",
      "<class 'data.RSContext'> iteration 98: loss = 498.2170, delta_loss = 11.99669 learning_Rate = 0.01000 rmse=1.00963 mae=0.78965\n",
      "<class 'data.RSContext'> iteration 99: loss = 486.6112, delta_loss = 11.60573 learning_Rate = 0.01000 rmse=1.01018 mae=0.79006\n",
      "<class 'data.RSContext'> iteration 100: loss = 475.3810, delta_loss = 11.23022 learning_Rate = 0.01000 rmse=1.01071 mae=0.79045\n",
      "<class 'data.RSContext'> iteration 101: loss = 464.5115, delta_loss = 10.86946 learning_Rate = 0.01000 rmse=1.01124 mae=0.79085\n",
      "<class 'data.RSContext'> iteration 102: loss = 453.9887, delta_loss = 10.52280 learning_Rate = 0.01000 rmse=1.01176 mae=0.79123\n",
      "<class 'data.RSContext'> iteration 103: loss = 443.7991, delta_loss = 10.18961 learning_Rate = 0.01000 rmse=1.01227 mae=0.79161\n",
      "<class 'data.RSContext'> iteration 104: loss = 433.9298, delta_loss = 9.86931 learning_Rate = 0.01000 rmse=1.01277 mae=0.79198\n",
      "<class 'data.RSContext'> iteration 105: loss = 424.3685, delta_loss = 9.56132 learning_Rate = 0.01000 rmse=1.01326 mae=0.79234\n",
      "<class 'data.RSContext'> iteration 106: loss = 415.1034, delta_loss = 9.26510 learning_Rate = 0.01000 rmse=1.01374 mae=0.79270\n",
      "<class 'data.RSContext'> iteration 107: loss = 406.1232, delta_loss = 8.98015 learning_Rate = 0.01000 rmse=1.01422 mae=0.79306\n",
      "<class 'data.RSContext'> iteration 108: loss = 397.4173, delta_loss = 8.70596 learning_Rate = 0.01000 rmse=1.01468 mae=0.79341\n",
      "<class 'data.RSContext'> iteration 109: loss = 388.9752, delta_loss = 8.44208 learning_Rate = 0.01000 rmse=1.01514 mae=0.79375\n",
      "<class 'data.RSContext'> iteration 110: loss = 380.7871, delta_loss = 8.18806 learning_Rate = 0.01000 rmse=1.01558 mae=0.79409\n",
      "<class 'data.RSContext'> iteration 111: loss = 372.8437, delta_loss = 7.94347 learning_Rate = 0.01000 rmse=1.01602 mae=0.79442\n",
      "<class 'data.RSContext'> iteration 112: loss = 365.1358, delta_loss = 7.70791 learning_Rate = 0.01000 rmse=1.01645 mae=0.79475\n",
      "<class 'data.RSContext'> iteration 113: loss = 357.6548, delta_loss = 7.48099 learning_Rate = 0.01000 rmse=1.01688 mae=0.79507\n",
      "<class 'data.RSContext'> iteration 114: loss = 350.3924, delta_loss = 7.26235 learning_Rate = 0.01000 rmse=1.01729 mae=0.79539\n",
      "<class 'data.RSContext'> iteration 115: loss = 343.3408, delta_loss = 7.05164 learning_Rate = 0.01000 rmse=1.01770 mae=0.79570\n",
      "<class 'data.RSContext'> iteration 116: loss = 336.4923, delta_loss = 6.84853 learning_Rate = 0.01000 rmse=1.01810 mae=0.79600\n",
      "<class 'data.RSContext'> iteration 117: loss = 329.8396, delta_loss = 6.65269 learning_Rate = 0.01000 rmse=1.01849 mae=0.79630\n",
      "<class 'data.RSContext'> iteration 118: loss = 323.3758, delta_loss = 6.46382 learning_Rate = 0.01000 rmse=1.01888 mae=0.79659\n",
      "<class 'data.RSContext'> iteration 119: loss = 317.0941, delta_loss = 6.28163 learning_Rate = 0.01000 rmse=1.01925 mae=0.79688\n",
      "<class 'data.RSContext'> iteration 120: loss = 310.9883, delta_loss = 6.10585 learning_Rate = 0.01000 rmse=1.01962 mae=0.79717\n",
      "<class 'data.RSContext'> iteration 121: loss = 305.0520, delta_loss = 5.93622 learning_Rate = 0.01000 rmse=1.01999 mae=0.79745\n",
      "<class 'data.RSContext'> iteration 122: loss = 299.2796, delta_loss = 5.77247 learning_Rate = 0.01000 rmse=1.02034 mae=0.79773\n",
      "<class 'data.RSContext'> iteration 123: loss = 293.6652, delta_loss = 5.61438 learning_Rate = 0.01000 rmse=1.02070 mae=0.79800\n",
      "<class 'data.RSContext'> iteration 124: loss = 288.2035, delta_loss = 5.46171 learning_Rate = 0.01000 rmse=1.02104 mae=0.79827\n",
      "<class 'data.RSContext'> iteration 125: loss = 282.8892, delta_loss = 5.31425 learning_Rate = 0.01000 rmse=1.02138 mae=0.79853\n",
      "<class 'data.RSContext'> iteration 126: loss = 277.7175, delta_loss = 5.17178 learning_Rate = 0.01000 rmse=1.02171 mae=0.79878\n",
      "<class 'data.RSContext'> iteration 127: loss = 272.6834, delta_loss = 5.03410 learning_Rate = 0.01000 rmse=1.02203 mae=0.79903\n",
      "<class 'data.RSContext'> iteration 128: loss = 267.7823, delta_loss = 4.90103 learning_Rate = 0.01000 rmse=1.02235 mae=0.79928\n",
      "<class 'data.RSContext'> iteration 129: loss = 263.0099, delta_loss = 4.77239 learning_Rate = 0.01000 rmse=1.02266 mae=0.79953\n",
      "<class 'data.RSContext'> iteration 130: loss = 258.3619, delta_loss = 4.64800 learning_Rate = 0.01000 rmse=1.02297 mae=0.79976\n",
      "<class 'data.RSContext'> iteration 131: loss = 253.8342, delta_loss = 4.52769 learning_Rate = 0.01000 rmse=1.02327 mae=0.80000\n",
      "<class 'data.RSContext'> iteration 132: loss = 249.4229, delta_loss = 4.41130 learning_Rate = 0.01000 rmse=1.02357 mae=0.80023\n",
      "<class 'data.RSContext'> iteration 133: loss = 245.1242, delta_loss = 4.29869 learning_Rate = 0.01000 rmse=1.02386 mae=0.80046\n",
      "<class 'data.RSContext'> iteration 134: loss = 240.9345, delta_loss = 4.18971 learning_Rate = 0.01000 rmse=1.02415 mae=0.80069\n",
      "<class 'data.RSContext'> iteration 135: loss = 236.8503, delta_loss = 4.08422 learning_Rate = 0.01000 rmse=1.02443 mae=0.80091\n",
      "<class 'data.RSContext'> iteration 136: loss = 232.8682, delta_loss = 3.98209 learning_Rate = 0.01000 rmse=1.02471 mae=0.80113\n",
      "<class 'data.RSContext'> iteration 137: loss = 228.9851, delta_loss = 3.88318 learning_Rate = 0.01000 rmse=1.02498 mae=0.80134\n",
      "<class 'data.RSContext'> iteration 138: loss = 225.1977, delta_loss = 3.78739 learning_Rate = 0.01000 rmse=1.02525 mae=0.80154\n",
      "<class 'data.RSContext'> iteration 139: loss = 221.5031, delta_loss = 3.69458 learning_Rate = 0.01000 rmse=1.02551 mae=0.80175\n",
      "<class 'data.RSContext'> iteration 140: loss = 217.8984, delta_loss = 3.60466 learning_Rate = 0.01000 rmse=1.02577 mae=0.80196\n",
      "<class 'data.RSContext'> iteration 141: loss = 214.3809, delta_loss = 3.51751 learning_Rate = 0.01000 rmse=1.02602 mae=0.80216\n",
      "<class 'data.RSContext'> iteration 142: loss = 210.9479, delta_loss = 3.43304 learning_Rate = 0.01000 rmse=1.02627 mae=0.80236\n",
      "<class 'data.RSContext'> iteration 143: loss = 207.5967, delta_loss = 3.35113 learning_Rate = 0.01000 rmse=1.02652 mae=0.80255\n",
      "<class 'data.RSContext'> iteration 144: loss = 204.3250, delta_loss = 3.27171 learning_Rate = 0.01000 rmse=1.02676 mae=0.80274\n",
      "<class 'data.RSContext'> iteration 145: loss = 201.1303, delta_loss = 3.19469 learning_Rate = 0.01000 rmse=1.02700 mae=0.80293\n",
      "<class 'data.RSContext'> iteration 146: loss = 198.0104, delta_loss = 3.11996 learning_Rate = 0.01000 rmse=1.02723 mae=0.80312\n",
      "<class 'data.RSContext'> iteration 147: loss = 194.9629, delta_loss = 3.04746 learning_Rate = 0.01000 rmse=1.02746 mae=0.80330\n",
      "<class 'data.RSContext'> iteration 148: loss = 191.9858, delta_loss = 2.97710 learning_Rate = 0.01000 rmse=1.02768 mae=0.80347\n",
      "<class 'data.RSContext'> iteration 149: loss = 189.0770, delta_loss = 2.90881 learning_Rate = 0.01000 rmse=1.02790 mae=0.80365\n",
      "<class 'data.RSContext'> iteration 150: loss = 186.2345, delta_loss = 2.84251 learning_Rate = 0.01000 rmse=1.02812 mae=0.80382\n",
      "<class 'data.RSContext'> iteration 151: loss = 183.4564, delta_loss = 2.77814 learning_Rate = 0.01000 rmse=1.02833 mae=0.80399\n",
      "<class 'data.RSContext'> iteration 152: loss = 180.7407, delta_loss = 2.71562 learning_Rate = 0.01000 rmse=1.02854 mae=0.80415\n",
      "<class 'data.RSContext'> iteration 153: loss = 178.0858, delta_loss = 2.65490 learning_Rate = 0.01000 rmse=1.02875 mae=0.80431\n",
      "<class 'data.RSContext'> iteration 154: loss = 175.4899, delta_loss = 2.59591 learning_Rate = 0.01000 rmse=1.02895 mae=0.80448\n",
      "<class 'data.RSContext'> iteration 155: loss = 172.9513, delta_loss = 2.53860 learning_Rate = 0.01000 rmse=1.02915 mae=0.80463\n",
      "<class 'data.RSContext'> iteration 156: loss = 170.4684, delta_loss = 2.48289 learning_Rate = 0.01000 rmse=1.02934 mae=0.80479\n",
      "<class 'data.RSContext'> iteration 157: loss = 168.0397, delta_loss = 2.42875 learning_Rate = 0.01000 rmse=1.02954 mae=0.80494\n",
      "<class 'data.RSContext'> iteration 158: loss = 165.6636, delta_loss = 2.37612 learning_Rate = 0.01000 rmse=1.02973 mae=0.80508\n",
      "<class 'data.RSContext'> iteration 159: loss = 163.3386, delta_loss = 2.32494 learning_Rate = 0.01000 rmse=1.02991 mae=0.80522\n",
      "<class 'data.RSContext'> iteration 160: loss = 161.0634, delta_loss = 2.27518 learning_Rate = 0.01000 rmse=1.03010 mae=0.80537\n",
      "current best rmse is 1.03010, mae is 0.80537\n"
     ]
    }
   ],
   "source": [
    "rc_svd_fac = []\n",
    "preci_svd_fac = []\n",
    "for factors in [10,20,30,40,50,60,70,80,90,100]:\n",
    "    f = {'factors':factors}\n",
    "    svdpp = SVDPP(**f)\n",
    "    temp_svd = run_func(init_model=svdpp.init_model,train_model=svdpp.train_model,predict = svdpp.predict)\n",
    "    rc = recall_svd(temp_svd)\n",
    "    rc_svd_fac.append(rc)\n",
    "    preci = precision_svd(temp_svd)\n",
    "    preci_svd_fac.append(preci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.004455123391900686,\n",
       " 0.008259498423186665,\n",
       " 0.009711167843019472,\n",
       " 0.013165139910897532,\n",
       " 0.012214046153076037,\n",
       " 0.0123141612854783,\n",
       " 0.013165139910897532,\n",
       " 0.01191370075586925,\n",
       " 0.012514391550282826,\n",
       " 0.010762376733243229]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc_svd_fac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01887592788971368,\n",
       " 0.03499469777306469,\n",
       " 0.04114528101802757,\n",
       " 0.055779427359490985,\n",
       " 0.05174973488865323,\n",
       " 0.05217391304347826,\n",
       " 0.055779427359490985,\n",
       " 0.05047720042417816,\n",
       " 0.053022269353128315,\n",
       " 0.04559915164369035]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preci_svd_fac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with fixed other parameters and then change number of recomm-items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot all recall curve and precision curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "bpr_svd = pd.DataFrame(index = [10,50,100,150,200,250,300],columns = ['rc_svd','preci_svd','rc_bpr','preci_bpr'])\n",
    "bpr_svd.rc_svd = rc_list_svd\n",
    "bpr_svd.preci_svd = preci_list_svd\n",
    "bpr_svd.rc_bpr = rc_list_bpr\n",
    "bpr_svd.preci_bpr = preci_list_bpr\n",
    "bpr_svd\n",
    "bpr_svd.plot.line()\n",
    "plt.xlabel('Number of Recomm_items')\n",
    "plt.ylabel('rate')\n",
    "plt.title('bpr svd recall/precision compare with iteration=160')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the number of recommended items increases, the recall rate continues to rise for BPR but its precision is always at a lower level in the figure. For SVD, the recall rate also continues to rise, and the precision rate will continue to decline. In comparison, SVD's precision and recall rate are higher than BPR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot precision-recall curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))   \n",
    "plt.subplot(1,2,1) \n",
    "p1 = bpr_svd.sort_values(by='rc_svd')\n",
    "plt.plot(p1.rc_svd,p1.preci_svd,\"b\",label='svd precision-recall curve',linestyle='-.')\n",
    "plt.legend()\n",
    "plt.xlabel(\"recall rate\")\n",
    "plt.ylabel(\"precision rate\")\n",
    "\n",
    "plt.subplot(1,2,2)    \n",
    "p2 = bpr_svd.sort_values(by='rc_bpr')\n",
    "plt.plot(p2.rc_bpr,p2.preci_bpr,\"b\",label='bpr precision-recall curve',linestyle='-.')  \n",
    "plt.legend()\n",
    "plt.xlabel(\"recall rate\")\n",
    "plt.ylabel(\"precision rate\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Precision-Recall curve, we find that BPR presents a significantly inverse trend, and SVD will initially rise sharply until it reaches a highest and then inversely proportional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**plot f-scores curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr_svd['f_value_svd'] = 2*bpr_svd.rc_svd*bpr_svd.preci_svd/(bpr_svd.rc_svd + bpr_svd.preci_svd)\n",
    "bpr_svd['f_value_bpr'] = 2*bpr_svd.rc_bpr*bpr_svd.preci_bpr/(bpr_svd.rc_bpr + bpr_svd.preci_bpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bpr_svd[['f_value_svd','f_value_bpr']].plot()\n",
    "plt.title(\"f-scores of svd/bpr\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The f value of SVD is significantly larger than BPR, so the accuracy and recall rate of SVD is more effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with fixed other parameters and then change number of factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot all recall curve and precision curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bpr_svd_factors = pd.DataFrame(index=[10,20,30,40,50,60,70,80,90,100],columns=['bpr_precision','bpr_recall','svd_precision','svd_recall'])\n",
    "bpr_svd_factors.svd_recall = rc_svd_fac\n",
    "bpr_svd_factors.svd_precision = preci_svd_fac\n",
    "bpr_svd_factors.bpr_recall = rc_bpr_fac\n",
    "bpr_svd_factors.bpr_precision = preci_bpr_fac\n",
    "bpr_svd_factors.plot()\n",
    "plt.xlabel(\"number of factors\")\n",
    "plt.ylabel(\"rate\")\n",
    "plt.title(\"bpr svd factors' effect on recall and precision\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the increase in the number of factors, SVD++'s precision and recall have both increased, the precision rise is relatively large, and the BPR precison and recall have relatively small fluctuations, which are at a relatively low level relative to SVD++."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot precision-recall curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))   \n",
    "plt.subplot(1,2,1) \n",
    "p1 = bpr_svd_factors.sort_values(by='svd_recall')\n",
    "plt.plot(p1.svd_recall,p1.svd_precision,\"b\",label='svd precision-recall curve',linestyle='-.')\n",
    "plt.legend()        \n",
    "plt.xlabel(\"recall rate\")\n",
    "plt.ylabel(\"precision rate\")\n",
    " \n",
    "plt.subplot(1,2,2)\n",
    "p2 = bpr_svd_factors.sort_values(by='bpr_recall')\n",
    "plt.plot(p2.bpr_recall,p2.bpr_precision,\"b\",label='bpr precision-recall curve',linestyle='-.')  \n",
    "plt.legend()\n",
    "plt.xlabel(\"recall rate\")\n",
    "plt.ylabel(\"precision rate\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two figures show that both precision and recall are directly proportional to SVD and BPR, and The proportional relationship of SVD is more stable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**plot f-scores curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr_svd_factors['f_value_svd'] = 2*bpr_svd_factors.svd_recall*bpr_svd_factors.svd_precision/(bpr_svd_factors.svd_recall + bpr_svd_factors.svd_precision)\n",
    "bpr_svd_factors['f_value_bpr'] = 2*bpr_svd_factors.bpr_recall*bpr_svd_factors.bpr_precision/(bpr_svd_factors.bpr_recall + bpr_svd_factors.bpr_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bpr_svd_factors[['f_value_svd','f_value_bpr']].plot()\n",
    "plt.title(\"f-scores of svd/bpr\")\n",
    "plt.xlabel(\"number of factors\")\n",
    "plt.ylabel(\"rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The f value of SVD is significantly larger than BPR, so the accuracy and recall rate of SVD is more effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above evaluation results, SVD++ has higher precision and recall rate than BPR in a range of factors and a certain number of recommendations, and also evaluates the effectiveness of BPR evaluation based on evaluation indicators is greater than BPR. From this point of view, when BPR processes implicit data, its precision and recall are far less than explicit data, although its accuracy in ordering is higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [BPR: Bayesian Personalized Ranking from Implicit Feedback](https://arxiv.org/ftp/arxiv/papers/1205/1205.2618.pdf)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. [Factor in the neighbors: Scalable and accurate collaborative filtering](http://courses.ischool.berkeley.edu/i290-dm/s11/SECURE/a1-koren.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\\\Users\\\\lenovo\\\\Desktop\\\\RS_AE\\\\RSA\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'run_func'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-79a14421f2b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mRSA\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'run_func'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
