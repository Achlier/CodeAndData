{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fc2ca7f",
   "metadata": {},
   "source": [
    "# PyTorch学习-基础笔记（LS1-LS14）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fe23a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dbf9b6",
   "metadata": {},
   "source": [
    "## LS1.初见"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dfbacd",
   "metadata": {},
   "source": [
    "### PyTorch VS TensorFlow\n",
    "\n",
    "- PyTorch ：FaceBook使用的框架，易上手，动态图\n",
    "- TensorFlow ：Google使用的框架，适合工程师搭建，静态图（即需要在Session中Run才能输出，无法方便Debug调参）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fb404f",
   "metadata": {},
   "source": [
    "### PyTorch包\n",
    "\n",
    "- 自然语言处理 ：NLP，AllenNLP\n",
    "- 视觉 ：TorchVision\n",
    "- 图网络/图卷积 ：geometric，Fast.ai\n",
    "- 模型部署 ：ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9252f093",
   "metadata": {},
   "source": [
    "### PyTorch能做什么"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a072c9",
   "metadata": {},
   "source": [
    "#### 1. GPU加速"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f6f7213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1+cu116\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "# 检查版本是否匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee31a097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu 0.3280599117279053 tensor(141364.0156)\n",
      "cuda:0 2.3828623294830322 tensor(141507.7656, device='cuda:0')\n",
      "cuda:0 0.0009987354278564453 tensor(141507.7656, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(10000, 1000)\n",
    "b = torch.randn(1000, 2000)\n",
    "# 创建矩阵\n",
    "\n",
    "t0 = time.time()\n",
    "c = torch.matmul(a, b)\n",
    "t1 = time.time()\n",
    "print(a.device, t1 - t0, c.norm(2))\n",
    "# 使用CPU运算\n",
    "\n",
    "device = torch.device('cuda')\n",
    "a = a.to(device)\n",
    "b = b.to(device)\n",
    "# 将矩阵搬入cuda\n",
    "\n",
    "t0 = time.time()\n",
    "c = torch.matmul(a, b)\n",
    "t2 = time.time()\n",
    "print(a.device, t2 - t0, c.norm(2))\n",
    "# 先进行初始化再在GPU上进行运算\n",
    "\n",
    "t0 = time.time()\n",
    "c = torch.matmul(a, b)\n",
    "t2 = time.time()\n",
    "print(a.device, t2 - t0, c.norm(2))\n",
    "# 初始化上一步已经完成，直接进行运算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587f178e",
   "metadata": {},
   "source": [
    "#### 2. 梯度求导\n",
    "\n",
    "$$\n",
    "y=a^2x+bx+c\\qquad x=1\\qquad a,b,c=2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30c4e1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a8a1cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: None None None\n",
      "after : tensor(4.) tensor(1.) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(1.)\n",
    "a = torch.tensor(2., requires_grad=True)\n",
    "b = torch.tensor(2., requires_grad=True)\n",
    "c = torch.tensor(2., requires_grad=True)\n",
    "# requires_grad=True 告诉pytorch需要求导\n",
    "\n",
    "y = a**2 * x + b * x + c\n",
    "\n",
    "print('before:', a.grad, b.grad, c.grad) # 运算前没有梯度信息\n",
    "grads = autograd.grad(y, [a, b, c])\n",
    "print('after :', grads[0], grads[1], grads[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dabd10",
   "metadata": {},
   "source": [
    "#### 3. 常用网络层\n",
    "\n",
    "- nn.Linear\n",
    "- nn.Conv2d\n",
    "- nn.LSTM\n",
    "\n",
    "\n",
    "- nn.ReLU\n",
    "- nn.Sigmoid\n",
    "\n",
    "\n",
    "- nn.Softmax\n",
    "- nn.CrossEntropyLoss\n",
    "- nn.MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37a2dc2",
   "metadata": {},
   "source": [
    "## LS2.有关数据类型的基本操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eef1eff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n",
      "<class 'torch.Tensor'>\n",
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "a=torch.randn(2,3)\n",
    "\n",
    "print(a.type())\n",
    "print(type(a)) # python自带的方法并不能判断数据是float还是int\n",
    "print(isinstance(a,torch.FloatTensor))\n",
    "print(isinstance(a,torch.cuda.FloatTensor)) # 在cpu上和在cuda上是不一样的\n",
    "a=a.cuda()\n",
    "print(isinstance(a,torch.cuda.FloatTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8370b096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n",
      "0\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "a=torch.tensor(2.2) # 0维度\n",
    "\n",
    "print(a.shape)\n",
    "print(len(a.shape))\n",
    "print(a.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f003ead8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "a=torch.randn(2,3) # 2维度\n",
    "print(a.numel()) #numel指的是tensor占用内存的数量，2*3\n",
    "print(a.dim()) #equal to len(a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee34e08f",
   "metadata": {},
   "source": [
    "## LS3.几个方法创建Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6b3872c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0000, 3.3000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a=np.array([2,3.3]) # import from numpy\n",
    "print(torch.from_numpy(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f91cb050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.3694e-38])\n",
      "tensor([2., 3.])\n",
      "tensor([[3.4007e-06, 2.0823e+23, 1.6839e+22],\n",
      "        [3.3056e+21, 1.6800e-07, 2.1513e+23]])\n",
      "tensor([[ 912537648, 1714446640, 1684288869],\n",
      "        [1664299620,  875848241, 1714829365]], dtype=torch.int32)\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.empty(1))\n",
    "#未初始化的Tensor一定要跟写入数据的后续步骤\n",
    "\n",
    "print(torch.Tensor([2,3]))\n",
    "print(torch.Tensor(2,3))\n",
    "print(torch.IntTensor(2,3))\n",
    "print(torch.FloatTensor(2,3))\n",
    "#.tensor接受的是数据的内容\n",
    "#.Tensor.IntTensor.FloatTensor接受的是数据的shape,除非输入list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adb97dc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.DoubleTensor\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_tensor_type(torch.DoubleTensor) # set default type\n",
    "print(torch.tensor([1.2,3]).type())\n",
    "torch.set_default_tensor_type(torch.FloatTensor) # generally, use default type (torch.FloatTensor)\n",
    "print(torch.tensor([1.2,3]).type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41f23451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4139, 0.1328, 0.8629],\n",
      "        [0.0312, 0.2243, 0.7997],\n",
      "        [0.5681, 0.9832, 0.4253]])\n",
      "tensor([[-0.5769, -0.1792,  1.9824],\n",
      "        [ 0.9507,  0.6540, -0.0424],\n",
      "        [-0.5346, -0.4958, -1.3556]])\n",
      "tensor([[3, 9, 9],\n",
      "        [3, 7, 2],\n",
      "        [9, 6, 2]])\n",
      "tensor([[7, 7, 7],\n",
      "        [7, 7, 7]])\n",
      "tensor([1.0000, 0.9000, 0.8000, 0.7000, 0.6000, 0.5000, 0.4000, 0.3000, 0.2000,\n",
      "        0.1000])\n",
      "tensor([ 0.0000,  3.3333,  6.6667, 10.0000])\n",
      "tensor([1.0000e+00, 2.1544e+03, 4.6416e+06, 1.0000e+10])\n",
      "tensor([[0.4119, 0.3886, 0.6826],\n",
      "        [0.0795, 0.7317, 0.8148],\n",
      "        [0.0499, 0.3007, 0.1318]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.rand(3,3)) #均匀分布rand会随机产生0-1之间的数值，不包括1\n",
    "print(torch.randn(3,3)) #正态分布\n",
    "print(torch.randint(1,10,[3,3])) #均匀采样0-10的tensor\n",
    "print(torch.full([2,3],7)) #生成对应大小由特定元素填满\n",
    "print(torch.arange(1,0,-0.1)) #1-0，间隔0.1\n",
    "print(torch.linspace(0,10,steps=4)) #0-10，等分数列\n",
    "print(torch.logspace(0,10,steps=4)) #返回10的x次方\n",
    "\n",
    "\n",
    "a=torch.rand(3,3)\n",
    "print(torch.rand_like(a)) #仿照a的格式产生"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80ece717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.ones(3,3))\n",
    "print(torch.zeros(3,3))\n",
    "print(torch.eye(3,4)) #单位矩阵\n",
    "\n",
    "a=torch.zeros(3,3)\n",
    "print(torch.ones_like(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9c3bc76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 9, 1, 5, 4, 2, 3, 8, 7, 0])\n",
      "tensor([0, 2, 1])\n",
      "tensor([[0.8521, 0.0413],\n",
      "        [0.8517, 0.5678],\n",
      "        [0.7366, 0.4911]])\n",
      "tensor([[0.8521, 0.0413],\n",
      "        [0.7366, 0.4911],\n",
      "        [0.8517, 0.5678]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.randperm(10))  #随机打散\n",
    "\n",
    "a=torch.rand(3,2)\n",
    "idx=torch.randperm(3)\n",
    "print(idx)\n",
    "print(a)\n",
    "print(a[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdd7881",
   "metadata": {},
   "source": [
    "## LS8.进行索引及切片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "458d7e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5, 5])\n",
      "torch.Size([5, 5])\n",
      "tensor(0.0799)\n"
     ]
    }
   ],
   "source": [
    "a=torch.rand(5,5,5,5)\n",
    "print(a[0].shape)\n",
    "print(a[0,0].shape)\n",
    "print(a[0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8869851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6470, 0.0561, 0.9499],\n",
      "        [0.4071, 0.8629, 0.3111],\n",
      "        [0.9711, 0.5190, 0.8429]])\n",
      "tensor([[0.6470, 0.0561, 0.9499],\n",
      "        [0.4071, 0.8629, 0.3111]])\n",
      "tensor([[0.6470, 0.0561],\n",
      "        [0.4071, 0.8629]])\n",
      "tensor([[0.9499],\n",
      "        [0.3111]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.rand(3,3)\n",
    "print(a[:2])\n",
    "print(a[:2,:-1])\n",
    "print(a[:2,-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a894df6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2740, 0.2456, 0.5549, 0.8365, 0.4994])\n",
      "tensor([0.2740, 0.2456, 0.5549, 0.8365, 0.4994])\n",
      "tensor([0.2740, 0.5549, 0.4994])\n",
      "tensor([0.2740, 0.5549, 0.4994])\n"
     ]
    }
   ],
   "source": [
    "a=torch.rand(5)\n",
    "print(a)\n",
    "print(a[...])\n",
    "print(a[0:5:2])\n",
    "print(a[::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae052a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8389, 0.7743, 0.3600],\n",
      "        [0.5588, 0.4112, 0.4842],\n",
      "        [0.4019, 0.1733, 0.3622]])\n",
      "tensor([[0.8389, 0.7743, 0.3600],\n",
      "        [0.4019, 0.1733, 0.3622]])\n",
      "tensor([[0.8389, 0.3600],\n",
      "        [0.5588, 0.4842],\n",
      "        [0.4019, 0.3622]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.rand(3,3)\n",
    "print(a)\n",
    "print(a.index_select(0,torch.tensor([0,2])))\n",
    "print(a.index_select(1,torch.tensor([0,2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e1161a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6071, 1.4642],\n",
      "        [1.1086, 0.0352]])\n",
      "tensor([[ True,  True],\n",
      "        [ True, False]])\n",
      "tensor([0.6071, 1.4642, 1.1086])\n"
     ]
    }
   ],
   "source": [
    "x=torch.randn(2,2)\n",
    "print(x)\n",
    "mask=x.ge(0.5) #ByteTensor ,随机的\n",
    "print(mask)\n",
    "print(torch.masked_select(x,mask)) #取出所有大于0.5的元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82612e3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 5, 8])\n"
     ]
    }
   ],
   "source": [
    "src=torch.tensor([[4,3,5]\n",
    "                 ,[6,7,8]])\n",
    "\n",
    "print(torch.take(src,torch.tensor([0,2,5]))) # 打平后挑选"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b17227",
   "metadata": {},
   "source": [
    "## LS9.改变数据维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eca65bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 5, 5])\n",
      "torch.Size([3, 75])\n",
      "torch.Size([45, 5])\n",
      "torch.Size([225])\n",
      "torch.Size([3, 3, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "a=torch.rand(3,3,5,5)\n",
    "print(a.shape)\n",
    "print(a.view(3,3*5*5).shape)\n",
    "print(a.view(3*3*5,5).shape)\n",
    "print(a.view(-1).shape)\n",
    "\n",
    "b=a.view(3,3*5*5)\n",
    "print(b.view(3,3,5,5).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "423ee500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 5, 5])\n",
      "torch.Size([1, 3, 3, 5, 5])\n",
      "torch.Size([3, 3, 5, 5, 1])\n"
     ]
    }
   ],
   "source": [
    "print(a.shape)\n",
    "print(a.unsqueeze(0).shape)\n",
    "print(a.unsqueeze(-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "765b5de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 3, 1])\n",
      "torch.Size([3])\n",
      "torch.Size([1, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "b=torch.rand(3).unsqueeze(0).unsqueeze(0).unsqueeze(-1)\n",
    "print(b.shape)\n",
    "print(b.squeeze().shape)\n",
    "print(b.squeeze(0).shape)\n",
    "print(b.squeeze(-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa57ba97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.8181],\n",
      "          [0.3624],\n",
      "          [0.7913]]]])\n",
      "tensor([[[[0.8181],\n",
      "          [0.3624],\n",
      "          [0.7913]],\n",
      "\n",
      "         [[0.8181],\n",
      "          [0.3624],\n",
      "          [0.7913]]]])\n",
      "tensor([[[[0.8181],\n",
      "          [0.3624],\n",
      "          [0.7913]],\n",
      "\n",
      "         [[0.8181],\n",
      "          [0.3624],\n",
      "          [0.7913]]]])\n"
     ]
    }
   ],
   "source": [
    "print(b)\n",
    "print(b.expand(1,2,3,1)) # -1 represent no change\n",
    "print(b.repeat(1,2,1,1)) # 相当于乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac738975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1])\n",
      "torch.Size([3, 2, 1])\n",
      "torch.Size([2, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "c=torch.randn(1,2)\n",
    "print(c.t().shape)\n",
    "\n",
    "c=torch.randn(1,2,3)\n",
    "print(c.transpose(0,2).shape)\n",
    "print(c.permute(1,2,0).shape) # 多次变换"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19f5f41",
   "metadata": {},
   "source": [
    "transpose和permute会打乱内存顺序，要用.contiguous()把内存顺序调整回来。\n",
    "\n",
    "详细见 [此处《Pytorch中的contiguous理解》](https://blog.csdn.net/gdymind/article/details/82662502?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-82662502-blog-107855070.t5_refersearch_landing&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-82662502-blog-107855070.t5_refersearch_landing&utm_relevant_index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251e46cc",
   "metadata": {},
   "source": [
    "## LS11.进行合并与分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "144e6af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "a=torch.rand(2,3,2,4)\n",
    "b=torch.rand(2,3,1,4)\n",
    "print(torch.cat([a,b],dim=2).shape) # 非concat维度必须保持一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c265d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 2, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "a=torch.rand(2,3,1,4)\n",
    "b=torch.rand(2,3,1,4)\n",
    "print(torch.stack([a,b],dim=2).shape) # 必须所有维度全部保持一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bcf9ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1]) torch.Size([2, 3])\n",
      "torch.Size([2, 2]) torch.Size([2, 2])\n",
      "torch.Size([2, 2]) torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "c=torch.rand(2,4)\n",
    "aa,bb=c.split([1,3],dim=1) # 按照长度拆分\n",
    "print(aa.shape,bb.shape)\n",
    "aa,bb=c.split(2,dim=1)\n",
    "print(aa.shape,bb.shape)\n",
    "aa,bb=c.chunk(2,dim=1) # 按数量拆分\n",
    "print(aa.shape,bb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317aa915",
   "metadata": {},
   "source": [
    "## LS12.进行数学运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4845d05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "a=torch.rand(2,3)\n",
    "b=torch.rand(3)\n",
    "\n",
    "print(torch.all(torch.eq(a+b,torch.add(a,b)))) #加\n",
    "print(torch.all(torch.eq(a-b,torch.sub(a,b)))) #减\n",
    "print(torch.all(torch.eq(a*b,torch.mul(a,b)))) #乘\n",
    "print(torch.all(torch.eq(a/b,torch.div(a,b)))) #除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0c4334c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6., 6.],\n",
      "        [6., 6.]])\n",
      "tensor([[6., 6.],\n",
      "        [6., 6.]])\n",
      "tensor([[6., 6.],\n",
      "        [6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.tensor([[3.,3.],[3.,3.]])\n",
    "b=torch.ones(2,2)\n",
    "\n",
    "print(torch.mm(a,b)) #只能用于二维矩阵的相乘\n",
    "print(torch.matmul(a,b)) #可以用于多维矩阵的相乘\n",
    "print(a@b) # @等价于torch.matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2361a6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4, 6])\n",
      "torch.Size([2, 3, 4, 6])\n"
     ]
    }
   ],
   "source": [
    "a=torch.rand(2,3,4,5)\n",
    "\n",
    "b=torch.rand(2,3,5,6)\n",
    "print(torch.matmul(a,b).shape)  #最后两维进行矩阵相乘\n",
    "\n",
    "b=torch.rand(2,1,5,6)\n",
    "print(torch.matmul(a,b).shape)  #用broadcast机制补全后进行运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a2a1eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9, 9],\n",
      "        [9, 9]])\n",
      "tensor([[9, 9],\n",
      "        [9, 9]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.full([2,2],3)\n",
    "\n",
    "print(a.pow(2))\n",
    "print(a**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e87bb843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]])\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]])\n",
      "tensor([[0.3333, 0.3333],\n",
      "        [0.3333, 0.3333]])\n"
     ]
    }
   ],
   "source": [
    "aa=a**2\n",
    "\n",
    "print(aa**0.5)\n",
    "print(aa.sqrt())\n",
    "print(aa.rsqrt()) #平方根的倒数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a15a2b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.7183, 2.7183],\n",
      "        [2.7183, 2.7183]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.exp(torch.ones(2,2))\n",
    "\n",
    "print(a)\n",
    "print(torch.log(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9615fa9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.) tensor(4.) tensor(3.) tensor(0.1400)\n"
     ]
    }
   ],
   "source": [
    "a=torch.tensor(3.14)\n",
    "\n",
    "print(a.floor(),a.ceil(),a.trunc(),a.frac())\n",
    "#a.floor() 向上取整 a.ceil() 向下取整 a.trunc() 取整数位 a.frac() 取小数位 a.round() 四舍五入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e040e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8.3140,  4.7482],\n",
      "        [ 3.6645, 11.5761]])\n",
      "tensor([[10.0000, 10.0000],\n",
      "        [10.0000, 11.5761]])\n",
      "tensor([[ 8.3140,  4.7482],\n",
      "        [ 3.6645, 10.0000]])\n"
     ]
    }
   ],
   "source": [
    "grad=torch.rand(2,2)*15\n",
    "\n",
    "print(grad)\n",
    "print(grad.clamp(10)) #把原矩阵中小于10的都换成10\n",
    "print(grad.clamp(0,10)) #把原矩阵的数的范围换成0-10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de62dd6",
   "metadata": {},
   "source": [
    "## LS13.统计属性运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d1feb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor([[[1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.]]])\n",
      "tensor(8.) tensor(8.)\n",
      "tensor(2.8284) tensor(2.8284)\n"
     ]
    }
   ],
   "source": [
    "a=torch.full([8],1,dtype=torch.float32) #加上数据类型\n",
    "b=a.view(2,4)\n",
    "c=a.view(2,2,2)\n",
    "print(b)\n",
    "print(c)\n",
    "\n",
    "print(b.norm(1),c.norm(1)) # 1-范数：绝对值求和\n",
    "print(b.norm(2),c.norm(2)) # 2-范数：平方和开根号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bfc5afdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4., 4.]) tensor([[2., 2.],\n",
      "        [2., 2.]])\n",
      "tensor([2., 2., 2., 2.]) tensor([[2., 2.],\n",
      "        [2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "#求哪个维度上的范数，那个维度就会消失\n",
    "print(b.norm(1,dim=1),c.norm(1,dim=1)) #第1维度上的1-范数\n",
    "print(b.norm(1,dim=0),c.norm(1,dim=0)) #第0维度上的1-范数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d1840823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2., 3.],\n",
      "        [4., 5., 6., 7.]])\n",
      "tensor(0.) tensor(7.) tensor(3.5000) tensor(0.) tensor(28.)\n"
     ]
    }
   ],
   "source": [
    "a=torch.arange(8).view(2,4).float()\n",
    "\n",
    "print(a)\n",
    "print(a.min(),a.max(),a.mean(),a.prod(),a.sum()) # 最小值和最大值，均值以及相乘相加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d2e0ee09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 3., 1., 0.],\n",
      "        [6., 7., 5., 4.]])\n",
      "tensor(5) tensor(3)\n"
     ]
    }
   ],
   "source": [
    "idx=torch.randperm(4)\n",
    "a=a[:,idx] # 打乱\n",
    "\n",
    "print(a)\n",
    "print(a.argmax(),a.argmin()) # 求打平后最小值和最大值的索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8fe52f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([1.9155, 1.6649, 1.5232, 0.6204]),\n",
      "indices=tensor([7, 2, 6, 5]))\n",
      "tensor([7, 2, 6, 5])\n",
      "torch.return_types.max(\n",
      "values=tensor([[1.9155],\n",
      "        [1.6649],\n",
      "        [1.5232],\n",
      "        [0.6204]]),\n",
      "indices=tensor([[7],\n",
      "        [2],\n",
      "        [6],\n",
      "        [5]]))\n"
     ]
    }
   ],
   "source": [
    "a=torch.randn(4,10)\n",
    "\n",
    "print(a.max(dim=1))\n",
    "print(a.argmax(dim=1))\n",
    "print(a.max(dim=1,keepdim=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c00d865c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([[ 1.6105, -0.0882, -0.4803],\n",
      "        [ 0.9384,  0.3840, -0.9316]]),\n",
      "indices=tensor([[1, 2, 4],\n",
      "        [0, 3, 2]]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([[-0.7087, -0.6440, -0.4803],\n",
      "        [-2.1850, -0.9395, -0.9316]]),\n",
      "indices=tensor([[3, 0, 4],\n",
      "        [1, 4, 2]]))\n",
      "torch.return_types.kthvalue(\n",
      "values=tensor([-0.4803, -0.9316]),\n",
      "indices=tensor([4, 2]))\n"
     ]
    }
   ],
   "source": [
    "a=torch.randn(2,5)\n",
    "\n",
    "#Topk: 从前往后数\n",
    "#kthvalue:从后往前数\n",
    "print(a.topk(3,dim=1))  #第1维度排名前3\n",
    "print(a.topk(3,dim=1,largest=False)) #第1维度排名后3\n",
    "print(a.kthvalue(3,dim=1)) #第1维度排名倒数第3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5f986a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5077, 1.0516],\n",
      "        [0.7547, 1.4434]])\n",
      "tensor([[True, True],\n",
      "        [True, True]])\n",
      "tensor([[True, True],\n",
      "        [True, True]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.randn(2,2)\n",
    "print(a)\n",
    "\n",
    "#>,>=,<,<=,!=,==\n",
    "print(a>0)\n",
    "print(torch.gt(a,0)) #等价于a>0,greater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b9f9fa20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False],\n",
      "        [False, False]])\n",
      "tensor([[True, True],\n",
      "        [True, True]])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "a=torch.ones(2,2)\n",
    "b=torch.randn(2,2)\n",
    "\n",
    "#torch.eq(a,b):tensor中各元素的对比\n",
    "#torch.equal(a,b):tensor的对比\n",
    "print(torch.eq(a,b))\n",
    "print(torch.eq(a,a))\n",
    "print(torch.equal(a,a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54e6240",
   "metadata": {},
   "source": [
    "## LS14.高阶操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2a4bb80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2644, 0.7934],\n",
      "        [0.0957, 0.6672]])\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "cond=torch.rand(2,2)\n",
    "print(cond)\n",
    "\n",
    "a=torch.zeros(2,2).float()\n",
    "b=torch.ones(2,2).float()\n",
    "\n",
    "print(torch.where(cond>0.5,a,b)) # where cond>0.5 a,else b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f7a20012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[107, 103, 100],\n",
      "        [102, 104, 101],\n",
      "        [106, 107, 108],\n",
      "        [108, 105, 107]])\n"
     ]
    }
   ],
   "source": [
    "prob=torch.randn(4,10)\n",
    "idx=prob.topk(dim=1,k=3) #取一维最大3个数\n",
    "idx=idx[1] # 取最大数的索引\n",
    "\n",
    "label=torch.arange(10)+100 # 100-109，10个数\n",
    "\n",
    "print(torch.gather(label.expand(4,10),dim=1,index=idx.long())) # 按照idx的顺序给label构造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972569c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
